---
title: "Cenários de dados envolvendo o Repositório Data Lake | Microsoft Docs"
description: "Entenda os diferentes cenários e as ferramentas usando quais dados podem ser ingeridos, processados, baixados e visualizados em um Repositório Data Lake"
services: data-lake-store
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
ms.assetid: 37409a71-a563-4bb7-bc46-2cbd426a2ece
ms.service: data-lake-store
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 05/10/2017
ms.author: nitinme
ms.openlocfilehash: 2a2801e5c506dcc8aa9ca2ecd275b52c72d5fbbf
ms.sourcegitcommit: 18ad9bc049589c8e44ed277f8f43dcaa483f3339
ms.translationtype: MT
ms.contentlocale: pt-BR
ms.lasthandoff: 08/29/2017
---
# <a name="using-azure-data-lake-store-for-big-data-requirements"></a><span data-ttu-id="5b64d-103">Como usar o Repositório Data Lake do Azure para exigências de big data</span><span class="sxs-lookup"><span data-stu-id="5b64d-103">Using Azure Data Lake Store for big data requirements</span></span>
<span data-ttu-id="5b64d-104">Há quatro estágios principais no processamento de big data:</span><span class="sxs-lookup"><span data-stu-id="5b64d-104">There are four key stages in big data processing:</span></span>

* <span data-ttu-id="5b64d-105">Ingestão de grandes quantidades de dados em um repositório de dados, em tempo real ou em lotes</span><span class="sxs-lookup"><span data-stu-id="5b64d-105">Ingesting large amounts of data into a data store, at real-time or in batches</span></span>
* <span data-ttu-id="5b64d-106">Processamento dos dados</span><span class="sxs-lookup"><span data-stu-id="5b64d-106">Processing the data</span></span>
* <span data-ttu-id="5b64d-107">Download dos dados</span><span class="sxs-lookup"><span data-stu-id="5b64d-107">Downloading the data</span></span>
* <span data-ttu-id="5b64d-108">Visualização dos dados</span><span class="sxs-lookup"><span data-stu-id="5b64d-108">Visualizing the data</span></span>

<span data-ttu-id="5b64d-109">Neste artigo, analisamos esses estágios com relação ao Repositório Azure Data Lake para entender as opções e as ferramentas disponíveis para atender às suas necessidades de big data.</span><span class="sxs-lookup"><span data-stu-id="5b64d-109">In this article, we look at these stages with respect to Azure Data Lake Store to understand the options and tools available to meet your big data needs.</span></span>

## <a name="ingest-data-into-data-lake-store"></a><span data-ttu-id="5b64d-110">Ingerir dados no Repositório Data Lake</span><span class="sxs-lookup"><span data-stu-id="5b64d-110">Ingest data into Data Lake Store</span></span>
<span data-ttu-id="5b64d-111">Esta seção destaca as diferentes fontes de dados e as diferentes maneiras que os dados podem ser ingeridos em uma conta do Repositório Data Lake.</span><span class="sxs-lookup"><span data-stu-id="5b64d-111">This section highlights the different sources of data and the different ways in which that data can be ingested into a Data Lake Store account.</span></span>

<span data-ttu-id="5b64d-112">![Ingerir dados no Data Lake Store](./media/data-lake-store-data-scenarios/ingest-data.png "Ingerir dados no Data Lake Store")</span><span class="sxs-lookup"><span data-stu-id="5b64d-112">![Ingest data into Data Lake Store](./media/data-lake-store-data-scenarios/ingest-data.png "Ingest data into Data Lake Store")</span></span>

### <a name="ad-hoc-data"></a><span data-ttu-id="5b64d-113">Dados ad hoc</span><span class="sxs-lookup"><span data-stu-id="5b64d-113">Ad hoc data</span></span>
<span data-ttu-id="5b64d-114">Representam conjuntos de dados menores que são usados para criar protótipos de um aplicativo de big data.</span><span class="sxs-lookup"><span data-stu-id="5b64d-114">This represents smaller data sets that are used for prototyping a big data application.</span></span> <span data-ttu-id="5b64d-115">Há diferentes maneiras de ingerir dados ad hoc, dependendo da fonte dos dados.</span><span class="sxs-lookup"><span data-stu-id="5b64d-115">There are different ways of ingesting ad hoc data depending on the source of the data.</span></span>

| <span data-ttu-id="5b64d-116">Fonte de dados</span><span class="sxs-lookup"><span data-stu-id="5b64d-116">Data Source</span></span> | <span data-ttu-id="5b64d-117">Ingeri-la usando</span><span class="sxs-lookup"><span data-stu-id="5b64d-117">Ingest it using</span></span> |
| --- | --- |
| <span data-ttu-id="5b64d-118">Computador local</span><span class="sxs-lookup"><span data-stu-id="5b64d-118">Local computer</span></span> |<ul> <li>[<span data-ttu-id="5b64d-119">Portal do Azure</span><span class="sxs-lookup"><span data-stu-id="5b64d-119">Azure Portal</span></span>](/data-lake-store-get-started-portal.md)</li> <li>[<span data-ttu-id="5b64d-120">PowerShell do Azure</span><span class="sxs-lookup"><span data-stu-id="5b64d-120">Azure PowerShell</span></span>](data-lake-store-get-started-powershell.md)</li> <li>[<span data-ttu-id="5b64d-121">CLI 2.0 de plataforma cruzada do Azure</span><span class="sxs-lookup"><span data-stu-id="5b64d-121">Azure Cross-platform CLI 2.0</span></span>](data-lake-store-get-started-cli-2.0.md)</li> <li>[<span data-ttu-id="5b64d-122">Usando as ferramentas do Data Lake para o Visual Studio</span><span class="sxs-lookup"><span data-stu-id="5b64d-122">Using Data Lake Tools for Visual Studio</span></span>](../data-lake-analytics/data-lake-analytics-data-lake-tools-get-started.md) </li></ul> |
| <span data-ttu-id="5b64d-123">Blob de Armazenamento do Azure</span><span class="sxs-lookup"><span data-stu-id="5b64d-123">Azure Storage Blob</span></span> |<ul> <li>[<span data-ttu-id="5b64d-124">Azure Data Factory</span><span class="sxs-lookup"><span data-stu-id="5b64d-124">Azure Data Factory</span></span>](../data-factory/data-factory-azure-datalake-connector.md)</li> <li>[<span data-ttu-id="5b64d-125">ferramenta AdlCopy</span><span class="sxs-lookup"><span data-stu-id="5b64d-125">AdlCopy tool</span></span>](data-lake-store-copy-data-azure-storage-blob.md)</li><li>[<span data-ttu-id="5b64d-126">DistCp em execução no cluster HDInsight</span><span class="sxs-lookup"><span data-stu-id="5b64d-126">DistCp running on HDInsight cluster</span></span>](data-lake-store-copy-data-wasb-distcp.md)</li> </ul> |

### <a name="streamed-data"></a><span data-ttu-id="5b64d-127">Dados transmitidos</span><span class="sxs-lookup"><span data-stu-id="5b64d-127">Streamed data</span></span>
<span data-ttu-id="5b64d-128">Representam os dados que podem ser gerados por várias fontes, como aplicativos, dispositivos, sensores, etc. Esses dados podem ser ingeridos em um Repositório Data Lake por uma variedade de ferramentas.</span><span class="sxs-lookup"><span data-stu-id="5b64d-128">This represents data that can be generated by various sources such as applications, devices, sensors, etc. This data can be ingested into a Data Lake Store by variety tools.</span></span> <span data-ttu-id="5b64d-129">Essas ferramentas geralmente capturam e processam os dados em um evento em tempo real e gravam os eventos em lotes no Repositório Data Lake para que depois eles possam ser processados.</span><span class="sxs-lookup"><span data-stu-id="5b64d-129">These tools will usually capture and process the data on an event-by-event basis in real-time, and then write the events in batches into Data Lake Store so that they can be further processed.</span></span>

<span data-ttu-id="5b64d-130">Veja as ferramentas que você pode usar:</span><span class="sxs-lookup"><span data-stu-id="5b64d-130">Following are tools that you can use:</span></span>

* <span data-ttu-id="5b64d-131">[Stream Analytics do Azure](../stream-analytics/stream-analytics-data-lake-output.md) – os eventos ingeridos nos Hubs de Eventos podem ser gravados no Azure Data Lake usando uma saída do Azure Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="5b64d-131">[Azure Stream Analytics](../stream-analytics/stream-analytics-data-lake-output.md) - Events ingested into Event Hubs can be written to Azure Data Lake using an Azure Data Lake Store output.</span></span>
* <span data-ttu-id="5b64d-132">[Azure HDInsight Storm](../hdinsight/hdinsight-storm-write-data-lake-store.md) : é possível gravar dados diretamente do cluster Storm no Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="5b64d-132">[Azure HDInsight Storm](../hdinsight/hdinsight-storm-write-data-lake-store.md) - You can write data directly to Data Lake Store from the Storm cluster.</span></span>
* <span data-ttu-id="5b64d-133">[EventProcessorHost](../event-hubs/event-hubs-dotnet-standard-getstarted-receive-eph.md) – É possível receber eventos dos Hubs de Eventos e gravá-los no Data Lake Store usando o [SDK para .NET do Data Lake Store](data-lake-store-get-started-net-sdk.md).</span><span class="sxs-lookup"><span data-stu-id="5b64d-133">[EventProcessorHost](../event-hubs/event-hubs-dotnet-standard-getstarted-receive-eph.md) – You can receive events from Event Hubs and then write it to Data Lake Store using the [Data Lake Store .NET SDK](data-lake-store-get-started-net-sdk.md).</span></span>

### <a name="relational-data"></a><span data-ttu-id="5b64d-134">Dados relacionais</span><span class="sxs-lookup"><span data-stu-id="5b64d-134">Relational data</span></span>
<span data-ttu-id="5b64d-135">Você também pode originar dados nos bancos de dados relacionais.</span><span class="sxs-lookup"><span data-stu-id="5b64d-135">You can also source data from relational databases.</span></span> <span data-ttu-id="5b64d-136">Durante um período, os bancos de dados relacionais coletam grandes volumes de dados que podem fornecer informações importantes se processados por meio de um pipeline de big data.</span><span class="sxs-lookup"><span data-stu-id="5b64d-136">Over a period of time, relational databases collect huge amounts of data which can provide key insights if processed through a big data pipeline.</span></span> <span data-ttu-id="5b64d-137">É possível usar as ferramentas a seguir para mover tais dados para o Repositório Data Lake.</span><span class="sxs-lookup"><span data-stu-id="5b64d-137">You can use the following tools to move such data into Data Lake Store.</span></span>

* [<span data-ttu-id="5b64d-138">Apache Sqoop</span><span class="sxs-lookup"><span data-stu-id="5b64d-138">Apache Sqoop</span></span>](data-lake-store-data-transfer-sql-sqoop.md)
* [<span data-ttu-id="5b64d-139">Azure Data Factory</span><span class="sxs-lookup"><span data-stu-id="5b64d-139">Azure Data Factory</span></span>](../data-factory/data-factory-data-movement-activities.md)

### <a name="web-server-log-data-upload-using-custom-applications"></a><span data-ttu-id="5b64d-140">Dados de log do servidor Web (carregar usando aplicativos personalizados)</span><span class="sxs-lookup"><span data-stu-id="5b64d-140">Web server log data (upload using custom applications)</span></span>
<span data-ttu-id="5b64d-141">Esse tipo de conjunto de dados é especificamente chamado porque a análise dos dados do log do servidor Web é um caso de uso comum para aplicativos de big data e requer que grandes volumes de arquivos de log sejam carregados no Repositório Data Lake.</span><span class="sxs-lookup"><span data-stu-id="5b64d-141">This type of dataset is specifically called out because analysis of web server log data is a common use case for big data applications and requires large volumes of log files to be uploaded to the Data Lake Store.</span></span> <span data-ttu-id="5b64d-142">Você pode usar qualquer uma das ferramentas a seguir para escrever seus próprios scripts ou aplicativos para carregar esses dados.</span><span class="sxs-lookup"><span data-stu-id="5b64d-142">You can use any of the following tools to write your own scripts or applications to upload such data.</span></span>

* [<span data-ttu-id="5b64d-143">CLI 2.0 de plataforma cruzada do Azure</span><span class="sxs-lookup"><span data-stu-id="5b64d-143">Azure Cross-platform CLI 2.0</span></span>](data-lake-store-get-started-cli-2.0.md)
* [<span data-ttu-id="5b64d-144">PowerShell do Azure</span><span class="sxs-lookup"><span data-stu-id="5b64d-144">Azure PowerShell</span></span>](data-lake-store-get-started-powershell.md)
* [<span data-ttu-id="5b64d-145">SDK .NET do Repositório Azure Data Lake</span><span class="sxs-lookup"><span data-stu-id="5b64d-145">Azure Data Lake Store .NET SDK</span></span>](data-lake-store-get-started-net-sdk.md)
* [<span data-ttu-id="5b64d-146">Azure Data Factory</span><span class="sxs-lookup"><span data-stu-id="5b64d-146">Azure Data Factory</span></span>](../data-factory/data-factory-data-movement-activities.md)

<span data-ttu-id="5b64d-147">Para carregar dados de log do servidor Web, e também para carregar outros tipos de dados (por exemplo, dados de sentimentos sociais), é uma boa abordagem escrever seus próprios scripts/aplicativos personalizados, pois eles proporcionam a flexibilidade para incluir seus dados carregando o componente como parte do aplicativo maior de big data.</span><span class="sxs-lookup"><span data-stu-id="5b64d-147">For uploading web server log data, and also for uploading other kinds of data (e.g. social sentiments data), it is a good approach to write your own custom scripts/applications because it gives you the flexibility to include your data uploading component as part of your larger big data application.</span></span> <span data-ttu-id="5b64d-148">Em alguns casos, esse código pode assumir a forma de um script ou um utilitário simples de linha de comando.</span><span class="sxs-lookup"><span data-stu-id="5b64d-148">In some cases this code may take the form of a script or simple command line utility.</span></span> <span data-ttu-id="5b64d-149">Em outros casos, o código pode ser usado para integrar o processamento de big data em um aplicativo ou uma solução de negócios.</span><span class="sxs-lookup"><span data-stu-id="5b64d-149">In other cases, the code may be used to integrate big data processing into a business application or solution.</span></span>

### <a name="data-associated-with-azure-hdinsight-clusters"></a><span data-ttu-id="5b64d-150">Dados associados aos clusters Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="5b64d-150">Data associated with Azure HDInsight clusters</span></span>
<span data-ttu-id="5b64d-151">A maioria dos tipos de cluster HDInsight (Hadoop, HBase, Storm) é compatível com o Repositório Data Lake como um repositório de armazenamento de dados.</span><span class="sxs-lookup"><span data-stu-id="5b64d-151">Most HDInsight cluster types (Hadoop, HBase, Storm) support Data Lake Store as a data storage repository.</span></span> <span data-ttu-id="5b64d-152">Os clusters HDInsight acessam dados dos WASB (Blobs de Armazenamento do Azure).</span><span class="sxs-lookup"><span data-stu-id="5b64d-152">HDInsight clusters access data from Azure Storage Blobs (WASB).</span></span> <span data-ttu-id="5b64d-153">Para obter melhor desempenho, você pode copiar os dados do WASB em uma conta do Repositório Data Lake associada ao cluster.</span><span class="sxs-lookup"><span data-stu-id="5b64d-153">For better performance, you can copy the data from WASB into a Data Lake Store account associated with the cluster.</span></span> <span data-ttu-id="5b64d-154">Você pode usar as ferramentas a seguir para copiar os dados.</span><span class="sxs-lookup"><span data-stu-id="5b64d-154">You can use the following tools to copy the data.</span></span>

* [<span data-ttu-id="5b64d-155">Apache DistCp</span><span class="sxs-lookup"><span data-stu-id="5b64d-155">Apache DistCp</span></span>](data-lake-store-copy-data-wasb-distcp.md)
* [<span data-ttu-id="5b64d-156">Serviço AdlCopy</span><span class="sxs-lookup"><span data-stu-id="5b64d-156">AdlCopy Service</span></span>](data-lake-store-copy-data-azure-storage-blob.md)
* [<span data-ttu-id="5b64d-157">Azure Data Factory</span><span class="sxs-lookup"><span data-stu-id="5b64d-157">Azure Data Factory</span></span>](../data-factory/data-factory-azure-datalake-connector.md)

### <a name="data-stored-in-on-premises-or-iaas-hadoop-clusters"></a><span data-ttu-id="5b64d-158">Dados armazenados localmente ou em clusters Hadoop da IaaS</span><span class="sxs-lookup"><span data-stu-id="5b64d-158">Data stored in on-premises or IaaS Hadoop clusters</span></span>
<span data-ttu-id="5b64d-159">É possível armazenar grandes quantidades de dados em clusters de Hadoop existentes, localmente em computadores que usam o HDFS.</span><span class="sxs-lookup"><span data-stu-id="5b64d-159">Large amounts of data may be stored in existing Hadoop clusters, locally on machines using HDFS.</span></span> <span data-ttu-id="5b64d-160">Os clusters Hadoop podem estar em uma implantação local ou em um cluster da IaaS no Azure.</span><span class="sxs-lookup"><span data-stu-id="5b64d-160">The Hadoop clusters may be in an on-premises deployment or may be within an IaaS cluster on Azure.</span></span> <span data-ttu-id="5b64d-161">Pode haver requisitos para copiar esses dados no Repositório Data Lake do Azure para uma abordagem única ou de forma recorrente.</span><span class="sxs-lookup"><span data-stu-id="5b64d-161">There could be requirements to copy such data to Azure Data Lake Store for a one-off approach or in a recurring fashion.</span></span> <span data-ttu-id="5b64d-162">Há várias opções que podem ser usadas para conseguir isso.</span><span class="sxs-lookup"><span data-stu-id="5b64d-162">There are various options that you can use to achieve this.</span></span> <span data-ttu-id="5b64d-163">Veja abaixo uma lista de alternativas e as compensações associadas.</span><span class="sxs-lookup"><span data-stu-id="5b64d-163">Below is a list of alternatives and the associated trade-offs.</span></span>

| <span data-ttu-id="5b64d-164">Abordagem</span><span class="sxs-lookup"><span data-stu-id="5b64d-164">Approach</span></span> | <span data-ttu-id="5b64d-165">Detalhes</span><span class="sxs-lookup"><span data-stu-id="5b64d-165">Details</span></span> | <span data-ttu-id="5b64d-166">Vantagens</span><span class="sxs-lookup"><span data-stu-id="5b64d-166">Advantages</span></span> | <span data-ttu-id="5b64d-167">Considerações</span><span class="sxs-lookup"><span data-stu-id="5b64d-167">Considerations</span></span> |
| --- | --- | --- | --- |
| <span data-ttu-id="5b64d-168">Usar o ADF (Azure Data Factory) para copiar dados diretamente de clusters Hadoop para o Repositório Data Lake do Azure</span><span class="sxs-lookup"><span data-stu-id="5b64d-168">Use Azure Data Factory (ADF) to copy data directly from Hadoop clusters to Azure Data Lake Store</span></span> |[<span data-ttu-id="5b64d-169">O ADF oferece suporte ao HDFS como uma fonte de dados</span><span class="sxs-lookup"><span data-stu-id="5b64d-169">ADF supports HDFS as a data source</span></span>](../data-factory/data-factory-hdfs-connector.md) |<span data-ttu-id="5b64d-170">O ADF fornece suporte nativo para HDFS e gerenciamento e monitoramento de primeira classe completo</span><span class="sxs-lookup"><span data-stu-id="5b64d-170">ADF provides out-of-the-box support for HDFS and first class end-to-end management and monitoring</span></span> |<span data-ttu-id="5b64d-171">Ele exige que um gateway de gerenciamento de dados seja implantado localmente ou em um cluster da IaaS</span><span class="sxs-lookup"><span data-stu-id="5b64d-171">Requires Data Management Gateway to be deployed on-premises or in the IaaS cluster</span></span> |
| <span data-ttu-id="5b64d-172">Exporte os dados do Hadoop como arquivos.</span><span class="sxs-lookup"><span data-stu-id="5b64d-172">Export data from Hadoop as files.</span></span> <span data-ttu-id="5b64d-173">Em seguida, copie os arquivos no Repositório Data Lake do Azure Store usando o mecanismo apropriado.</span><span class="sxs-lookup"><span data-stu-id="5b64d-173">Then copy the files to Azure Data Lake Store using appropriate mechanism.</span></span> |<span data-ttu-id="5b64d-174">Você pode copiar os arquivos no Azure Data Lake Store usando: </span><span class="sxs-lookup"><span data-stu-id="5b64d-174">You can copy files to Azure Data Lake Store using:</span></span> <ul><li>[<span data-ttu-id="5b64d-175">Azure PowerShell para o sistema operacional Windows</span><span class="sxs-lookup"><span data-stu-id="5b64d-175">Azure PowerShell for Windows OS</span></span>](data-lake-store-get-started-powershell.md)</li><li>[<span data-ttu-id="5b64d-176">CLI 2.0 de plataforma cruzada do Azure para sistema operacional não Windows</span><span class="sxs-lookup"><span data-stu-id="5b64d-176">Azure Cross-platform CLI 2.0 for non-Windows OS</span></span>](data-lake-store-get-started-cli-2.0.md)</li><li><span data-ttu-id="5b64d-177">Aplicativo personalizado usando qualquer SDK do Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="5b64d-177">Custom app using any Data Lake Store SDK</span></span></li></ul> |<span data-ttu-id="5b64d-178">Início rápido.</span><span class="sxs-lookup"><span data-stu-id="5b64d-178">Quick to get started.</span></span> <span data-ttu-id="5b64d-179">Pode realizar carregamentos personalizados</span><span class="sxs-lookup"><span data-stu-id="5b64d-179">Can do customized uploads</span></span> |<span data-ttu-id="5b64d-180">Processo de várias etapas que envolve várias tecnologias.</span><span class="sxs-lookup"><span data-stu-id="5b64d-180">Multi-step process that involves multiple technologies.</span></span> <span data-ttu-id="5b64d-181">O monitoramento e o gerenciamento aumentarão a serão um desafio ao longo do tempo devido à natureza personalizada das ferramentas</span><span class="sxs-lookup"><span data-stu-id="5b64d-181">Management and monitoring will grow to be a challenge over time given the customized nature of the tools</span></span> |
| <span data-ttu-id="5b64d-182">Use Distcp para copiar dados do Hadoop para o Armazenamento do Azure.</span><span class="sxs-lookup"><span data-stu-id="5b64d-182">Use Distcp to copy data from Hadoop to Azure Storage.</span></span> <span data-ttu-id="5b64d-183">Em seguida, copie os dados no Armazenamento do Azure para o Repositório Data Lake usando o mecanismo apropriado.</span><span class="sxs-lookup"><span data-stu-id="5b64d-183">Then copy data from Azure Storage to Data Lake Store using appropriate mechanism.</span></span> |<span data-ttu-id="5b64d-184">Você pode copiar dados do Armazenamento do Azure para o Data Lake Store usando: </span><span class="sxs-lookup"><span data-stu-id="5b64d-184">You can copy data from Azure Storage to Data Lake Store using:</span></span> <ul><li>[<span data-ttu-id="5b64d-185">Azure Data Factory</span><span class="sxs-lookup"><span data-stu-id="5b64d-185">Azure Data Factory</span></span>](../data-factory/data-factory-data-movement-activities.md)</li><li>[<span data-ttu-id="5b64d-186">ferramenta AdlCopy</span><span class="sxs-lookup"><span data-stu-id="5b64d-186">AdlCopy tool</span></span>](data-lake-store-copy-data-azure-storage-blob.md)</li><li>[<span data-ttu-id="5b64d-187">Apache DistCp em execução em clusters do HDInsight</span><span class="sxs-lookup"><span data-stu-id="5b64d-187">Apache DistCp running on HDInsight clusters</span></span>](data-lake-store-copy-data-wasb-distcp.md)</li></ul> |<span data-ttu-id="5b64d-188">Você pode usar ferramentas de software livre.</span><span class="sxs-lookup"><span data-stu-id="5b64d-188">You can use open-source tools.</span></span> |<span data-ttu-id="5b64d-189">Processo de várias etapas que envolve várias tecnologias</span><span class="sxs-lookup"><span data-stu-id="5b64d-189">Multi-step process that involves multiple technologies</span></span> |

### <a name="really-large-datasets"></a><span data-ttu-id="5b64d-190">Conjuntos de dados realmente grandes</span><span class="sxs-lookup"><span data-stu-id="5b64d-190">Really large datasets</span></span>
<span data-ttu-id="5b64d-191">Carregar conjuntos de dados que incluem vários terabytes usando os métodos descritos acima, às vezes, pode ser uma tarefa lenta e onerosa.</span><span class="sxs-lookup"><span data-stu-id="5b64d-191">For uploading datasets that range in several terabytes, using the methods described above can sometimes be slow and costly.</span></span> <span data-ttu-id="5b64d-192">Nesses casos, você pode usar as opções a seguir.</span><span class="sxs-lookup"><span data-stu-id="5b64d-192">In such cases, you can use the options below.</span></span>

* <span data-ttu-id="5b64d-193">**Usando o ExpressRoute do Azure**.</span><span class="sxs-lookup"><span data-stu-id="5b64d-193">**Using Azure ExpressRoute**.</span></span> <span data-ttu-id="5b64d-194">O Azure ExpressRoute permite criar conexões privadas entre os datacenters do Azure e a infraestrutura presente em seu local.</span><span class="sxs-lookup"><span data-stu-id="5b64d-194">Azure ExpressRoute lets you create private connections between Azure datacenters and infrastructure on your premises.</span></span> <span data-ttu-id="5b64d-195">Isso proporciona uma opção confiável para transferir grandes quantidades de dados.</span><span class="sxs-lookup"><span data-stu-id="5b64d-195">This provides a reliable option for transferring large amounts of data.</span></span> <span data-ttu-id="5b64d-196">Para obter mais informações, confira a [documentação do ExpressRoute do Azure](../expressroute/expressroute-introduction.md).</span><span class="sxs-lookup"><span data-stu-id="5b64d-196">For more information, see [Azure ExpressRoute documentation](../expressroute/expressroute-introduction.md).</span></span>
* <span data-ttu-id="5b64d-197">**Carregamento de dados "offline"**.</span><span class="sxs-lookup"><span data-stu-id="5b64d-197">**"Offline" upload of data**.</span></span> <span data-ttu-id="5b64d-198">Se o uso do ExpressRoute do Azure não for possível por qualquer motivo, você poderá usar o [serviço de Importação/Exportação do Azure](../storage/common/storage-import-export-service.md) para enviar unidades de disco rígido com seus dados para um datacenter do Azure.</span><span class="sxs-lookup"><span data-stu-id="5b64d-198">If using Azure ExpressRoute is not feasible for any reason, you can use [Azure Import/Export service](../storage/common/storage-import-export-service.md) to ship hard disk drives with your data to an Azure data center.</span></span> <span data-ttu-id="5b64d-199">Seus dados são carregados pela primeira vez nos Blobs de Armazenamento do Azure.</span><span class="sxs-lookup"><span data-stu-id="5b64d-199">Your data is first uploaded to Azure Storage Blobs.</span></span> <span data-ttu-id="5b64d-200">Em seguida, é possível usar o [Azure Data Factory](../data-factory/data-factory-azure-datalake-connector.md) ou a [ferramenta AdlCopy](data-lake-store-copy-data-azure-storage-blob.md) para copiar dados dos Azure Storage Blobs para o Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="5b64d-200">You can then use [Azure Data Factory](../data-factory/data-factory-azure-datalake-connector.md) or [AdlCopy tool](data-lake-store-copy-data-azure-storage-blob.md) to copy data from Azure Storage Blobs to Data Lake Store.</span></span>

  > [!NOTE]
  > <span data-ttu-id="5b64d-201">Ao usar o serviço Importação/Exportação, os tamanhos dos arquivos nos discos que você envia ao datacenter do Azure não devem ultrapassar 195 GB.</span><span class="sxs-lookup"><span data-stu-id="5b64d-201">While using the Import/Export service, the file sizes on the disks that you ship to Azure data center should not be greater than 195 GB.</span></span>
  >
  >

## <a name="process-data-stored-in-data-lake-store"></a><span data-ttu-id="5b64d-202">Processar dados armazenados no Repositório Data Lake</span><span class="sxs-lookup"><span data-stu-id="5b64d-202">Process data stored in Data Lake Store</span></span>
<span data-ttu-id="5b64d-203">Depois que os dados estiverem disponíveis no Repositório Data Lake, você poderá fazer uma análise nesses dados usando os aplicativos de big data compatíveis.</span><span class="sxs-lookup"><span data-stu-id="5b64d-203">Once the data is available in Data Lake Store you can run analysis on that data using the supported big data applications.</span></span> <span data-ttu-id="5b64d-204">Atualmente, é possível usar o Azure HDInsight e a Análise do Azure Data Lake para executar trabalhos de análise de dados nos dados armazenados em um Repositório Data Lake.</span><span class="sxs-lookup"><span data-stu-id="5b64d-204">Currently, you can use Azure HDInsight and Azure Data Lake Analytics to run data analysis jobs on the data stored in Data Lake Store.</span></span>

<span data-ttu-id="5b64d-205">![Analisar os dados no Data Lake Store](./media/data-lake-store-data-scenarios/analyze-data.png "Analisar os dados no Data Lake Store")</span><span class="sxs-lookup"><span data-stu-id="5b64d-205">![Analyze data in Data Lake Store](./media/data-lake-store-data-scenarios/analyze-data.png "Analyze data in Data Lake Store")</span></span>

<span data-ttu-id="5b64d-206">Você pode analisar os exemplos a seguir.</span><span class="sxs-lookup"><span data-stu-id="5b64d-206">You can look at the following examples.</span></span>

* [<span data-ttu-id="5b64d-207">Criar um cluster HDInsight com o Repositório Data Lake como armazenamento</span><span class="sxs-lookup"><span data-stu-id="5b64d-207">Create an HDInsight cluster with Data Lake Store as storage</span></span>](data-lake-store-hdinsight-hadoop-use-portal.md)
* [<span data-ttu-id="5b64d-208">Usar a Análise Data Lake do Azure com o Repositório Data Lake</span><span class="sxs-lookup"><span data-stu-id="5b64d-208">Use Azure Data Lake Analytics with Data Lake Store</span></span>](../data-lake-analytics/data-lake-analytics-get-started-portal.md)

## <a name="download-data-from-data-lake-store"></a><span data-ttu-id="5b64d-209">Baixar dados do Repositório Data Lake</span><span class="sxs-lookup"><span data-stu-id="5b64d-209">Download data from Data Lake Store</span></span>
<span data-ttu-id="5b64d-210">Você também pode querer baixar ou mover dados do Repositório Azure Data Lake para cenários como:</span><span class="sxs-lookup"><span data-stu-id="5b64d-210">You might also want to download or move data from Azure Data Lake Store for scenarios such as:</span></span>

* <span data-ttu-id="5b64d-211">Mover dados para outros repositórios para fazer interface com os pipelines de processamento de dados existentes.</span><span class="sxs-lookup"><span data-stu-id="5b64d-211">Move data to other repositories to interface with your existing data processing pipelines.</span></span> <span data-ttu-id="5b64d-212">Por exemplo, você pode querer mover os dados do Repositório Data Lake para o Banco de Dados SQL do Azure ou SQL Server local.</span><span class="sxs-lookup"><span data-stu-id="5b64d-212">For example, you might want to move data from Data Lake Store to Azure SQL Database or on-premises SQL Server.</span></span>
* <span data-ttu-id="5b64d-213">Baixar dados no computador local para processamento em ambientes IDE durante a criação de protótipos de aplicativo.</span><span class="sxs-lookup"><span data-stu-id="5b64d-213">Download data to your local computer for processing in IDE environments while building application prototypes.</span></span>

<span data-ttu-id="5b64d-214">![Gerar dados no Data Lake Store](./media/data-lake-store-data-scenarios/egress-data.png "Gerar dados no Data Lake Store")</span><span class="sxs-lookup"><span data-stu-id="5b64d-214">![Egress data from Data Lake Store](./media/data-lake-store-data-scenarios/egress-data.png "Egress data from Data Lake Store")</span></span>

<span data-ttu-id="5b64d-215">Nesses casos, você pode usar qualquer uma das opções a seguir:</span><span class="sxs-lookup"><span data-stu-id="5b64d-215">In such cases, you can use any of the following options:</span></span>

* [<span data-ttu-id="5b64d-216">Apache Sqoop</span><span class="sxs-lookup"><span data-stu-id="5b64d-216">Apache Sqoop</span></span>](data-lake-store-data-transfer-sql-sqoop.md)
* [<span data-ttu-id="5b64d-217">Azure Data Factory</span><span class="sxs-lookup"><span data-stu-id="5b64d-217">Azure Data Factory</span></span>](../data-factory/data-factory-data-movement-activities.md)
* [<span data-ttu-id="5b64d-218">Apache DistCp</span><span class="sxs-lookup"><span data-stu-id="5b64d-218">Apache DistCp</span></span>](data-lake-store-copy-data-wasb-distcp.md)

<span data-ttu-id="5b64d-219">Você também pode usar os métodos a seguir para escrever seu próprio script/aplicativo e baixar dados do Repositório Data Lake.</span><span class="sxs-lookup"><span data-stu-id="5b64d-219">You can also use the following methods to write your own script/application to download data from Data Lake Store.</span></span>

* [<span data-ttu-id="5b64d-220">CLI 2.0 de plataforma cruzada do Azure</span><span class="sxs-lookup"><span data-stu-id="5b64d-220">Azure Cross-platform CLI 2.0</span></span>](data-lake-store-get-started-cli-2.0.md)
* [<span data-ttu-id="5b64d-221">PowerShell do Azure</span><span class="sxs-lookup"><span data-stu-id="5b64d-221">Azure PowerShell</span></span>](data-lake-store-get-started-powershell.md)
* [<span data-ttu-id="5b64d-222">SDK .NET do Repositório Azure Data Lake</span><span class="sxs-lookup"><span data-stu-id="5b64d-222">Azure Data Lake Store .NET SDK</span></span>](data-lake-store-get-started-net-sdk.md)

## <a name="visualize-data-in-data-lake-store"></a><span data-ttu-id="5b64d-223">Visualizar dados no Repositório Data Lake</span><span class="sxs-lookup"><span data-stu-id="5b64d-223">Visualize data in Data Lake Store</span></span>
<span data-ttu-id="5b64d-224">Você pode usar uma combinação de serviços para criar representações visuais de dados armazenados no Repositório Data Lake.</span><span class="sxs-lookup"><span data-stu-id="5b64d-224">You can use a mix of services to create visual representations of data stored in Data Lake Store.</span></span>

<span data-ttu-id="5b64d-225">![Visualizar dados no Data Lake Store](./media/data-lake-store-data-scenarios/visualize-data.png "Visualizar dados no Data Lake Store")</span><span class="sxs-lookup"><span data-stu-id="5b64d-225">![Visualize data in Data Lake Store](./media/data-lake-store-data-scenarios/visualize-data.png "Visualize data in Data Lake Store")</span></span>

* <span data-ttu-id="5b64d-226">É possível começar usando o [Azure Data Factory para mover dados do Data Lake Store para um SQL Data Warehouse do Azure](../data-factory/data-factory-data-movement-activities.md#supported-data-stores-and-formats)</span><span class="sxs-lookup"><span data-stu-id="5b64d-226">You can start by using [Azure Data Factory to move data from Data Lake Store to Azure SQL Data Warehouse](../data-factory/data-factory-data-movement-activities.md#supported-data-stores-and-formats)</span></span>
* <span data-ttu-id="5b64d-227">Depois disso, você pode [integrar o Power BI ao SQL Data Warehouse do Azure](../sql-data-warehouse/sql-data-warehouse-integrate-power-bi.md) para criar a representação visual dos dados.</span><span class="sxs-lookup"><span data-stu-id="5b64d-227">After that, you can [integrate Power BI with Azure SQL Data Warehouse](../sql-data-warehouse/sql-data-warehouse-integrate-power-bi.md) to create visual representation of the data.</span></span>
