---
title: "Guia de desempenho e ajuste da Atividade de Cópia | Microsoft Docs"
description: "Saiba mais sobre os principais fatores que afetam o desempenho da movimentação de dados no Azure Data Factory quando você usa a Atividade de Cópia."
services: data-factory
documentationcenter: 
author: linda33wj
manager: jhubbard
editor: monicar
ms.assetid: 4b9a6a4f-8cf5-4e0a-a06f-8133a2b7bc58
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 08/10/2017
ms.author: jingwang
ms.openlocfilehash: 2779655aee3af3a351b30f18b4c9d9918e9f2210
ms.sourcegitcommit: 18ad9bc049589c8e44ed277f8f43dcaa483f3339
ms.translationtype: MT
ms.contentlocale: pt-BR
ms.lasthandoff: 08/29/2017
---
# <a name="copy-activity-performance-and-tuning-guide"></a><span data-ttu-id="663f9-103">Guia Desempenho e ajuste da Atividade de Cópia</span><span class="sxs-lookup"><span data-stu-id="663f9-103">Copy Activity performance and tuning guide</span></span>
<span data-ttu-id="663f9-104">A Atividade de cópia do Azure Data Factory fornece uma solução de dados excelente, segura, confiável e de alto desempenho.</span><span class="sxs-lookup"><span data-stu-id="663f9-104">Azure Data Factory Copy Activity delivers a first-class secure, reliable, and high-performance data loading solution.</span></span> <span data-ttu-id="663f9-105">Ela permite que você a copie dezenas de terabytes de dados diariamente em uma grande variedade de repositórios de dados na nuvem e locais.</span><span class="sxs-lookup"><span data-stu-id="663f9-105">It enables you to copy tens of terabytes of data every day across a rich variety of cloud and on-premises data stores.</span></span> <span data-ttu-id="663f9-106">Desempenho de carregamento de dados de rápido são a chave para garantir que você possa se concentrar no principal problema de "Big Data": a criação de soluções de análise avançada e obtenção de informações aprofundadas de todos esses dados.</span><span class="sxs-lookup"><span data-stu-id="663f9-106">Blazing-fast data loading performance is key to ensure you can focus on the core “big data” problem: building advanced analytics solutions and getting deep insights from all that data.</span></span>

<span data-ttu-id="663f9-107">O Azure fornece um conjunto de soluções de armazenamento de dados e data warehouse de nível empresarial, e atividade de cópia oferece uma experiência de carregamento de dados altamente otimizada que é fácil de configurar.</span><span class="sxs-lookup"><span data-stu-id="663f9-107">Azure provides a set of enterprise-grade data storage and data warehouse solutions, and Copy Activity offers a highly optimized data loading experience that is easy to configure and set up.</span></span> <span data-ttu-id="663f9-108">Com apenas uma atividade de cópia única, você pode obter:</span><span class="sxs-lookup"><span data-stu-id="663f9-108">With just a single copy activity, you can achieve:</span></span>

* <span data-ttu-id="663f9-109">Carregar dados no **SQL Data Warehouse do Azure** a **1,2 GBps**.</span><span class="sxs-lookup"><span data-stu-id="663f9-109">Loading data into **Azure SQL Data Warehouse** at **1.2 GBps**.</span></span> <span data-ttu-id="663f9-110">Para ver um passo a passo com um caso de uso, veja [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md) (Carregar 1 TB no SQL Data Warehouse do Azure em menos de 15 minutos com o Azure Data Factory).</span><span class="sxs-lookup"><span data-stu-id="663f9-110">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>
* <span data-ttu-id="663f9-111">O carregamento de dados no **Armazenamento de Blobs do Azure** a **1,0 GBps**</span><span class="sxs-lookup"><span data-stu-id="663f9-111">Loading data into **Azure Blob storage** at **1.0 GBps**</span></span>
* <span data-ttu-id="663f9-112">O carregamento de dados no **Azure Data Lake Store** a **1,0 GBps**</span><span class="sxs-lookup"><span data-stu-id="663f9-112">Loading data into **Azure Data Lake Store** at **1.0 GBps**</span></span>

<span data-ttu-id="663f9-113">Este artigo descreve:</span><span class="sxs-lookup"><span data-stu-id="663f9-113">This article describes:</span></span>

* <span data-ttu-id="663f9-114">[números de referência de desempenho](#performance-reference) para armazenamentos de dados de origem e coletor com suporte, para ajudá-lo a planejar o projeto;</span><span class="sxs-lookup"><span data-stu-id="663f9-114">[Performance reference numbers](#performance-reference) for supported source and sink data stores to help you plan your project;</span></span>
* <span data-ttu-id="663f9-115">Recursos que podem aumentar a taxa de transferência de cópia em cenários diferentes, incluindo [unidades de movimentação de dados em nuvem](#cloud-data-movement-units), [cópia paralela](#parallel-copy) e [cópia em etapas](#staged-copy);</span><span class="sxs-lookup"><span data-stu-id="663f9-115">Features that can boost the copy throughput in different scenarios, including [cloud data movement units](#cloud-data-movement-units), [parallel copy](#parallel-copy), and [staged Copy](#staged-copy);</span></span>
* <span data-ttu-id="663f9-116">[diretrizes de ajuste de desempenho](#performance-tuning-steps) sobre como ajustar o desempenho e os principais fatores que podem afetar o desempenho da cópia.</span><span class="sxs-lookup"><span data-stu-id="663f9-116">[Performance tuning guidance](#performance-tuning-steps) on how to tune the performance and the key factors that can impact copy performance.</span></span>

> [!NOTE]
> <span data-ttu-id="663f9-117">Se você não estiver familiarizado com a Atividade de Cópia em geral, consulte [Mover dados usando a Atividade de Cópia](data-factory-data-movement-activities.md) antes de ler este artigo.</span><span class="sxs-lookup"><span data-stu-id="663f9-117">If you are not familiar with Copy Activity in general, see [Move data by using Copy Activity](data-factory-data-movement-activities.md) before reading this article.</span></span>
>

## <a name="performance-reference"></a><span data-ttu-id="663f9-118">Referência de desempenho</span><span class="sxs-lookup"><span data-stu-id="663f9-118">Performance reference</span></span>

<span data-ttu-id="663f9-119">Como uma referência, a tabela abaixo mostra o número da taxa de transferência de cópia em MBps para a origem específica e os pares de coletores com base nos testes internos.</span><span class="sxs-lookup"><span data-stu-id="663f9-119">As a reference, below table shows the copy throughput number in MBps for the given source and sink pairs based on in-house testing.</span></span> <span data-ttu-id="663f9-120">Para comparação, ela também demonstra como as diferentes configurações das [unidades de movimentação de dados na nuvem](#cloud-data-movement-units) ou da [escalabilidade do Gateway de Gerenciamento de Dados](data-factory-data-management-gateway-high-availability-scalability.md) (vários nós de gateway) podem ajudar no desempenho da cópia.</span><span class="sxs-lookup"><span data-stu-id="663f9-120">For comparison, it also demonstrates how different settings of [cloud data movement units](#cloud-data-movement-units) or [Data Management Gateway scalability](data-factory-data-management-gateway-high-availability-scalability.md) (multiple gateway nodes) can help on copy performance.</span></span>

![Matriz de desempenho](./media/data-factory-copy-activity-performance/CopyPerfRef.png)


<span data-ttu-id="663f9-122">**Pontos a serem observados:**</span><span class="sxs-lookup"><span data-stu-id="663f9-122">**Points to note:**</span></span>
* <span data-ttu-id="663f9-123">A taxa de transferência é calculada usando a seguinte fórmula: [tamanho dos dados lidos na origem]/[duração da execução da Atividade de Cópia].</span><span class="sxs-lookup"><span data-stu-id="663f9-123">Throughput is calculated by using the following formula: [size of data read from source]/[Copy Activity run duration].</span></span>
* <span data-ttu-id="663f9-124">Os números de referência de desempenho na tabela foram medidos usando o conjunto de dados [TPC-H](http://www.tpc.org/tpch/) em uma execução de atividade de cópia única.</span><span class="sxs-lookup"><span data-stu-id="663f9-124">The performance reference numbers in the table were measured using [TPC-H](http://www.tpc.org/tpch/) data set in a single copy activity run.</span></span>
* <span data-ttu-id="663f9-125">Nos armazenamentos de dados do Azure, a origem e o coletor estão na mesma região do Azure.</span><span class="sxs-lookup"><span data-stu-id="663f9-125">In Azure data stores, the source and sink are in the same Azure region.</span></span>
* <span data-ttu-id="663f9-126">Para a cópia híbrida entre o armazenamento de dados local e na nuvem, cada nó de gateway foi executado em um computador que foi separado do armazenamento de dados local com a especificação abaixo.</span><span class="sxs-lookup"><span data-stu-id="663f9-126">For hybrid copy between on-premises and cloud data stores, each gateway node was running on a machine that was separate from the on-premises data store with below specification.</span></span> <span data-ttu-id="663f9-127">Quando uma única atividade foi executada no gateway, a operação de cópia consumiu apenas uma pequena parte da CPU, da memória ou da largura de banda do computador de teste.</span><span class="sxs-lookup"><span data-stu-id="663f9-127">When a single activity was running on gateway, the copy operation consumed only a small portion of the test machine's CPU, memory, or network bandwidth.</span></span> <span data-ttu-id="663f9-128">Saiba mais em [Considerações do Gateway de Gerenciamento de Dados](#considerations-for-data-management-gateway).</span><span class="sxs-lookup"><span data-stu-id="663f9-128">Learn more from [consideration for Data Management Gateway](#considerations-for-data-management-gateway).</span></span>
    <table>
    <tr>
        <td><span data-ttu-id="663f9-129">CPU</span><span class="sxs-lookup"><span data-stu-id="663f9-129">CPU</span></span></td>
        <td><span data-ttu-id="663f9-130">32 núcleos, Intel Xeon E5-2660 v2 de 2.20 GHz</span><span class="sxs-lookup"><span data-stu-id="663f9-130">32 cores 2.20 GHz Intel Xeon E5-2660 v2</span></span></td>
    </tr>
    <tr>
        <td><span data-ttu-id="663f9-131">Memória</span><span class="sxs-lookup"><span data-stu-id="663f9-131">Memory</span></span></td>
        <td><span data-ttu-id="663f9-132">128 GB</span><span class="sxs-lookup"><span data-stu-id="663f9-132">128 GB</span></span></td>
    </tr>
    <tr>
        <td><span data-ttu-id="663f9-133">Rede</span><span class="sxs-lookup"><span data-stu-id="663f9-133">Network</span></span></td>
        <td><span data-ttu-id="663f9-134">Interface da Internet: 10 Gbps; Interface da intranet: 40 Gbps</span><span class="sxs-lookup"><span data-stu-id="663f9-134">Internet interface: 10 Gbps; intranet interface: 40 Gbps</span></span></td>
    </tr>
    </table>


> [!TIP]
> <span data-ttu-id="663f9-135">Você pode obter uma maior taxa de transferência aproveitando mais DMUs (unidades de movimentação de dados) do que o padrão máximo, que é 32 para a execução de uma atividade de cópia de nuvem para nuvem.</span><span class="sxs-lookup"><span data-stu-id="663f9-135">You can achieve higher throughput by leveraging more data movement units (DMUs) than the default maximum DMUs, which is 32 for a cloud-to-cloud copy activity run.</span></span> <span data-ttu-id="663f9-136">Por exemplo, com 100 DMUs, é possível copiar dados do Blob do Azure para o Azure Data Lake Store a **1 GBps**.</span><span class="sxs-lookup"><span data-stu-id="663f9-136">For example, with 100 DMUs, you can achieve copying data from Azure Blob into Azure Data Lake Store at **1.0GBps**.</span></span> <span data-ttu-id="663f9-137">Confira a seção [Unidades de movimentação de dados de nuvem](#cloud-data-movement-units) para obter detalhes sobre esse recurso e o cenário com suporte.</span><span class="sxs-lookup"><span data-stu-id="663f9-137">See the [Cloud data movement units](#cloud-data-movement-units) section for details about this feature and the supported scenario.</span></span> <span data-ttu-id="663f9-138">Entre em contato com [suporte do Azure](https://azure.microsoft.com/support/) para solicitar mais DMUs.</span><span class="sxs-lookup"><span data-stu-id="663f9-138">Contact [Azure support](https://azure.microsoft.com/support/) to request more DMUs.</span></span>

## <a name="parallel-copy"></a><span data-ttu-id="663f9-139">Cópia paralela</span><span class="sxs-lookup"><span data-stu-id="663f9-139">Parallel copy</span></span>
<span data-ttu-id="663f9-140">Você pode ler os dados na origem ou gravar os dados no destino **em paralelo dentro de uma execução da Atividade de Cópia**.</span><span class="sxs-lookup"><span data-stu-id="663f9-140">You can read data from the source or write data to the destination **in parallel within a Copy Activity run**.</span></span> <span data-ttu-id="663f9-141">Esse recurso melhora a taxa de transferência de uma operação de cópia e reduz o tempo que leva para mover os dados.</span><span class="sxs-lookup"><span data-stu-id="663f9-141">This feature enhances the throughput of a copy operation and reduces the time it takes to move data.</span></span>

<span data-ttu-id="663f9-142">Essa configuração é diferente da propriedade de **simultaneidade** na definição da atividade.</span><span class="sxs-lookup"><span data-stu-id="663f9-142">This setting is different from the **concurrency** property in the activity definition.</span></span> <span data-ttu-id="663f9-143">A propriedade de **simultaneidade** determina o número de **execuções simultâneas** da Atividade de Cópia para processar os dados de diferentes janelas de atividade (1:00 às 2:00, 2:00 às 3:00, 3:00 às 4:00 e assim por diante).</span><span class="sxs-lookup"><span data-stu-id="663f9-143">The **concurrency** property determines the number of **concurrent Copy Activity runs** to process data from different activity windows (1 AM to 2 AM, 2 AM to 3 AM, 3 AM to 4 AM, and so on).</span></span> <span data-ttu-id="663f9-144">Esse recurso é útil quando você executa um carregamento histórico.</span><span class="sxs-lookup"><span data-stu-id="663f9-144">This capability is helpful when you perform a historical load.</span></span> <span data-ttu-id="663f9-145">O recurso de cópia paralela aplica-se a uma **simples execução da atividade**.</span><span class="sxs-lookup"><span data-stu-id="663f9-145">The parallel copy capability applies to a **single activity run**.</span></span>

<span data-ttu-id="663f9-146">Vejamos um cenário de exemplo.</span><span class="sxs-lookup"><span data-stu-id="663f9-146">Let's look at a sample scenario.</span></span> <span data-ttu-id="663f9-147">No exemplo a seguir, várias fatias do passado precisam ser processadas.</span><span class="sxs-lookup"><span data-stu-id="663f9-147">In the following example, multiple slices from the past need to be processed.</span></span> <span data-ttu-id="663f9-148">O Data Factory executa uma instância da Atividade de Cópia (uma execução da atividade) para cada fatia:</span><span class="sxs-lookup"><span data-stu-id="663f9-148">Data Factory runs an instance of Copy Activity (an activity run) for each slice:</span></span>

* <span data-ttu-id="663f9-149">Fatia de dados da primeira janela de atividade (1:00 às 2:00) = = > Execução da atividade 1</span><span class="sxs-lookup"><span data-stu-id="663f9-149">The data slice from the first activity window (1 AM to 2 AM) ==> Activity run 1</span></span>
* <span data-ttu-id="663f9-150">Fatia de dados da segunda janela de atividade (2:00 às 3:00) = = > Execução da atividade 2</span><span class="sxs-lookup"><span data-stu-id="663f9-150">The data slice from the second activity window (2 AM to 3 AM) ==> Activity run 2</span></span>
* <span data-ttu-id="663f9-151">Fatia de dados da terceira janela de atividade (3:00 às 4:00) == > Execução da atividade 3</span><span class="sxs-lookup"><span data-stu-id="663f9-151">The data slice from the second activity window (3 AM to 4 AM) ==> Activity run 3</span></span>

<span data-ttu-id="663f9-152">E assim por diante.</span><span class="sxs-lookup"><span data-stu-id="663f9-152">And so on.</span></span>

<span data-ttu-id="663f9-153">Neste exemplo, quando o valor da **simultaneidade** é definido para 2, a **execução da atividade 1** e a **execução da atividade 2** copiam dos dados das duas janelas de atividade **simultaneamente** para melhorar o desempenho da movimentação de dados.</span><span class="sxs-lookup"><span data-stu-id="663f9-153">In this example, when the **concurrency** value is set to 2, **Activity run 1** and **Activity run 2** copy data from two activity windows **concurrently** to improve data movement performance.</span></span> <span data-ttu-id="663f9-154">No entanto, se vários arquivos estiverem associados à execução da Atividade 1, o serviço de movimentação de dados copiará os arquivos da origem para o destino um arquivo por vez.</span><span class="sxs-lookup"><span data-stu-id="663f9-154">However, if multiple files are associated with Activity run 1, the data movement service copies files from the source to the destination one file at a time.</span></span>

### <a name="cloud-data-movement-units"></a><span data-ttu-id="663f9-155">Unidades de movimentação de dados de nuvem</span><span class="sxs-lookup"><span data-stu-id="663f9-155">Cloud data movement units</span></span>
<span data-ttu-id="663f9-156">Uma **unidade de movimentação de dados de nuvem (DMU)** é uma medida que representa a potência (uma combinação de CPU, memória e alocação de recursos da rede) de uma unidade única no Data Factory.</span><span class="sxs-lookup"><span data-stu-id="663f9-156">A **cloud data movement unit (DMU)** is a measure that represents the power (a combination of CPU, memory, and network resource allocation) of a single unit in Data Factory.</span></span> <span data-ttu-id="663f9-157">Uma DMU pode ser usada em uma operação de cópia de nuvem para nuvem, mas não em uma cópia híbrida.</span><span class="sxs-lookup"><span data-stu-id="663f9-157">A DMU might be used in a cloud-to-cloud copy operation, but not in a hybrid copy.</span></span>

<span data-ttu-id="663f9-158">Por padrão, o Data Factory usa uma única DMU de nuvem para fazer uma única execução da Atividade de Cópia.</span><span class="sxs-lookup"><span data-stu-id="663f9-158">By default, Data Factory uses a single cloud DMU to perform a single Copy Activity run.</span></span> <span data-ttu-id="663f9-159">Para substituir esse padrão, especifique um valor para a propriedade **cloudDataMovementUnits** da seguinte maneira.</span><span class="sxs-lookup"><span data-stu-id="663f9-159">To override this default, specify a value for the **cloudDataMovementUnits** property as follows.</span></span> <span data-ttu-id="663f9-160">Para obter informações sobre o nível de ganho de desempenho que você pode obter ao configurar mais unidades para uma origem e coletor de cópia específicos, consulte a [referência de desempenho](#performance-reference).</span><span class="sxs-lookup"><span data-stu-id="663f9-160">For information about the level of performance gain you might get when you configure more units for a specific copy source and sink, see the [performance reference](#performance-reference).</span></span>

```json
"activities":[  
    {
        "name": "Sample copy activity",
        "description": "",
        "type": "Copy",
        "inputs": [{ "name": "InputDataset" }],
        "outputs": [{ "name": "OutputDataset" }],
        "typeProperties": {
            "source": {
                "type": "BlobSource",
            },
            "sink": {
                "type": "AzureDataLakeStoreSink"
            },
            "cloudDataMovementUnits": 32
        }
    }
]
```
<span data-ttu-id="663f9-161">Os **valores permitidos** para a propriedade **cloudDataMovementUnits** são: 1 (padrão), 2, 4, 8, 16 e 32.</span><span class="sxs-lookup"><span data-stu-id="663f9-161">The **allowed values** for the **cloudDataMovementUnits** property are 1 (default), 2, 4, 8, 16, 32.</span></span> <span data-ttu-id="663f9-162">O **número real de DMUs de nuvem** que a operação de cópia usa na execução é igual ou menor que o valor configurado, dependendo do seu padrão de dados.</span><span class="sxs-lookup"><span data-stu-id="663f9-162">The **actual number of cloud DMUs** that the copy operation uses at run time is equal to or less than the configured value, depending on your data pattern.</span></span>

> [!NOTE]
> <span data-ttu-id="663f9-163">Se precisar de mais DMUs de nuvem para uma taxa de transferência maior, entre em contato com o [suporte do Azure](https://azure.microsoft.com/support/).</span><span class="sxs-lookup"><span data-stu-id="663f9-163">If you need more cloud DMUs for a higher throughput, contact [Azure support](https://azure.microsoft.com/support/).</span></span> <span data-ttu-id="663f9-164">A configuração de 8 e superior atualmente funciona apenas quando você **copia vários arquivos do Armazenamento de Blobs/Data Lake Store/Amazon S3/FTP na nuvem/SFTP na nuvem para Armazenamento de Blobs/Data Lake Store/Banco de Dados SQL do Azure**.</span><span class="sxs-lookup"><span data-stu-id="663f9-164">Setting of 8 and above currently works only when you **copy multiple files from Blob storage/Data Lake Store/Amazon S3/cloud FTP/cloud SFTP to Blob storage/Data Lake Store/Azure SQL Database**.</span></span>
>

### <a name="parallelcopies"></a><span data-ttu-id="663f9-165">parallelCopies</span><span class="sxs-lookup"><span data-stu-id="663f9-165">parallelCopies</span></span>
<span data-ttu-id="663f9-166">Você pode usar a propriedade **parallelCopies** para indicar o paralelismo que deseja que a Atividade de Cópia use.</span><span class="sxs-lookup"><span data-stu-id="663f9-166">You can use the **parallelCopies** property to indicate the parallelism that you want Copy Activity to use.</span></span> <span data-ttu-id="663f9-167">Você pode considerar essa propriedade como o número máximo de threads na Atividade de Cópia que podem ler a partir de sua fonte ou gravar em seus armazenamentos do coletor de dados em paralelo.</span><span class="sxs-lookup"><span data-stu-id="663f9-167">You can think of this property as the maximum number of threads within Copy Activity that can read from your source or write to your sink data stores in parallel.</span></span>

<span data-ttu-id="663f9-168">Para cada execução da Atividade de Cópia, o Data Factory determina o número de cópias paralelas a usar para copiar os dados do armazenamento de dados de origem para o de destino.</span><span class="sxs-lookup"><span data-stu-id="663f9-168">For each Copy Activity run, Data Factory determines the number of parallel copies to use to copy data from the source data store and to the destination data store.</span></span> <span data-ttu-id="663f9-169">O número padrão de cópias paralelas usadas depende do tipo de fonte e coletor usado.</span><span class="sxs-lookup"><span data-stu-id="663f9-169">The default number of parallel copies that it uses depends on the type of source and sink that you are using.</span></span>  

| <span data-ttu-id="663f9-170">Fonte e coletor</span><span class="sxs-lookup"><span data-stu-id="663f9-170">Source and sink</span></span> | <span data-ttu-id="663f9-171">Contagem de cópia paralela padrão determinada pelo serviço</span><span class="sxs-lookup"><span data-stu-id="663f9-171">Default parallel copy count determined by service</span></span> |
| --- | --- |
| <span data-ttu-id="663f9-172">Copiar dados entre os armazenamentos baseados em arquivo (armazenamento de Blobs; Data Lake Store; Amazon S3; sistema de arquivos local; HDFS (Sistema de Arquivos Distribuído Hadoop) local)</span><span class="sxs-lookup"><span data-stu-id="663f9-172">Copy data between file-based stores (Blob storage; Data Lake Store; Amazon S3; an on-premises file system; an on-premises HDFS)</span></span> |<span data-ttu-id="663f9-173">Entre 1 e 32.</span><span class="sxs-lookup"><span data-stu-id="663f9-173">Between 1 and 32.</span></span> <span data-ttu-id="663f9-174">Depende do tamanho dos arquivos e do número de unidades de movimentação de dados de nuvem (DMUs) usados para copiar os dados entre dois armazenamentos de dados de nuvem ou da configuração física do computador do Gateway usado para obter uma cópia híbrida (para copiar os dados de ou para um armazenamento de dados local).</span><span class="sxs-lookup"><span data-stu-id="663f9-174">Depends on the size of the files and the number of cloud data movement units (DMUs) used to copy data between two cloud data stores, or the physical configuration of the Gateway machine used for a hybrid copy (to copy data to or from an on-premises data store).</span></span> |
| <span data-ttu-id="663f9-175">Copiar dados de **qualquer armazenamento de dados de origem para o armazenamento de Tabelas do Azure**</span><span class="sxs-lookup"><span data-stu-id="663f9-175">Copy data from **any source data store to Azure Table storage**</span></span> |<span data-ttu-id="663f9-176">4</span><span class="sxs-lookup"><span data-stu-id="663f9-176">4</span></span> |
| <span data-ttu-id="663f9-177">Todos os outros pares de origem e coletor</span><span class="sxs-lookup"><span data-stu-id="663f9-177">All other source and sink pairs</span></span> |<span data-ttu-id="663f9-178">1</span><span class="sxs-lookup"><span data-stu-id="663f9-178">1</span></span> |

<span data-ttu-id="663f9-179">Normalmente, o comportamento padrão deve fornecer a melhor taxa de transferência.</span><span class="sxs-lookup"><span data-stu-id="663f9-179">Usually, the default behavior should give you the best throughput.</span></span> <span data-ttu-id="663f9-180">No entanto, para controlar a carga em computadores que hospedam os armazenamentos de dados ou ajustar o desempenho da cópia, você pode optar por substituir o valor padrão e especificar um valor para a propriedade **parallelCopies** .</span><span class="sxs-lookup"><span data-stu-id="663f9-180">However, to control the load on machines that host your data stores, or to tune copy performance, you may choose to override the default value and specify a value for the **parallelCopies** property.</span></span> <span data-ttu-id="663f9-181">O valor deve estar entre 1 e 32 (ambos incluídos).</span><span class="sxs-lookup"><span data-stu-id="663f9-181">The value must be between 1 and 32 (both inclusive).</span></span> <span data-ttu-id="663f9-182">Na execução, para ter o melhor desempenho, a Atividade de Cópia usa um valor menor ou igual ao valor definido.</span><span class="sxs-lookup"><span data-stu-id="663f9-182">At run time, for the best performance, Copy Activity uses a value that is less than or equal to the value that you set.</span></span>

```json
"activities":[  
    {
        "name": "Sample copy activity",
        "description": "",
        "type": "Copy",
        "inputs": [{ "name": "InputDataset" }],
        "outputs": [{ "name": "OutputDataset" }],
        "typeProperties": {
            "source": {
                "type": "BlobSource",
            },
            "sink": {
                "type": "AzureDataLakeStoreSink"
            },
            "parallelCopies": 8
        }
    }
]
```
<span data-ttu-id="663f9-183">Pontos a serem observados:</span><span class="sxs-lookup"><span data-stu-id="663f9-183">Points to note:</span></span>

* <span data-ttu-id="663f9-184">Quando você copia dados entre repositórios baseados em arquivo, **parallelCopies** determina o paralelismo no nível de arquivo.</span><span class="sxs-lookup"><span data-stu-id="663f9-184">When you copy data between file-based stores, the **parallelCopies** determine the parallelism at the file level.</span></span> <span data-ttu-id="663f9-185">O agrupamento em um único arquivo aconteceria abaixo de modo automático e transparente, sendo projetado para usar o tamanho da parte mais adequado para um determinado tipo de repositório de dados de modo a carregar dados de modo paralelo e ortogonal em parallelCopies.</span><span class="sxs-lookup"><span data-stu-id="663f9-185">The chunking within a single file would happen underneath automatically and transparently, and it's designed to use the best suitable chunk size for a given source data store type to load data in parallel and orthogonal to parallelCopies.</span></span> <span data-ttu-id="663f9-186">O número real de cópias paralelas que o serviço de movimentação de dados usa para a operação de cópia no tempo de execução não é superior ao número de arquivos existentes.</span><span class="sxs-lookup"><span data-stu-id="663f9-186">The actual number of parallel copies the data movement service uses for the copy operation at run time is no more than the number of files you have.</span></span> <span data-ttu-id="663f9-187">Se o comportamento da cópia for **mergeFile**, a Atividade de Cópia não poderá aproveitar o paralelismo no nível de arquivo.</span><span class="sxs-lookup"><span data-stu-id="663f9-187">If the copy behavior is **mergeFile**, Copy Activity cannot take advantage of file-level parallelism.</span></span>
* <span data-ttu-id="663f9-188">Quando você especificar um valor para a propriedade **parallelCopies** , considere o aumento de carga para seus armazenamentos de dados da origem e do coletor, e para o gateway, se for uma cópia híbrida.</span><span class="sxs-lookup"><span data-stu-id="663f9-188">When you specify a value for the **parallelCopies** property, consider the load increase on your source and sink data stores, and to gateway if it is a hybrid copy.</span></span> <span data-ttu-id="663f9-189">Isso ocorre especialmente quando você tem várias atividades ou execuções simultâneas das mesmas atividades executadas em relação ao mesmo armazenamento de dados.</span><span class="sxs-lookup"><span data-stu-id="663f9-189">This happens especially when you have multiple activities or concurrent runs of the same activities that run against the same data store.</span></span> <span data-ttu-id="663f9-190">Se você perceber que o armazenamento de dados ou o Gateway está sobrecarregado com a carga, diminua o valor **parallelCopies** para aliviá-la.</span><span class="sxs-lookup"><span data-stu-id="663f9-190">If you notice that either the data store or Gateway is overwhelmed with the load, decrease the **parallelCopies** value to relieve the load.</span></span>
* <span data-ttu-id="663f9-191">Quando você copia dados de armazenamentos que não são baseados em arquivos para os armazenamentos que são, o serviço de movimentação de dados ignora a propriedade **parallelCopies** .</span><span class="sxs-lookup"><span data-stu-id="663f9-191">When you copy data from stores that are not file-based to stores that are file-based, the data movement service ignores the **parallelCopies** property.</span></span> <span data-ttu-id="663f9-192">Mesmo se o paralelismo for especificado, ele não será aplicado neste caso.</span><span class="sxs-lookup"><span data-stu-id="663f9-192">Even if parallelism is specified, it's not applied in this case.</span></span>

> [!NOTE]
> <span data-ttu-id="663f9-193">Você deve usar o Gateway de Gerenciamento de Dados versão 1.11 ou posterior para utilizar o recurso **parallelCopies** quando faz uma cópia híbrida.</span><span class="sxs-lookup"><span data-stu-id="663f9-193">You must use Data Management Gateway version 1.11 or later to use the **parallelCopies** feature when you do a hybrid copy.</span></span>
>
>

<span data-ttu-id="663f9-194">Para usar melhor essas duas propriedades e para melhorar a taxa de transferência de movimentação de dados, consulte os [casos de uso de exemplo](#case-study-use-parallel-copy).</span><span class="sxs-lookup"><span data-stu-id="663f9-194">To better use these two properties, and to enhance your data movement throughput, see the [sample use cases](#case-study-use-parallel-copy).</span></span> <span data-ttu-id="663f9-195">Você não precisa configurar **parallelCopies** para aproveitar o comportamento padrão.</span><span class="sxs-lookup"><span data-stu-id="663f9-195">You don't need to configure **parallelCopies** to take advantage of the default behavior.</span></span> <span data-ttu-id="663f9-196">Se você configurar e **parallelCopies** for muito pequeno, várias DMUs de nuvem poderão não ser totalmente utilizadas.</span><span class="sxs-lookup"><span data-stu-id="663f9-196">If you do configure and **parallelCopies** is too small, multiple cloud DMUs might not be fully utilized.</span></span>  

### <a name="billing-impact"></a><span data-ttu-id="663f9-197">Impacto de cobrança</span><span class="sxs-lookup"><span data-stu-id="663f9-197">Billing impact</span></span>
<span data-ttu-id="663f9-198">É **importante** lembrar que você é cobrado com base no tempo total da operação de cópia.</span><span class="sxs-lookup"><span data-stu-id="663f9-198">It's **important** to remember that you are charged based on the total time of the copy operation.</span></span> <span data-ttu-id="663f9-199">Se um trabalho de cópia costumava levar uma hora com a unidade de nuvem e agora leva 15 minutos com quatro unidades de nuvem, a fatura geral fica quase igual.</span><span class="sxs-lookup"><span data-stu-id="663f9-199">If a copy job used to take one hour with one cloud unit and now it takes 15 minutes with four cloud units, the overall bill remains almost the same.</span></span> <span data-ttu-id="663f9-200">Por exemplo, você usa quatro unidades de nuvem.</span><span class="sxs-lookup"><span data-stu-id="663f9-200">For example, you use four cloud units.</span></span> <span data-ttu-id="663f9-201">A primeira unidade de nuvem gasta 10 minutos, a segunda, 10 minutos, a terceira, 5 minutos e a quarta, 5 minutos, tudo em uma execução da Atividade de Cópia.</span><span class="sxs-lookup"><span data-stu-id="663f9-201">The first cloud unit spends 10 minutes, the second one, 10 minutes, the third one, 5 minutes, and the fourth one, 5 minutes, all in one Copy Activity run.</span></span> <span data-ttu-id="663f9-202">Você é cobrado pelo tempo de cópia total (movimentação de dados), que é de 10 + 10 + 5 + 5 = 30 minutos.</span><span class="sxs-lookup"><span data-stu-id="663f9-202">You are charged for the total copy (data movement) time, which is 10 + 10 + 5 + 5 = 30 minutes.</span></span> <span data-ttu-id="663f9-203">Usar **parallelCopies** não afeta a cobrança.</span><span class="sxs-lookup"><span data-stu-id="663f9-203">Using **parallelCopies** does not affect billing.</span></span>

## <a name="staged-copy"></a><span data-ttu-id="663f9-204">Cópia em etapas</span><span class="sxs-lookup"><span data-stu-id="663f9-204">Staged copy</span></span>
<span data-ttu-id="663f9-205">Ao copiar dados de um armazenamento de dados de origem para um armazenamento de dados do coletor, você pode escolher usar um armazenamento de Blobs como um armazenamento de preparação provisório.</span><span class="sxs-lookup"><span data-stu-id="663f9-205">When you copy data from a source data store to a sink data store, you might choose to use Blob storage as an interim staging store.</span></span> <span data-ttu-id="663f9-206">Esse preparo é especialmente útil nos seguintes casos:</span><span class="sxs-lookup"><span data-stu-id="663f9-206">Staging is especially useful in the following cases:</span></span>

1. <span data-ttu-id="663f9-207">**Você deseja ingerir dados de vários armazenamentos de dados no SQL Data Warehouse via PolyBase**.</span><span class="sxs-lookup"><span data-stu-id="663f9-207">**You want to ingest data from various data stores into SQL Data Warehouse via PolyBase**.</span></span> <span data-ttu-id="663f9-208">O SQL Data Warehouse usa o PolyBase como um mecanismo de alta taxa de transferência para carregar uma grande quantidade de dados no SQL Data Warehouse.</span><span class="sxs-lookup"><span data-stu-id="663f9-208">SQL Data Warehouse uses PolyBase as a high-throughput mechanism to load a large amount of data into SQL Data Warehouse.</span></span> <span data-ttu-id="663f9-209">No entanto, os dados de origem devem estar no armazenamento de Blobs e devem atender a critérios adicionais.</span><span class="sxs-lookup"><span data-stu-id="663f9-209">However, the source data must be in Blob storage, and it must meet additional criteria.</span></span> <span data-ttu-id="663f9-210">Quando você carrega dados de um armazenamento de dados diferente do armazenamento de Blobs, pode ativar a cópia dos dados por meio do armazenamento de Blobs de preparo intermediário.</span><span class="sxs-lookup"><span data-stu-id="663f9-210">When you load data from a data store other than Blob storage, you can activate data copying via interim staging Blob storage.</span></span> <span data-ttu-id="663f9-211">Nesse caso, o Data Factory executa as transformações de dados necessárias para garantir que eles atenderão aos requisitos do PolyBase.</span><span class="sxs-lookup"><span data-stu-id="663f9-211">In that case, Data Factory performs the required data transformations to ensure that it meets the requirements of PolyBase.</span></span> <span data-ttu-id="663f9-212">Em seguida, ele usa o PolyBase para carregar os dados no SQL Data Warehouse.</span><span class="sxs-lookup"><span data-stu-id="663f9-212">Then it uses PolyBase to load data into SQL Data Warehouse.</span></span> <span data-ttu-id="663f9-213">Para ver mais detalhes, confira [Usar o PolyBase para carregar dados para o Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse).</span><span class="sxs-lookup"><span data-stu-id="663f9-213">For more details, see [Use PolyBase to load data into Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse).</span></span> <span data-ttu-id="663f9-214">Para ver um passo a passo com um caso de uso, veja [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md) (Carregar 1 TB no SQL Data Warehouse do Azure em menos de 15 minutos com o Azure Data Factory).</span><span class="sxs-lookup"><span data-stu-id="663f9-214">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>
2. <span data-ttu-id="663f9-215">**Às vezes, leva algum tempo para realizar a movimentação de dados híbridos (ou seja, copiar entre um armazenamento de dados local e um armazenamento de dados de nuvem) em uma conexão de rede lenta**.</span><span class="sxs-lookup"><span data-stu-id="663f9-215">**Sometimes it takes a while to perform a hybrid data movement (that is, to copy between an on-premises data store and a cloud data store) over a slow network connection**.</span></span> <span data-ttu-id="663f9-216">Para melhorar o desempenho, você pode compactar os dados locais para que leve menos tempo mover os dados para o armazenamento de dados de preparo na nuvem.</span><span class="sxs-lookup"><span data-stu-id="663f9-216">To improve performance, you can compress the data on-premises so that it takes less time to move data to the staging data store in the cloud.</span></span> <span data-ttu-id="663f9-217">Em seguida, você pode descompactar os dados no armazenamento de preparo antes de carregá-lo no armazenamento de dados de destino.</span><span class="sxs-lookup"><span data-stu-id="663f9-217">Then you can decompress the data in the staging store before you load it into the destination data store.</span></span>
3. <span data-ttu-id="663f9-218">**Você não deseja abrir portas diferentes da porta 80 e da porta 443 em seu firewall, devido às políticas corporativas de TI**.</span><span class="sxs-lookup"><span data-stu-id="663f9-218">**You don't want to open ports other than port 80 and port 443 in your firewall, because of corporate IT policies**.</span></span> <span data-ttu-id="663f9-219">Por exemplo, quando você copia dados de um armazenamento de dados local para um coletor do Banco de Dados SQL ou um coletor do SQL Data Warehouse, precisa ativar a comunicação de saída TCP na porta 1433 para o firewall do Windows e o firewall corporativo.</span><span class="sxs-lookup"><span data-stu-id="663f9-219">For example, when you copy data from an on-premises data store to an Azure SQL Database sink or an Azure SQL Data Warehouse sink, you need to activate outbound TCP communication on port 1433 for both the Windows firewall and your corporate firewall.</span></span> <span data-ttu-id="663f9-220">Nesse cenário, aproveite o gateway para primeiro copiar os dados para uma instância de preparo do Armazenamento de Blobs via HTTP ou HTTPS na porta 443.</span><span class="sxs-lookup"><span data-stu-id="663f9-220">In this scenario, take advantage of the gateway to first copy data to a Blob storage staging instance over HTTP or HTTPS on port 443.</span></span> <span data-ttu-id="663f9-221">Em seguida, carregue os dados no Banco de Dados SQL ou no SQL Data Warehouse a partir do preparo do armazenamento de Blobs.</span><span class="sxs-lookup"><span data-stu-id="663f9-221">Then, load the data into SQL Database or SQL Data Warehouse from Blob storage staging.</span></span> <span data-ttu-id="663f9-222">Nesse fluxo, você não precisa habilitar a porta 1433.</span><span class="sxs-lookup"><span data-stu-id="663f9-222">In this flow, you don't need to enable port 1433.</span></span>

### <a name="how-staged-copy-works"></a><span data-ttu-id="663f9-223">Como funciona a cópia em etapas</span><span class="sxs-lookup"><span data-stu-id="663f9-223">How staged copy works</span></span>
<span data-ttu-id="663f9-224">Quando você ativa o recurso de preparo, primeiro os dados são copiados do armazenamento de dados de origem para o armazenamento de dados de preparo (traga seu próprio).</span><span class="sxs-lookup"><span data-stu-id="663f9-224">When you activate the staging feature, first the data is copied from the source data store to the staging data store (bring your own).</span></span> <span data-ttu-id="663f9-225">Em seguida, os dados são copiados do armazenamento de dados de preparo para o armazenamento de dados do coletor.</span><span class="sxs-lookup"><span data-stu-id="663f9-225">Next, the data is copied from the staging data store to the sink data store.</span></span> <span data-ttu-id="663f9-226">O Data Factory gerencia automaticamente o fluxo de dois estágios para você.</span><span class="sxs-lookup"><span data-stu-id="663f9-226">Data Factory automatically manages the two-stage flow for you.</span></span> <span data-ttu-id="663f9-227">O Data Factory também limpa os dados temporários do armazenamento de preparo após a movimentação de dados ser concluída.</span><span class="sxs-lookup"><span data-stu-id="663f9-227">Data Factory also cleans up temporary data from the staging storage after the data movement is complete.</span></span>

<span data-ttu-id="663f9-228">No cenário de cópia de nuvem (origem e coletor estão na nuvem), o gateway não é usado.</span><span class="sxs-lookup"><span data-stu-id="663f9-228">In the cloud copy scenario (both source and sink data stores are in the cloud), gateway is not used.</span></span> <span data-ttu-id="663f9-229">O serviço Data Factory executa as operações de cópia.</span><span class="sxs-lookup"><span data-stu-id="663f9-229">The Data Factory service performs the copy operations.</span></span>

![Cópia em etapas: cenário de nuvem](media/data-factory-copy-activity-performance/staged-copy-cloud-scenario.png)

<span data-ttu-id="663f9-231">No cenário de cópia híbrida, (fonte local e coletor na nuvem), o gateway move os dados do armazenamento de dados de origem para um armazenamento de dados de preparo.</span><span class="sxs-lookup"><span data-stu-id="663f9-231">In the hybrid copy scenario (source is on-premises and sink is in the cloud), the gateway moves data from the source data store to a staging data store.</span></span> <span data-ttu-id="663f9-232">O serviço Data Factory também move os dados do armazenamento de dados de preparo para o armazenamento de dados do coletor.</span><span class="sxs-lookup"><span data-stu-id="663f9-232">Data Factory service moves data from the staging data store to the sink data store.</span></span> <span data-ttu-id="663f9-233">Copiar os dados de um armazenamento de dados de nuvem para um armazenamento de dados local por meio do preparo também é possível com o fluxo invertido.</span><span class="sxs-lookup"><span data-stu-id="663f9-233">Copying data from a cloud data store to an on-premises data store via staging also is supported with the reversed flow.</span></span>

![Cópia em etapas: cenário híbrido](media/data-factory-copy-activity-performance/staged-copy-hybrid-scenario.png)

<span data-ttu-id="663f9-235">Quando você ativa o movimento de dados usando um armazenamento de preparo, pode especificar se deseja que os dados sejam compactados antes de mover os dados do armazenamento de dados de origem para um armazenamento de dados de preparo ou provisório, em seguida, descompactados antes de mover os dados de um armazenamento de preparo ou provisório para o armazenamento de dados do coletor.</span><span class="sxs-lookup"><span data-stu-id="663f9-235">When you activate data movement by using a staging store, you can specify whether you want the data to be compressed before moving data from the source data store to an interim or staging data store, and then decompressed before moving data from an interim or staging data store to the sink data store.</span></span>

<span data-ttu-id="663f9-236">Atualmente, não é possível copiar dados entre dois armazenamentos de dados locais usando um armazenamento de preparo.</span><span class="sxs-lookup"><span data-stu-id="663f9-236">Currently, you can't copy data between two on-premises data stores by using a staging store.</span></span> <span data-ttu-id="663f9-237">Esperamos que essa opção esteja disponível em breve.</span><span class="sxs-lookup"><span data-stu-id="663f9-237">We expect this option to be available soon.</span></span>

### <a name="configuration"></a><span data-ttu-id="663f9-238">Configuração</span><span class="sxs-lookup"><span data-stu-id="663f9-238">Configuration</span></span>
<span data-ttu-id="663f9-239">Configure a definição **enableStaging** na Atividade de Cópia para especificar se deseja que os dados sejam preparados no Armazenamento de Blobs do Azure antes de carregá-los em um armazenamento de dados de destino.</span><span class="sxs-lookup"><span data-stu-id="663f9-239">Configure the **enableStaging** setting in Copy Activity to specify whether you want the data to be staged in Blob storage before you load it into a destination data store.</span></span> <span data-ttu-id="663f9-240">Quando você definir **enableStaging** para TRUE, especifique as propriedades adicionais listadas na tabela a seguir.</span><span class="sxs-lookup"><span data-stu-id="663f9-240">When you set **enableStaging** to TRUE, specify the additional properties listed in the next table.</span></span> <span data-ttu-id="663f9-241">Se não tiver um, também precisará criar um Armazenamento do Azure ou um serviço vinculado de assinatura de acesso compartilhado do Armazenamento para o preparo.</span><span class="sxs-lookup"><span data-stu-id="663f9-241">If you don’t have one, you also need to create an Azure Storage or Storage shared access signature-linked service for staging.</span></span>

| <span data-ttu-id="663f9-242">Propriedade</span><span class="sxs-lookup"><span data-stu-id="663f9-242">Property</span></span> | <span data-ttu-id="663f9-243">Descrição</span><span class="sxs-lookup"><span data-stu-id="663f9-243">Description</span></span> | <span data-ttu-id="663f9-244">Valor padrão</span><span class="sxs-lookup"><span data-stu-id="663f9-244">Default value</span></span> | <span data-ttu-id="663f9-245">Obrigatório</span><span class="sxs-lookup"><span data-stu-id="663f9-245">Required</span></span> |
| --- | --- | --- | --- |
| <span data-ttu-id="663f9-246">**enableStaging**</span><span class="sxs-lookup"><span data-stu-id="663f9-246">**enableStaging**</span></span> |<span data-ttu-id="663f9-247">Especifique se você deseja copiar os dados por meio de um armazenamento de preparo provisório.</span><span class="sxs-lookup"><span data-stu-id="663f9-247">Specify whether you want to copy data via an interim staging store.</span></span> |<span data-ttu-id="663f9-248">Falso</span><span class="sxs-lookup"><span data-stu-id="663f9-248">False</span></span> |<span data-ttu-id="663f9-249">Não</span><span class="sxs-lookup"><span data-stu-id="663f9-249">No</span></span> |
| <span data-ttu-id="663f9-250">**linkedServiceName**</span><span class="sxs-lookup"><span data-stu-id="663f9-250">**linkedServiceName**</span></span> |<span data-ttu-id="663f9-251">Especifique o nome de um serviço vinculado [AzureStorage](data-factory-azure-blob-connector.md#azure-storage-linked-service) ou [AzureStorageSas](data-factory-azure-blob-connector.md#azure-storage-sas-linked-service), que se refere à instância do Armazenamento que você usa como um armazenamento de preparo provisório.</span><span class="sxs-lookup"><span data-stu-id="663f9-251">Specify the name of an [AzureStorage](data-factory-azure-blob-connector.md#azure-storage-linked-service) or [AzureStorageSas](data-factory-azure-blob-connector.md#azure-storage-sas-linked-service) linked service, which refers to the instance of Storage that you use as an interim staging store.</span></span> <br/><br/> <span data-ttu-id="663f9-252">Você não pode usar o Armazenamento com uma assinatura de acesso compartilhado para carregar dados no SQL Data Warehouse via PolyBase.</span><span class="sxs-lookup"><span data-stu-id="663f9-252">You cannot use Storage with a shared access signature to load data into SQL Data Warehouse via PolyBase.</span></span> <span data-ttu-id="663f9-253">Pode usar em todos os outros cenários.</span><span class="sxs-lookup"><span data-stu-id="663f9-253">You can use it in all other scenarios.</span></span> |<span data-ttu-id="663f9-254">N/D</span><span class="sxs-lookup"><span data-stu-id="663f9-254">N/A</span></span> |<span data-ttu-id="663f9-255">Sim, quando **enableStaging** está definido para TRUE</span><span class="sxs-lookup"><span data-stu-id="663f9-255">Yes, when **enableStaging** is set to TRUE</span></span> |
| <span data-ttu-id="663f9-256">**path**</span><span class="sxs-lookup"><span data-stu-id="663f9-256">**path**</span></span> |<span data-ttu-id="663f9-257">Especifique o caminho do armazenamento de Blobs que você deseja que contenha os dados preparados.</span><span class="sxs-lookup"><span data-stu-id="663f9-257">Specify the Blob storage path that you want to contain the staged data.</span></span> <span data-ttu-id="663f9-258">Se você não fornecer um caminho, o serviço criará um contêiner para armazenar os dados temporários.</span><span class="sxs-lookup"><span data-stu-id="663f9-258">If you do not provide a path, the service creates a container to store temporary data.</span></span> <br/><br/> <span data-ttu-id="663f9-259">Especifique um caminho somente se você usar o Armazenamento com uma assinatura de acesso compartilhado ou precisar que os dados temporários fiquem em um local específico.</span><span class="sxs-lookup"><span data-stu-id="663f9-259">Specify a path only if you use Storage with a shared access signature, or you require temporary data to be in a specific location.</span></span> |<span data-ttu-id="663f9-260">N/D</span><span class="sxs-lookup"><span data-stu-id="663f9-260">N/A</span></span> |<span data-ttu-id="663f9-261">Não</span><span class="sxs-lookup"><span data-stu-id="663f9-261">No</span></span> |
| <span data-ttu-id="663f9-262">**enableCompression**</span><span class="sxs-lookup"><span data-stu-id="663f9-262">**enableCompression**</span></span> |<span data-ttu-id="663f9-263">Especifica se os dados devem ser compactados antes de serem copiados para o destino.</span><span class="sxs-lookup"><span data-stu-id="663f9-263">Specifies whether data should be compressed before it is copied to the destination.</span></span> <span data-ttu-id="663f9-264">Essa configuração reduz o volume de dados que são transferidos.</span><span class="sxs-lookup"><span data-stu-id="663f9-264">This setting reduces the volume of data being transferred.</span></span> |<span data-ttu-id="663f9-265">Falso</span><span class="sxs-lookup"><span data-stu-id="663f9-265">False</span></span> |<span data-ttu-id="663f9-266">Não</span><span class="sxs-lookup"><span data-stu-id="663f9-266">No</span></span> |

<span data-ttu-id="663f9-267">Aqui está um exemplo de definição da Atividade de Cópia com as propriedades descritas na tabela anterior:</span><span class="sxs-lookup"><span data-stu-id="663f9-267">Here's a sample definition of Copy Activity with the properties that are described in the preceding table:</span></span>

```json
"activities":[  
{
    "name": "Sample copy activity",
    "type": "Copy",
    "inputs": [{ "name": "OnpremisesSQLServerInput" }],
    "outputs": [{ "name": "AzureSQLDBOutput" }],
    "typeProperties": {
        "source": {
            "type": "SqlSource",
        },
        "sink": {
            "type": "SqlSink"
        },
        "enableStaging": true,
        "stagingSettings": {
            "linkedServiceName": "MyStagingBlob",
            "path": "stagingcontainer/path",
            "enableCompression": true
        }
    }
}
]
```

### <a name="billing-impact"></a><span data-ttu-id="663f9-268">Impacto de cobrança</span><span class="sxs-lookup"><span data-stu-id="663f9-268">Billing impact</span></span>
<span data-ttu-id="663f9-269">Você é cobrado com base em duas etapas: duração da cópia e tipo de cópia.</span><span class="sxs-lookup"><span data-stu-id="663f9-269">You are charged based on two steps: copy duration and copy type.</span></span>

* <span data-ttu-id="663f9-270">Quando você usa o preparo durante uma cópia de nuvem (copiar dados de um armazenamento de dados de nuvem para outro armazenamento de dados de nuvem), é cobrado pela [soma da duração da cópia das etapas 1 e 2] x [preço unitário da cópia de nuvem].</span><span class="sxs-lookup"><span data-stu-id="663f9-270">When you use staging during a cloud copy (copying data from a cloud data store to another cloud data store), you are charged the [sum of copy duration for step 1 and step 2] x [cloud copy unit price].</span></span>
* <span data-ttu-id="663f9-271">Quando você usa o preparo durante uma cópia híbrida (copiar dados de um armazenamento de dados local para um armazenamento de dados de nuvem), é cobrado pela [duração da cópia híbrida] x [preço unitário da cópia híbrida] + [duração da cópia de nuvem] x [preço unitário da cópia de nuvem].</span><span class="sxs-lookup"><span data-stu-id="663f9-271">When you use staging during a hybrid copy (copying data from an on-premises data store to a cloud data store), you are charged for [hybrid copy duration] x [hybrid copy unit price] + [cloud copy duration] x [cloud copy unit price].</span></span>

## <a name="performance-tuning-steps"></a><span data-ttu-id="663f9-272">Etapas de ajuste do desempenho</span><span class="sxs-lookup"><span data-stu-id="663f9-272">Performance tuning steps</span></span>
<span data-ttu-id="663f9-273">Sugerimos que você realize estas etapas para ajustar o desempenho do serviço Data Factory com a Atividade de Cópia:</span><span class="sxs-lookup"><span data-stu-id="663f9-273">We suggest that you take these steps to tune the performance of your Data Factory service with Copy Activity:</span></span>

1. <span data-ttu-id="663f9-274">**Estabelecer uma linha de base**.</span><span class="sxs-lookup"><span data-stu-id="663f9-274">**Establish a baseline**.</span></span> <span data-ttu-id="663f9-275">Durante a fase de desenvolvimento, teste seu pipeline com a Atividade de Cópia em relação a um exemplo de dados representativo.</span><span class="sxs-lookup"><span data-stu-id="663f9-275">During the development phase, test your pipeline by using Copy Activity against a representative data sample.</span></span> <span data-ttu-id="663f9-276">Você pode usar o [modelo de divisão](data-factory-scheduling-and-execution.md) do Data Factory para limitar a quantidade de dados com a qual trabalha.</span><span class="sxs-lookup"><span data-stu-id="663f9-276">You can use the Data Factory [slicing model](data-factory-scheduling-and-execution.md) to limit the amount of data you work with.</span></span>

   <span data-ttu-id="663f9-277">Colete o tempo de execução e as características do desempenho usando o **Monitoramento e Gerenciamento de Aplicativos**.</span><span class="sxs-lookup"><span data-stu-id="663f9-277">Collect execution time and performance characteristics by using the **Monitoring and Management App**.</span></span> <span data-ttu-id="663f9-278">Escolha **Monitorar e Gerenciar** na página inicial do Data Factory.</span><span class="sxs-lookup"><span data-stu-id="663f9-278">Choose **Monitor & Manage** on your Data Factory home page.</span></span> <span data-ttu-id="663f9-279">Na exibição em árvore, escolha o **conjunto de dados de saída**.</span><span class="sxs-lookup"><span data-stu-id="663f9-279">In the tree view, choose the **output dataset**.</span></span> <span data-ttu-id="663f9-280">Na lista **Janelas de Atividade** escolha a execução Atividade de Cópia.</span><span class="sxs-lookup"><span data-stu-id="663f9-280">In the **Activity Windows** list, choose the Copy Activity run.</span></span> <span data-ttu-id="663f9-281">**Janelas de Atividade** listam a duração da Atividade de Cópia e o tamanho dos dados copiados.</span><span class="sxs-lookup"><span data-stu-id="663f9-281">**Activity Windows** lists the Copy Activity duration and the size of the data that's copied.</span></span> <span data-ttu-id="663f9-282">A taxa de transferência é listada no **Gerenciador de Janelas de Atividades**.</span><span class="sxs-lookup"><span data-stu-id="663f9-282">The throughput is listed in **Activity Window Explorer**.</span></span> <span data-ttu-id="663f9-283">Para saber mais sobre o aplicativo, consulte [Monitorar e gerenciar os pipelines do Azure Data Factory usando o Monitoramento e Gerenciamento de Aplicativos](data-factory-monitor-manage-app.md).</span><span class="sxs-lookup"><span data-stu-id="663f9-283">To learn more about the app, see [Monitor and manage Azure Data Factory pipelines by using the Monitoring and Management App](data-factory-monitor-manage-app.md).</span></span>

   ![Detalhes da execução da atividade](./media/data-factory-copy-activity-performance/mmapp-activity-run-details.png)

   <span data-ttu-id="663f9-285">Posteriormente neste artigo, você pode comparar o desempenho e a configuração do seu cenário com a [referência de desempenho](#performance-reference) da Atividade de Cópia de nossos testes.</span><span class="sxs-lookup"><span data-stu-id="663f9-285">Later in the article, you can compare the performance and configuration of your scenario to Copy Activity’s [performance reference](#performance-reference) from our tests.</span></span>
2. <span data-ttu-id="663f9-286">**Diagnosticar e otimizar o desempenho**.</span><span class="sxs-lookup"><span data-stu-id="663f9-286">**Diagnose and optimize performance**.</span></span> <span data-ttu-id="663f9-287">Se o desempenho observado não atender às suas expectativas, você precisará identificar os afunilamentos do desempenho.</span><span class="sxs-lookup"><span data-stu-id="663f9-287">If the performance you observe doesn't meet your expectations, you need to identify performance bottlenecks.</span></span> <span data-ttu-id="663f9-288">Em seguida, otimize o desempenho para remover ou reduzir o efeito dos afunilamentos.</span><span class="sxs-lookup"><span data-stu-id="663f9-288">Then, optimize performance to remove or reduce the effect of bottlenecks.</span></span> <span data-ttu-id="663f9-289">Uma descrição completa do diagnóstico de desempenho está além do escopo deste artigo, mas aqui estão algumas considerações comuns:</span><span class="sxs-lookup"><span data-stu-id="663f9-289">A full description of performance diagnosis is beyond the scope of this article, but here are some common considerations:</span></span>

   * <span data-ttu-id="663f9-290">Recursos de desempenho:</span><span class="sxs-lookup"><span data-stu-id="663f9-290">Performance features:</span></span>
     * [<span data-ttu-id="663f9-291">Cópia paralela</span><span class="sxs-lookup"><span data-stu-id="663f9-291">Parallel copy</span></span>](#parallel-copy)
     * [<span data-ttu-id="663f9-292">Unidades de movimentação de dados de nuvem</span><span class="sxs-lookup"><span data-stu-id="663f9-292">Cloud data movement units</span></span>](#cloud-data-movement-units)
     * [<span data-ttu-id="663f9-293">Cópia em etapas</span><span class="sxs-lookup"><span data-stu-id="663f9-293">Staged copy</span></span>](#staged-copy)
     * [<span data-ttu-id="663f9-294">Escalabilidade do Gateway de Gerenciamento de Dados</span><span class="sxs-lookup"><span data-stu-id="663f9-294">Data Management Gateway scalability</span></span>](data-factory-data-management-gateway-high-availability-scalability.md)
   * [<span data-ttu-id="663f9-295">Gateway de gerenciamento de dados</span><span class="sxs-lookup"><span data-stu-id="663f9-295">Data Management Gateway</span></span>](#considerations-for-data-management-gateway)
   * [<span data-ttu-id="663f9-296">Fonte</span><span class="sxs-lookup"><span data-stu-id="663f9-296">Source</span></span>](#considerations-for-the-source)
   * [<span data-ttu-id="663f9-297">Coletor</span><span class="sxs-lookup"><span data-stu-id="663f9-297">Sink</span></span>](#considerations-for-the-sink)
   * [<span data-ttu-id="663f9-298">Serialização e desserialização</span><span class="sxs-lookup"><span data-stu-id="663f9-298">Serialization and deserialization</span></span>](#considerations-for-serialization-and-deserialization)
   * [<span data-ttu-id="663f9-299">Compactação</span><span class="sxs-lookup"><span data-stu-id="663f9-299">Compression</span></span>](#considerations-for-compression)
   * [<span data-ttu-id="663f9-300">Mapeamento de coluna</span><span class="sxs-lookup"><span data-stu-id="663f9-300">Column mapping</span></span>](#considerations-for-column-mapping)
   * [<span data-ttu-id="663f9-301">Outras considerações</span><span class="sxs-lookup"><span data-stu-id="663f9-301">Other considerations</span></span>](#other-considerations)
3. <span data-ttu-id="663f9-302">**Expanda a configuração para todo o conjunto de dados**.</span><span class="sxs-lookup"><span data-stu-id="663f9-302">**Expand the configuration to your entire data set**.</span></span> <span data-ttu-id="663f9-303">Quando você estiver satisfeito com os resultados e o desempenho da execução, poderá expandir a definição e o período ativo do pipeline para cobrir todo o conjunto de dados.</span><span class="sxs-lookup"><span data-stu-id="663f9-303">When you're satisfied with the execution results and performance, you can expand the definition and pipeline active period to cover your entire data set.</span></span>

## <a name="considerations-for-data-management-gateway"></a><span data-ttu-id="663f9-304">Considerações do Gateway de Gerenciamento de Dados</span><span class="sxs-lookup"><span data-stu-id="663f9-304">Considerations for Data Management Gateway</span></span>
<span data-ttu-id="663f9-305">**Configuração do gateway**: é recomendável usar um computador dedicado para hospedar o Gateway de Gerenciamento de Dados.</span><span class="sxs-lookup"><span data-stu-id="663f9-305">**Gateway setup**: We recommend that you use a dedicated machine to host Data Management Gateway.</span></span> <span data-ttu-id="663f9-306">Confira [Considerações para o uso do Gateway de Gerenciamento de Dados](data-factory-data-management-gateway.md#considerations-for-using-gateway).</span><span class="sxs-lookup"><span data-stu-id="663f9-306">See [Considerations for using Data Management Gateway](data-factory-data-management-gateway.md#considerations-for-using-gateway).</span></span>  

<span data-ttu-id="663f9-307">**Monitoramento e escala vertical/horizontal do gateway**: um único gateway lógico com um ou mais nós de gateway pode atender a várias execuções de Atividade de Cópia ao mesmo tempo.</span><span class="sxs-lookup"><span data-stu-id="663f9-307">**Gateway monitoring and scale-up/out**: A single logical gateway with one or more gateway nodes can serve multiple Copy Activity runs at the same time concurrently.</span></span> <span data-ttu-id="663f9-308">Você pode exibir um instantâneo quase em tempo real da utilização de recursos (CPU, memória, rede (entrada/saída) etc). em um computador de gateway, bem como o número de trabalhos simultâneos em execução versus o limite no portal do Azure, confira [Monitorar o gateway no portal](data-factory-data-management-gateway.md#monitor-gateway-in-the-portal).</span><span class="sxs-lookup"><span data-stu-id="663f9-308">You can view near-real time snapshot of resource utilization (CPU, memory, network(in/out), etc.) on a gateway machine as well as the number of concurrent jobs running versus limit in the Azure portal, see [Monitor gateway in the portal](data-factory-data-management-gateway.md#monitor-gateway-in-the-portal).</span></span> <span data-ttu-id="663f9-309">Caso haja uma grande necessidade de movimentação de dados híbrida, seja com um grande número de execuções simultâneas da atividade de cópia, seja com um grande volume de dados a serem copiados, considere a [escala vertical ou horizontal do gateway](data-factory-data-management-gateway-high-availability-scalability.md#scale-considerations) de modo a melhor utilizar seus recursos ou provisionar mais recursos a fim de fortalecer a cópia.</span><span class="sxs-lookup"><span data-stu-id="663f9-309">If you have heavy need on hybrid data movement either with large number of concurrent copy activity runs or with large volume of data to copy, consider to [scale up or scale out gateway](data-factory-data-management-gateway-high-availability-scalability.md#scale-considerations) so as to better utilize your resource or to provision more resource to empower copy.</span></span> 

## <a name="considerations-for-the-source"></a><span data-ttu-id="663f9-310">Considerações para a origem</span><span class="sxs-lookup"><span data-stu-id="663f9-310">Considerations for the source</span></span>
### <a name="general"></a><span data-ttu-id="663f9-311">Geral</span><span class="sxs-lookup"><span data-stu-id="663f9-311">General</span></span>
<span data-ttu-id="663f9-312">Verifique se o armazenamento de dados subjacente não está sobrecarregado por outras cargas de trabalho em execução nele ou em relação a ele.</span><span class="sxs-lookup"><span data-stu-id="663f9-312">Be sure that the underlying data store is not overwhelmed by other workloads that are running on or against it.</span></span>

<span data-ttu-id="663f9-313">Para os armazenamentos de dados da Microsoft, confira os [tópicos de monitoramento e ajuste](#performance-reference) específicos dos armazenamentos de dados que o ajudam a entender as características de desempenho do armazenamento, minimizar os tempos de resposta e maximizar a taxa de transferência.</span><span class="sxs-lookup"><span data-stu-id="663f9-313">For Microsoft data stores, see [monitoring and tuning topics](#performance-reference) that are specific to data stores, and help you understand data store performance characteristics, minimize response times, and maximize throughput.</span></span>

<span data-ttu-id="663f9-314">Se você copiar os dados do armazenamento de Blobs para o SQL Data Warehouse, considere o uso do **PolyBase** para melhorar o desempenho.</span><span class="sxs-lookup"><span data-stu-id="663f9-314">If you copy data from Blob storage to SQL Data Warehouse, consider using **PolyBase** to boost performance.</span></span> <span data-ttu-id="663f9-315">Veja [Usar o PolyBase para carregar dados para o Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) para ver mais detalhes.</span><span class="sxs-lookup"><span data-stu-id="663f9-315">See [Use PolyBase to load data into Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) for details.</span></span> <span data-ttu-id="663f9-316">Para ver um passo a passo com um caso de uso, veja [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md) (Carregar 1 TB no SQL Data Warehouse do Azure em menos de 15 minutos com o Azure Data Factory).</span><span class="sxs-lookup"><span data-stu-id="663f9-316">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>

### <a name="file-based-data-stores"></a><span data-ttu-id="663f9-317">Armazenamentos de dados baseado em arquivo</span><span class="sxs-lookup"><span data-stu-id="663f9-317">File-based data stores</span></span>
<span data-ttu-id="663f9-318">*(Inclui o armazenamento de Blobs, Data Lake Store, Amazon S3, sistemas de arquivos locais e HDFS local)*</span><span class="sxs-lookup"><span data-stu-id="663f9-318">*(Includes Blob storage, Data Lake Store, Amazon S3, on-premises file systems, and on-premises HDFS)*</span></span>

* <span data-ttu-id="663f9-319">**Média de tamanho do arquivo e contagem de arquivos**: a Atividade de Cópia transfere os dados um arquivo por vez.</span><span class="sxs-lookup"><span data-stu-id="663f9-319">**Average file size and file count**: Copy Activity transfers data one file at a time.</span></span> <span data-ttu-id="663f9-320">Com a mesma quantidade de dados a ser movidos, a taxa de transferência geral será menor se os dados consistirem em muitos arquivos pequenos, em vez de alguns arquivos grandes, devido à fase de inicialização de cada arquivo.</span><span class="sxs-lookup"><span data-stu-id="663f9-320">With the same amount of data to be moved, the overall throughput is lower if the data consists of many small files rather than a few large files due to the bootstrap phase for each file.</span></span> <span data-ttu-id="663f9-321">Portanto, se possível, combine arquivos pequenos em arquivos maiores para obter uma maior taxa de transferência.</span><span class="sxs-lookup"><span data-stu-id="663f9-321">Therefore, if possible, combine small files into larger files to gain higher throughput.</span></span>
* <span data-ttu-id="663f9-322">**Formato de arquivo e compactação**: para ver outras maneiras de melhorar o desempenho, consulte as seções [Considerações da serialização e desserialização](#considerations-for-serialization-and-deserialization) e [Considerações da compactação](#considerations-for-compression).</span><span class="sxs-lookup"><span data-stu-id="663f9-322">**File format and compression**: For more ways to improve performance, see the [Considerations for serialization and deserialization](#considerations-for-serialization-and-deserialization) and [Considerations for compression](#considerations-for-compression) sections.</span></span>
* <span data-ttu-id="663f9-323">Além disso, para o cenário do **sistema de arquivos local** no qual o uso do **Gateway de Gerenciamento de Dados** é obrigatório, consulte a seção [Considerações do Gateway de Gerenciamento de Dados](#considerations-for-data-management-gateway).</span><span class="sxs-lookup"><span data-stu-id="663f9-323">For the **on-premises file system** scenario, in which **Data Management Gateway** is required, see the [Considerations for Data Management Gateway](#considerations-for-data-management-gateway) section.</span></span>

### <a name="relational-data-stores"></a><span data-ttu-id="663f9-324">Armazenamentos de dados relacionais</span><span class="sxs-lookup"><span data-stu-id="663f9-324">Relational data stores</span></span>
<span data-ttu-id="663f9-325">*(Inclui o Banco de Dados SQL, SQL Data Warehouse, Amazon Redshift, bancos de dados do SQL Server e bancos de dados Oracle, MySQL, DB2, Teradata, Sybase e PostgreSQL, etc.)*</span><span class="sxs-lookup"><span data-stu-id="663f9-325">*(Includes SQL Database; SQL Data Warehouse; Amazon Redshift; SQL Server databases; and Oracle, MySQL, DB2, Teradata, Sybase, and PostgreSQL databases, etc.)*</span></span>

* <span data-ttu-id="663f9-326">**Padrão de dados**: o esquema da tabela afeta a taxa de transferência de cópia.</span><span class="sxs-lookup"><span data-stu-id="663f9-326">**Data pattern**: Your table schema affects copy throughput.</span></span> <span data-ttu-id="663f9-327">Um tamanho de linha grande oferece um desempenho melhor do que o tamanho de linha pequeno para copiar a mesma quantidade de dados.</span><span class="sxs-lookup"><span data-stu-id="663f9-327">A large row size gives you a better performance than small row size, to copy the same amount of data.</span></span> <span data-ttu-id="663f9-328">O motivo é que o banco de dados pode recuperar de forma eficiente menos lotes de dados que contêm menos linhas.</span><span class="sxs-lookup"><span data-stu-id="663f9-328">The reason is that the database can more efficiently retrieve fewer batches of data that contain fewer rows.</span></span>
* <span data-ttu-id="663f9-329">**Consulta ou procedimento armazenado**: otimize a lógica da consulta ou do procedimento armazenado especificado na origem da Atividade de Cópia para buscar os dados com mais eficiência.</span><span class="sxs-lookup"><span data-stu-id="663f9-329">**Query or stored procedure**: Optimize the logic of the query or stored procedure you specify in the Copy Activity source to fetch data more efficiently.</span></span>
* <span data-ttu-id="663f9-330">Para os **bancos de dados relacionais locais**, como o SQL Server e Oracle, que exigem o uso do **Gateway de Gerenciamento de Dados**, consulte a seção [Considerações do Gateway de Gerenciamento de Dados](#considerations-on-data-management-gateway).</span><span class="sxs-lookup"><span data-stu-id="663f9-330">For **on-premises relational databases**, such as SQL Server and Oracle, which require the use of **Data Management Gateway**, see the [Considerations for Data Management Gateway](#considerations-on-data-management-gateway) section.</span></span>

## <a name="considerations-for-the-sink"></a><span data-ttu-id="663f9-331">Considerações do coletor</span><span class="sxs-lookup"><span data-stu-id="663f9-331">Considerations for the sink</span></span>
### <a name="general"></a><span data-ttu-id="663f9-332">Geral</span><span class="sxs-lookup"><span data-stu-id="663f9-332">General</span></span>
<span data-ttu-id="663f9-333">Verifique se o armazenamento de dados subjacente não está sobrecarregado por outras cargas de trabalho em execução nele ou em relação a ele.</span><span class="sxs-lookup"><span data-stu-id="663f9-333">Be sure that the underlying data store is not overwhelmed by other workloads that are running on or against it.</span></span>

<span data-ttu-id="663f9-334">Para os armazenamentos de dados da Microsoft, consulte os [tópicos de monitoramento e ajuste](#performance-reference) específicos dos armazenamentos de dados.</span><span class="sxs-lookup"><span data-stu-id="663f9-334">For Microsoft data stores, refer to [monitoring and tuning topics](#performance-reference) that are specific to data stores.</span></span> <span data-ttu-id="663f9-335">Esses tópicos o ajudarão a entender as características de desempenho do armazenamento de dados, minimizar os tempos de resposta e maximizar a taxa de transferência.</span><span class="sxs-lookup"><span data-stu-id="663f9-335">These topics can help you understand data store performance characteristics and how to minimize response times and maximize throughput.</span></span>

<span data-ttu-id="663f9-336">Se você estiver copiando os dados do **armazenamento de Blobs** para o **SQL Data Warehouse**, considere usar o **PolyBase** para melhorar o desempenho.</span><span class="sxs-lookup"><span data-stu-id="663f9-336">If you are copying data from **Blob storage** to **SQL Data Warehouse**, consider using **PolyBase** to boost performance.</span></span> <span data-ttu-id="663f9-337">Veja [Usar o PolyBase para carregar dados para o Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) para ver mais detalhes.</span><span class="sxs-lookup"><span data-stu-id="663f9-337">See [Use PolyBase to load data into Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) for details.</span></span> <span data-ttu-id="663f9-338">Para ver um passo a passo com um caso de uso, veja [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md) (Carregar 1 TB no SQL Data Warehouse do Azure em menos de 15 minutos com o Azure Data Factory).</span><span class="sxs-lookup"><span data-stu-id="663f9-338">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>

### <a name="file-based-data-stores"></a><span data-ttu-id="663f9-339">Armazenamentos de dados baseado em arquivo</span><span class="sxs-lookup"><span data-stu-id="663f9-339">File-based data stores</span></span>
<span data-ttu-id="663f9-340">*(Inclui o armazenamento de Blobs, Data Lake Store, Amazon S3, sistemas de arquivos locais e HDFS local)*</span><span class="sxs-lookup"><span data-stu-id="663f9-340">*(Includes Blob storage, Data Lake Store, Amazon S3, on-premises file systems, and on-premises HDFS)*</span></span>

* <span data-ttu-id="663f9-341">**Comportamento da cópia**: se você copiar os dados de um armazenamento de dados diferente com base em arquivos, a Atividade de Cópia terá três opções por meio da propriedade **copyBehavior**.</span><span class="sxs-lookup"><span data-stu-id="663f9-341">**Copy behavior**: If you copy data from a different file-based data store, Copy Activity has three options via the **copyBehavior** property.</span></span> <span data-ttu-id="663f9-342">Preserva a hierarquia, nivela a hierarquia ou mescla os arquivos.</span><span class="sxs-lookup"><span data-stu-id="663f9-342">It preserves hierarchy, flattens hierarchy, or merges files.</span></span> <span data-ttu-id="663f9-343">Preservar ou nivelar a hierarquia tem pouca ou nenhuma sobrecarga de desempenho, mas mesclar os arquivos faz aumentar a sobrecarga dele.</span><span class="sxs-lookup"><span data-stu-id="663f9-343">Either preserving or flattening hierarchy has little or no performance overhead, but merging files causes performance overhead to increase.</span></span>
* <span data-ttu-id="663f9-344">**Formato do arquivo e compactação**: consulte as seções [Considerações da serialização e desserialização](#considerations-for-serialization-and-deserialization) e [Considerações da compactação](#considerations-for-compression) para ver outras maneiras de melhorar o desempenho.</span><span class="sxs-lookup"><span data-stu-id="663f9-344">**File format and compression**: See the [Considerations for serialization and deserialization](#considerations-for-serialization-and-deserialization) and [Considerations for compression](#considerations-for-compression) sections for more ways to improve performance.</span></span>
* <span data-ttu-id="663f9-345">**Armazenamento de Blobs**: atualmente, o armazenamento de Blobs apenas suporta os blobs de blocos da transferência de dados otimizada e da taxa de transferência.</span><span class="sxs-lookup"><span data-stu-id="663f9-345">**Blob storage**: Currently, Blob storage supports only block blobs for optimized data transfer and throughput.</span></span>
* <span data-ttu-id="663f9-346">Para os cenários dos **sistemas de arquivos locais** que exigem o uso do **Gateway de Gerenciamento de Dados**, consulte a seção [Considerações do Gateway de Gerenciamento de Dados](#considerations-for-data-management-gateway).</span><span class="sxs-lookup"><span data-stu-id="663f9-346">For **on-premises file systems** scenarios that require the use of **Data Management Gateway**, see the [Considerations for Data Management Gateway](#considerations-for-data-management-gateway) section.</span></span>

### <a name="relational-data-stores"></a><span data-ttu-id="663f9-347">Armazenamentos de dados relacionais</span><span class="sxs-lookup"><span data-stu-id="663f9-347">Relational data stores</span></span>
<span data-ttu-id="663f9-348">*(Inclui o Banco de Dados SQL, SQL Data Warehouse, bancos de dados do SQL Server e bancos de dados Oracle)*</span><span class="sxs-lookup"><span data-stu-id="663f9-348">*(Includes SQL Database, SQL Data Warehouse, SQL Server databases, and Oracle databases)*</span></span>

* <span data-ttu-id="663f9-349">**Comportamento de cópia**: dependendo das propriedades configuradas para **sqlSink**, a Atividade de Cópia gravará os dados no banco de dados de destino de maneiras diferentes.</span><span class="sxs-lookup"><span data-stu-id="663f9-349">**Copy behavior**: Depending on the properties you've set for **sqlSink**, Copy Activity writes data to the destination database in different ways.</span></span>
  * <span data-ttu-id="663f9-350">Por padrão, o serviço de movimentação de dados usa a API de Cópia em Massa para inserir dados no modo de anexação, o que fornece o melhor desempenho.</span><span class="sxs-lookup"><span data-stu-id="663f9-350">By default, the data movement service uses the Bulk Copy API to insert data in append mode, which provides the best performance.</span></span>
  * <span data-ttu-id="663f9-351">Se você configurar um procedimento armazenado no coletor, o banco de dados aplicará os dados uma linha por vez, em vez de um carregamento em massa.</span><span class="sxs-lookup"><span data-stu-id="663f9-351">If you configure a stored procedure in the sink, the database applies the data one row at a time instead of as a bulk load.</span></span> <span data-ttu-id="663f9-352">O desempenho cai significativamente.</span><span class="sxs-lookup"><span data-stu-id="663f9-352">Performance drops significantly.</span></span> <span data-ttu-id="663f9-353">Se o conjunto de dados for grande, quando aplicável, considere trocar para usar a propriedade **sqlWriterCleanupScript** .</span><span class="sxs-lookup"><span data-stu-id="663f9-353">If your data set is large, when applicable, consider switching to using the **sqlWriterCleanupScript** property.</span></span>
  * <span data-ttu-id="663f9-354">Se você configurar a propriedade **sqlWriterCleanupScript** para cada execução da Atividade de Cópia, o serviço irá disparar o script, então, usará a API de Cópia em Massa para inserir os dados.</span><span class="sxs-lookup"><span data-stu-id="663f9-354">If you configure the **sqlWriterCleanupScript** property for each Copy Activity run, the service triggers the script, and then you use the Bulk Copy API to insert the data.</span></span> <span data-ttu-id="663f9-355">Por exemplo, para substituir a tabela inteira pelos dados mais recentes, você pode especificar um script para excluir primeiro todos os registros, antes de carregar em massa os novos dados da origem.</span><span class="sxs-lookup"><span data-stu-id="663f9-355">For example, to overwrite the entire table with the latest data, you can specify a script to first delete all records before bulk-loading the new data from the source.</span></span>
* <span data-ttu-id="663f9-356">**Padrão de dados e tamanho do lote**:</span><span class="sxs-lookup"><span data-stu-id="663f9-356">**Data pattern and batch size**:</span></span>
  * <span data-ttu-id="663f9-357">O esquema da tabela afeta a taxa de transferência da cópia.</span><span class="sxs-lookup"><span data-stu-id="663f9-357">Your table schema affects copy throughput.</span></span> <span data-ttu-id="663f9-358">Para copiar a mesma quantidade de dados, um tamanho de linha grande fornece um desempenho melhor do que um tamanho de linha pequeno, pois o banco de dados poderá confirmar com mais eficiência menos lotes de dados.</span><span class="sxs-lookup"><span data-stu-id="663f9-358">To copy the same amount of data, a large row size gives you better performance than a small row size because the database can more efficiently commit fewer batches of data.</span></span>
  * <span data-ttu-id="663f9-359">A Atividade de Cópia insere dados em uma série de lotes.</span><span class="sxs-lookup"><span data-stu-id="663f9-359">Copy Activity inserts data in a series of batches.</span></span> <span data-ttu-id="663f9-360">Você pode definir o número de linhas em um lote usando a propriedade **writeBatchSize** .</span><span class="sxs-lookup"><span data-stu-id="663f9-360">You can set the number of rows in a batch by using the **writeBatchSize** property.</span></span> <span data-ttu-id="663f9-361">Se os dados tiverem linhas pequenas, você poderá definir a propriedade **writeBatchSize** com um valor mais alto para aproveitar uma sobrecarga de lote menor e uma taxa de transferência maior.</span><span class="sxs-lookup"><span data-stu-id="663f9-361">If your data has small rows, you can set the **writeBatchSize** property with a higher value to benefit from lower batch overhead and higher throughput.</span></span> <span data-ttu-id="663f9-362">Se o tamanho da linha de dados for grande, tenha cuidado ao aumentar **writeBatchSize**.</span><span class="sxs-lookup"><span data-stu-id="663f9-362">If the row size of your data is large, be careful when you increase **writeBatchSize**.</span></span> <span data-ttu-id="663f9-363">Um valor alto pode levar a uma falha de cópia causada pela sobrecarga do banco de dados.</span><span class="sxs-lookup"><span data-stu-id="663f9-363">A high value might lead to a copy failure caused by overloading the database.</span></span>
* <span data-ttu-id="663f9-364">Para os **bancos de dados relacionais locais**, como o SQL Server e o Oracle, que exigem o uso do **Gateway de Gerenciamento de Dados**, consulte a seção [Considerações do Gateway de Gerenciamento de Dados](#considerations-for-data-management-gateway).</span><span class="sxs-lookup"><span data-stu-id="663f9-364">For **on-premises relational databases** like SQL Server and Oracle, which require the use of **Data Management Gateway**, see the [Considerations for Data Management Gateway](#considerations-for-data-management-gateway) section.</span></span>

### <a name="nosql-stores"></a><span data-ttu-id="663f9-365">Repositórios NoSQL</span><span class="sxs-lookup"><span data-stu-id="663f9-365">NoSQL stores</span></span>
<span data-ttu-id="663f9-366">*(Inclui o Armazenamento de tabelas e o Azure Cosmos DB)*</span><span class="sxs-lookup"><span data-stu-id="663f9-366">*(Includes Table storage and Azure Cosmos DB )*</span></span>

* <span data-ttu-id="663f9-367">Para o **Armazenamento de Tabelas**:</span><span class="sxs-lookup"><span data-stu-id="663f9-367">For **Table storage**:</span></span>
  * <span data-ttu-id="663f9-368">**Partição**: gravar os dados em partições intercaladas diminui drasticamente o desempenho.</span><span class="sxs-lookup"><span data-stu-id="663f9-368">**Partition**: Writing data to interleaved partitions dramatically degrades performance.</span></span> <span data-ttu-id="663f9-369">Classifique os dados de origem por chave de partição para que os dados sejam inseridos com eficiência em partições sucessivas ou ajuste a lógica para gravar os dados em uma única partição.</span><span class="sxs-lookup"><span data-stu-id="663f9-369">Sort your source data by partition key so that the data is inserted efficiently into one partition after another, or adjust the logic to write the data to a single partition.</span></span>
* <span data-ttu-id="663f9-370">Para o **Azure Cosmos DB**:</span><span class="sxs-lookup"><span data-stu-id="663f9-370">For **Azure Cosmos DB**:</span></span>
  * <span data-ttu-id="663f9-371">**Tamanho do lote**: a propriedade **writeBatchSize** define o número de solicitações paralelas para o serviço Azure Cosmos DB para criar documentos.</span><span class="sxs-lookup"><span data-stu-id="663f9-371">**Batch size**: The **writeBatchSize** property sets the number of parallel requests to the Azure Cosmos DB service to create documents.</span></span> <span data-ttu-id="663f9-372">Você pode esperar um melhor desempenho ao aumentar **writeBatchSize** porque mais solicitações paralelas são enviadas para o Azure Cosmos DB.</span><span class="sxs-lookup"><span data-stu-id="663f9-372">You can expect better performance when you increase **writeBatchSize** because more parallel requests are sent to Azure Cosmos DB.</span></span> <span data-ttu-id="663f9-373">No entanto, fique atento à limitação ao gravar no Azure Cosmos DB (a mensagem de erro é "A taxa de solicitação é grande").</span><span class="sxs-lookup"><span data-stu-id="663f9-373">However, watch for throttling when you write to Azure Cosmos DB (the error message is "Request rate is large").</span></span> <span data-ttu-id="663f9-374">Vários fatores podem causar a limitação, incluindo o tamanho do documento, o número de termos nos documentos e a política de indexação da coleção de destino.</span><span class="sxs-lookup"><span data-stu-id="663f9-374">Various factors can cause throttling, including document size, the number of terms in the documents, and the target collection's indexing policy.</span></span> <span data-ttu-id="663f9-375">Para obter uma maior taxa de transferência de cópia, considere usar uma coleção melhor, por exemplo, S3.</span><span class="sxs-lookup"><span data-stu-id="663f9-375">To achieve higher copy throughput, consider using a better collection, for example, S3.</span></span>

## <a name="considerations-for-serialization-and-deserialization"></a><span data-ttu-id="663f9-376">Considerações da serialização e desserialização</span><span class="sxs-lookup"><span data-stu-id="663f9-376">Considerations for serialization and deserialization</span></span>
<span data-ttu-id="663f9-377">A serialização e desserialização podem acontecer quando o conjunto de dados de entrada ou saída é um arquivo.</span><span class="sxs-lookup"><span data-stu-id="663f9-377">Serialization and deserialization can occur when your input data set or output data set is a file.</span></span> <span data-ttu-id="663f9-378">Consulte [Formatos de arquivo e compactação com suporte](data-factory-supported-file-and-compression-formats.md) para obter detalhes sobre os formatos de arquivo com suporte na Atividade de Cópia.</span><span class="sxs-lookup"><span data-stu-id="663f9-378">See [Supported file and compression formats](data-factory-supported-file-and-compression-formats.md) with details on supported file formats by Copy Activity.</span></span>

<span data-ttu-id="663f9-379">**Comportamento da cópia**:</span><span class="sxs-lookup"><span data-stu-id="663f9-379">**Copy behavior**:</span></span>

* <span data-ttu-id="663f9-380">Copiar arquivos entre os armazenamentos de dados baseados em arquivos:</span><span class="sxs-lookup"><span data-stu-id="663f9-380">Copying files between file-based data stores:</span></span>
  * <span data-ttu-id="663f9-381">Quando os conjuntos de dados de entrada e saída têm a mesma ou nenhuma configuração do formato de arquivo, o serviço de movimentação de dados executa uma cópia binária sem nenhuma serialização ou desserialização.</span><span class="sxs-lookup"><span data-stu-id="663f9-381">When input and output data sets both have the same or no file format settings, the data movement service executes a binary copy without any serialization or deserialization.</span></span> <span data-ttu-id="663f9-382">Você vê uma maior taxa de transferência em comparação com o cenário no qual as configurações do formato de arquivo de origem e do coletor são diferentes entre si.</span><span class="sxs-lookup"><span data-stu-id="663f9-382">You see a higher throughput compared to the scenario, in which the source and sink file format settings are different from each other.</span></span>
  * <span data-ttu-id="663f9-383">Quando os conjuntos de dados de entrada e saída estão no formato de texto e apenas o tipo de codificação é diferente, o serviço de movimentação de dados apenas faz a conversão da codificação.</span><span class="sxs-lookup"><span data-stu-id="663f9-383">When input and output data sets both are in text format and only the encoding type is different, the data movement service only does encoding conversion.</span></span> <span data-ttu-id="663f9-384">Ele não faz nenhuma serialização e desserialização, causando uma sobrecarga do desempenho em comparação com uma cópia binária.</span><span class="sxs-lookup"><span data-stu-id="663f9-384">It doesn't do any serialization and deserialization, which causes some performance overhead compared to a binary copy.</span></span>
  * <span data-ttu-id="663f9-385">Quando os conjuntos de dados de entrada e saída têm formatos de arquivo diferentes ou configurações diferentes, como delimitadores, o serviço de movimentação de dados desserializa os dados de origem para transmitir, transformar, então, serializa no formato de saída desejado.</span><span class="sxs-lookup"><span data-stu-id="663f9-385">When input and output data sets both have different file formats or different configurations, like delimiters, the data movement service deserializes source data to stream, transform, and then serialize it into the output format you indicated.</span></span> <span data-ttu-id="663f9-386">Essa operação resulta em uma sobrecarga do desempenho mais significativa em comparação com outros cenários.</span><span class="sxs-lookup"><span data-stu-id="663f9-386">This operation results in a much more significant performance overhead compared to other scenarios.</span></span>
* <span data-ttu-id="663f9-387">Quando você copia os arquivos de/para um armazenamento de dados que não é baseado em arquivos (por exemplo, de um armazenamento baseado em arquivos para um armazenamento relacional), a etapa da serialização ou desserialização é necessária.</span><span class="sxs-lookup"><span data-stu-id="663f9-387">When you copy files to/from a data store that is not file-based (for example, from a file-based store to a relational store), the serialization or deserialization step is required.</span></span> <span data-ttu-id="663f9-388">Essa etapa resulta em uma sobrecarga significativa do desempenho.</span><span class="sxs-lookup"><span data-stu-id="663f9-388">This step results in significant performance overhead.</span></span>

<span data-ttu-id="663f9-389">**Formato de arquivo**: O formato de arquivo escolhido pode afetar o desempenho da cópia.</span><span class="sxs-lookup"><span data-stu-id="663f9-389">**File format**: The file format you choose might affect copy performance.</span></span> <span data-ttu-id="663f9-390">Por exemplo, Avro é um formato binário compacto que armazena metadados com dados.</span><span class="sxs-lookup"><span data-stu-id="663f9-390">For example, Avro is a compact binary format that stores metadata with data.</span></span> <span data-ttu-id="663f9-391">Ele tem um amplo suporte no ecossistema do Hadoop para processar e consultar.</span><span class="sxs-lookup"><span data-stu-id="663f9-391">It has broad support in the Hadoop ecosystem for processing and querying.</span></span> <span data-ttu-id="663f9-392">No entanto, o Avro é mais caro para a serialização e a desserialização, o que resulta em uma menor taxa de transferência de cópia em comparação com o formato de texto.</span><span class="sxs-lookup"><span data-stu-id="663f9-392">However, Avro is more expensive for serialization and deserialization, which results in lower copy throughput compared to text format.</span></span> <span data-ttu-id="663f9-393">Faça a escolha do formato de arquivo em todo o fluxo de processamento de forma global.</span><span class="sxs-lookup"><span data-stu-id="663f9-393">Make your choice of file format throughout the processing flow holistically.</span></span> <span data-ttu-id="663f9-394">Inicie com qual forma os dados são armazenados, os armazenamentos dos dados de origem ou a extração dos sistemas externos; o melhor formato para o armazenamento, processamento analítico e consulta; e em qual formato os dados devem ser exportados para os data marts para as ferramentas de relatório e visualização.</span><span class="sxs-lookup"><span data-stu-id="663f9-394">Start with what form the data is stored in, source data stores or to be extracted from external systems; the best format for storage, analytical processing, and querying; and in what format the data should be exported into data marts for reporting and visualization tools.</span></span> <span data-ttu-id="663f9-395">Às vezes, um formato de arquivo abaixo do ideal para o desempenho de leitura e gravação pode ser uma boa escolha ao considerar o processo analítico geral.</span><span class="sxs-lookup"><span data-stu-id="663f9-395">Sometimes a file format that is suboptimal for read and write performance might be a good choice when you consider the overall analytical process.</span></span>

## <a name="considerations-for-compression"></a><span data-ttu-id="663f9-396">Considerações da compactação</span><span class="sxs-lookup"><span data-stu-id="663f9-396">Considerations for compression</span></span>
<span data-ttu-id="663f9-397">Quando o conjunto de dados de entrada ou saída é um arquivo, você pode definir a Atividade de Cópia para executar a compactação ou a descompactação conforme grava os dados no destino.</span><span class="sxs-lookup"><span data-stu-id="663f9-397">When your input or output data set is a file, you can set Copy Activity to perform compression or decompression as it writes data to the destination.</span></span> <span data-ttu-id="663f9-398">Quando você escolher a compactação, faça uma compensação entre a entrada/saída (E/S) e a CPU.</span><span class="sxs-lookup"><span data-stu-id="663f9-398">When you choose compression, you make a tradeoff between input/output (I/O) and CPU.</span></span> <span data-ttu-id="663f9-399">Compactar os dados tem um custo extra nos recursos de computação.</span><span class="sxs-lookup"><span data-stu-id="663f9-399">Compressing the data costs extra in compute resources.</span></span> <span data-ttu-id="663f9-400">Mas, por sua vez, reduz a E/S da rede e o armazenamento.</span><span class="sxs-lookup"><span data-stu-id="663f9-400">But in return, it reduces network I/O and storage.</span></span> <span data-ttu-id="663f9-401">Dependendo de seus dados, você poderá ver um aumento na taxa de transferência geral da cópia.</span><span class="sxs-lookup"><span data-stu-id="663f9-401">Depending on your data, you may see a boost in overall copy throughput.</span></span>

<span data-ttu-id="663f9-402">**Codec**: a atividade de cópia suporta gzip, bzip2 e os tipos de compactação Deflate.</span><span class="sxs-lookup"><span data-stu-id="663f9-402">**Codec**: Copy Activity supports gzip, bzip2, and Deflate compression types.</span></span> <span data-ttu-id="663f9-403">O Azure HDInsight pode consumir todos os três tipos de processamento.</span><span class="sxs-lookup"><span data-stu-id="663f9-403">Azure HDInsight can consume all three types for processing.</span></span> <span data-ttu-id="663f9-404">Cada codec de compactação tem suas vantagens.</span><span class="sxs-lookup"><span data-stu-id="663f9-404">Each compression codec has advantages.</span></span> <span data-ttu-id="663f9-405">Por exemplo, o bzip2 tem a menor taxa de transferência de cópia, mas você obtém o melhor desempenho de consulta do Hive com o bzip2 porque pode dividi-lo para o processamento.</span><span class="sxs-lookup"><span data-stu-id="663f9-405">For example, bzip2 has the lowest copy throughput, but you get the best Hive query performance with bzip2 because you can split it for processing.</span></span> <span data-ttu-id="663f9-406">O gzip é a opção mais equilibrada e é usado com mais frequência.</span><span class="sxs-lookup"><span data-stu-id="663f9-406">Gzip is the most balanced option, and it is used the most often.</span></span> <span data-ttu-id="663f9-407">Escolha o codec mais adequado para seu cenário completo.</span><span class="sxs-lookup"><span data-stu-id="663f9-407">Choose the codec that best suits your end-to-end scenario.</span></span>

<span data-ttu-id="663f9-408">**Nível**: você pode escolher entre duas opções para cada codec de compactação: compactado mais rápido e compactado ideal.</span><span class="sxs-lookup"><span data-stu-id="663f9-408">**Level**: You can choose from two options for each compression codec: fastest compressed and optimally compressed.</span></span> <span data-ttu-id="663f9-409">A opção compactada mais rápida compacta os dados o mais rapidamente possível, mesmo que o arquivo resultante não tenha uma compactação ideal.</span><span class="sxs-lookup"><span data-stu-id="663f9-409">The fastest compressed option compresses the data as quickly as possible, even if the resulting file is not optimally compressed.</span></span> <span data-ttu-id="663f9-410">A opção de compactação ideal leva mais tempo na compactação e produz uma quantidade mínima de dados.</span><span class="sxs-lookup"><span data-stu-id="663f9-410">The optimally compressed option spends more time on compression and yields a minimal amount of data.</span></span> <span data-ttu-id="663f9-411">Você pode testar as duas opções para qual fornece o melhor desempenho no seu caso.</span><span class="sxs-lookup"><span data-stu-id="663f9-411">You can test both options to see which provides better overall performance in your case.</span></span>

<span data-ttu-id="663f9-412">**Uma consideração**: para copiar uma grande quantidade de dados entre um armazenamento local e a nuvem, considere usar o armazenamento de blobs provisório com a compactação.</span><span class="sxs-lookup"><span data-stu-id="663f9-412">**A consideration**: To copy a large amount of data between an on-premises store and the cloud, consider using interim blob storage with compression.</span></span> <span data-ttu-id="663f9-413">Usar o armazenamento provisório é útil quando a largura de banda da rede corporativa e os serviços do Azure é o fator limitante e você deseja que os conjuntos de dados de entrada e saída estejam descompactados.</span><span class="sxs-lookup"><span data-stu-id="663f9-413">Using interim storage is helpful when the bandwidth of your corporate network and your Azure services is the limiting factor, and you want the input data set and output data set both to be in uncompressed form.</span></span> <span data-ttu-id="663f9-414">Mais especificamente, é possível dividir uma atividade de cópia única em duas atividades de cópia.</span><span class="sxs-lookup"><span data-stu-id="663f9-414">More specifically, you can break a single copy activity into two copy activities.</span></span> <span data-ttu-id="663f9-415">A primeira atividade de cópia copia da origem para um blob provisório ou de preparo no formato compactado.</span><span class="sxs-lookup"><span data-stu-id="663f9-415">The first copy activity copies from the source to an interim or staging blob in compressed form.</span></span> <span data-ttu-id="663f9-416">A segunda atividade de cópia copia os dados compactados a partir do preparo e descompacta enquanto grava no coletor.</span><span class="sxs-lookup"><span data-stu-id="663f9-416">The second copy activity copies the compressed data from staging, and then decompresses while it writes to the sink.</span></span>

## <a name="considerations-for-column-mapping"></a><span data-ttu-id="663f9-417">Considerações do mapeamento de coluna</span><span class="sxs-lookup"><span data-stu-id="663f9-417">Considerations for column mapping</span></span>
<span data-ttu-id="663f9-418">Você pode definir a propriedade **columnMappings** na Atividade de Cópia para mapear tudo ou um subconjunto de colunas de entrada para as colunas de saída.</span><span class="sxs-lookup"><span data-stu-id="663f9-418">You can set the **columnMappings** property in Copy Activity to map all or a subset of the input columns to the output columns.</span></span> <span data-ttu-id="663f9-419">Depois do serviço de movimentação de dados ler os dados de origem, ele precisa executar o mapeamento de coluna nos dados antes de gravar os dados no coletor.</span><span class="sxs-lookup"><span data-stu-id="663f9-419">After the data movement service reads the data from the source, it needs to perform column mapping on the data before it writes the data to the sink.</span></span> <span data-ttu-id="663f9-420">Esse processamento extra reduz a taxa de transferência de cópia.</span><span class="sxs-lookup"><span data-stu-id="663f9-420">This extra processing reduces copy throughput.</span></span>

<span data-ttu-id="663f9-421">Se o armazenamento de dados de origem for de consulta, por exemplo, for um armazenamento relacional como o Banco de Dados SQL ou o SQL Server, ou se for um armazenamento NoSQL, como o Armazenamento de tabelas ou o Azure Cosmos DB, considere enviar a filtragem da coluna por push e reordenar a lógica para a propriedade **query**, em vez de usar o mapeamento de coluna.</span><span class="sxs-lookup"><span data-stu-id="663f9-421">If your source data store is queryable, for example, if it's a relational store like SQL Database or SQL Server, or if it's a NoSQL store like Table storage or Azure Cosmos DB, consider pushing the column filtering and reordering logic to the **query** property instead of using column mapping.</span></span> <span data-ttu-id="663f9-422">Dessa forma, a projeção ocorrerá enquanto o serviço de movimentação de dados lê os dados no armazenamento de dados de origem, onde é muito mais eficiente.</span><span class="sxs-lookup"><span data-stu-id="663f9-422">This way, the projection occurs while the data movement service reads data from the source data store, where it is much more efficient.</span></span>

## <a name="other-considerations"></a><span data-ttu-id="663f9-423">Outras considerações</span><span class="sxs-lookup"><span data-stu-id="663f9-423">Other considerations</span></span>
<span data-ttu-id="663f9-424">Se o tamanho dos dados que você deseja copiar for grande, você poderá ajustar sua lógica de negócios para particionar ainda mais os dados usando o mecanismo de divisão no Data Factory.</span><span class="sxs-lookup"><span data-stu-id="663f9-424">If the size of data you want to copy is large, you can adjust your business logic to further partition the data using the slicing mechanism in Data Factory.</span></span> <span data-ttu-id="663f9-425">Em seguida, agende a Atividade de Cópia para ser executada com mais frequência para reduzir o tamanho dos dados para cada execução da Atividade.</span><span class="sxs-lookup"><span data-stu-id="663f9-425">Then, schedule Copy Activity to run more frequently to reduce the data size for each Copy Activity run.</span></span>

<span data-ttu-id="663f9-426">Tenha cuidado com o número de conjuntos de dados e atividades de cópia que requerem o Data Factory para conectar o mesmo armazenamento de dados ao mesmo tempo.</span><span class="sxs-lookup"><span data-stu-id="663f9-426">Be cautious about the number of data sets and copy activities requiring Data Factory to connector to the same data store at the same time.</span></span> <span data-ttu-id="663f9-427">Vários trabalhos de cópia simultâneos pode restringir um armazenamento de dados e levar a um desempenho reduzido, repetições internas do trabalho de cópia e, em alguns casos, falhas de execução.</span><span class="sxs-lookup"><span data-stu-id="663f9-427">Many concurrent copy jobs might throttle a data store and lead to degraded performance, copy job internal retries, and in some cases, execution failures.</span></span>

## <a name="sample-scenario-copy-from-an-on-premises-sql-server-to-blob-storage"></a><span data-ttu-id="663f9-428">Cenário de exemplo: copiar de um SQL Server local para o armazenamento de Blobs</span><span class="sxs-lookup"><span data-stu-id="663f9-428">Sample scenario: Copy from an on-premises SQL Server to Blob storage</span></span>
<span data-ttu-id="663f9-429">**Cenário:**um pipeline é criado para copiar os dados de um SQL Server local para um armazenamento de Blobs no formato CSV.</span><span class="sxs-lookup"><span data-stu-id="663f9-429">**Scenario**: A pipeline is built to copy data from an on-premises SQL Server to Blob storage in CSV format.</span></span> <span data-ttu-id="663f9-430">Para acelerar o trabalho de cópia, os arquivos CSV devem ser compactados no formato bzip2.</span><span class="sxs-lookup"><span data-stu-id="663f9-430">To make the copy job faster, the CSV files should be compressed into bzip2 format.</span></span>

<span data-ttu-id="663f9-431">**Análise e teste**: A taxa de transferência da Atividade de Cópia é menor que 2 MBps, que é muito mais lento do que o parâmetro de comparação de desempenho.</span><span class="sxs-lookup"><span data-stu-id="663f9-431">**Test and analysis**: The throughput of Copy Activity is less than 2 MBps, which is much slower than the performance benchmark.</span></span>

<span data-ttu-id="663f9-432">**Análise e ajuste do desempenho:**para solucionar o problema de desempenho, vejamos como os dados são processados e movidos.</span><span class="sxs-lookup"><span data-stu-id="663f9-432">**Performance analysis and tuning**: To troubleshoot the performance issue, let’s look at how the data is processed and moved.</span></span>

1. <span data-ttu-id="663f9-433">**Ler dados:**o Gateway abre uma conexão com o SQL Server e envia a consulta.</span><span class="sxs-lookup"><span data-stu-id="663f9-433">**Read data**: Gateway opens a connection to SQL Server and sends the query.</span></span> <span data-ttu-id="663f9-434">SQL Server responde enviando o fluxo de dados para o Gateway por meio da intranet.</span><span class="sxs-lookup"><span data-stu-id="663f9-434">SQL Server responds by sending the data stream to Gateway via the intranet.</span></span>
2. <span data-ttu-id="663f9-435">**Serializar e compactar dados**: o Gateway serializa o fluxo de dados para o formato CSV e compacta os dados em um fluxo bzip2.</span><span class="sxs-lookup"><span data-stu-id="663f9-435">**Serialize and compress data**: Gateway serializes the data stream to CSV format, and compresses the data to a bzip2 stream.</span></span>
3. <span data-ttu-id="663f9-436">**Gravar dados**: o Gateway carrega o fluxo bzip2 no armazenamento de Blobs via Internet.</span><span class="sxs-lookup"><span data-stu-id="663f9-436">**Write data**: Gateway uploads the bzip2 stream to Blob storage via the Internet.</span></span>

<span data-ttu-id="663f9-437">Como você pode ver, os dados estão sendo processados e movidos de forma sequencial e em fluxo: SQL Server > LAN > Gateway > WAN > armazenamento de Blobs.</span><span class="sxs-lookup"><span data-stu-id="663f9-437">As you can see, the data is being processed and moved in a streaming sequential manner: SQL Server > LAN > Gateway > WAN > Blob storage.</span></span> <span data-ttu-id="663f9-438">**O desempenho geral é limitado pela taxa de transferência mínima no pipeline**.</span><span class="sxs-lookup"><span data-stu-id="663f9-438">**The overall performance is gated by the minimum throughput across the pipeline**.</span></span>

![Fluxo de dados](./media/data-factory-copy-activity-performance/case-study-pic-1.png)

<span data-ttu-id="663f9-440">Um ou mais dos seguintes fatores pode causar o afunilamento do desempenho:</span><span class="sxs-lookup"><span data-stu-id="663f9-440">One or more of the following factors might cause the performance bottleneck:</span></span>

* <span data-ttu-id="663f9-441">**Origem:**o próprio SQL Server tem uma baixa taxa de transferência devido às cargas pesadas.</span><span class="sxs-lookup"><span data-stu-id="663f9-441">**Source**: SQL Server itself has low throughput because of heavy loads.</span></span>
* <span data-ttu-id="663f9-442">**Gateway de Gerenciamento de Dados**:</span><span class="sxs-lookup"><span data-stu-id="663f9-442">**Data Management Gateway**:</span></span>
  * <span data-ttu-id="663f9-443">**LAN**: o Gateway está localizado longe do computador do SQL Server e tem uma conexão de baixa largura de banda.</span><span class="sxs-lookup"><span data-stu-id="663f9-443">**LAN**: Gateway is located far from the SQL Server machine and has a low-bandwidth connection.</span></span>
  * <span data-ttu-id="663f9-444">**Gateway**: o Gateway atingiu suas limitações de carga para executar as seguintes operações:</span><span class="sxs-lookup"><span data-stu-id="663f9-444">**Gateway**: Gateway has reached its load limitations to perform the following operations:</span></span>
    * <span data-ttu-id="663f9-445">**Serialização**: serializar o fluxo de dados para o formato CSV tem a taxa de transferência lenta.</span><span class="sxs-lookup"><span data-stu-id="663f9-445">**Serialization**: Serializing the data stream to CSV format has slow throughput.</span></span>
    * <span data-ttu-id="663f9-446">**Compactação**: você escolheu um codec de compactação lenta (por exemplo, bzip2, que é 2.8 MBps com Core i7).</span><span class="sxs-lookup"><span data-stu-id="663f9-446">**Compression**: You chose a slow compression codec (for example, bzip2, which is 2.8 MBps with Core i7).</span></span>
  * <span data-ttu-id="663f9-447">**WAN**: a largura de banda entre a rede corporativa e os serviços do Azure é baixa (por exemplo, T1 = 1,544 kbps; T2 = 6,312 kbps).</span><span class="sxs-lookup"><span data-stu-id="663f9-447">**WAN**: The bandwidth between the corporate network and your Azure services is low (for example, T1 = 1,544 kbps; T2 = 6,312 kbps).</span></span>
* <span data-ttu-id="663f9-448">**Coletor**: o armazenamento de Blobs tem baixa taxa de transferência.</span><span class="sxs-lookup"><span data-stu-id="663f9-448">**Sink**: Blob storage has low throughput.</span></span> <span data-ttu-id="663f9-449">(Esse cenário é improvável porque seu SLA garante um mínimo de 60 MBps.)</span><span class="sxs-lookup"><span data-stu-id="663f9-449">(This scenario is unlikely because its SLA guarantees a minimum of 60 MBps.)</span></span>

<span data-ttu-id="663f9-450">Nesse caso, a compactação de dados bzip2 pode estar desacelerando todo o pipeline.</span><span class="sxs-lookup"><span data-stu-id="663f9-450">In this case, bzip2 data compression might be slowing down the entire pipeline.</span></span> <span data-ttu-id="663f9-451">Trocar para o codec de compactação gzip pode aliviar esse afunilamento.</span><span class="sxs-lookup"><span data-stu-id="663f9-451">Switching to a gzip compression codec might ease this bottleneck.</span></span>

## <a name="sample-scenarios-use-parallel-copy"></a><span data-ttu-id="663f9-452">Cenários de exemplo: usar cópia paralela</span><span class="sxs-lookup"><span data-stu-id="663f9-452">Sample scenarios: Use parallel copy</span></span>
<span data-ttu-id="663f9-453">**i cenário:** copiar 1.000 arquivos de 1 MB do sistema de arquivos local para o armazenamento de Blobs.</span><span class="sxs-lookup"><span data-stu-id="663f9-453">**Scenario I:** Copy 1,000 1-MB files from the on-premises file system to Blob storage.</span></span>

<span data-ttu-id="663f9-454">**Análise e ajuste do desempenho**: por exemplo, se você instalou o gateway em uma máquina com quatro núcleos, o Data Factory usará 16 cópias paralelas para mover os arquivos do sistema de arquivos para o Armazenamento de Blobs simultaneamente.</span><span class="sxs-lookup"><span data-stu-id="663f9-454">**Analysis and performance tuning**: For an example, if you have installed gateway on a quad core machine, Data Factory uses 16 parallel copies to move files from the file system to Blob storage concurrently.</span></span> <span data-ttu-id="663f9-455">Essa execução paralela deve resultar em alta taxa de transferência.</span><span class="sxs-lookup"><span data-stu-id="663f9-455">This parallel execution should result in high throughput.</span></span> <span data-ttu-id="663f9-456">Você também pode especificar explicitamente a contagem de cópias paralelas.</span><span class="sxs-lookup"><span data-stu-id="663f9-456">You also can explicitly specify the parallel copies count.</span></span> <span data-ttu-id="663f9-457">Ao copiar muitos arquivos pequenos, as cópias paralelas ajudam muito a taxa de transferência usando os recursos com mais eficiência.</span><span class="sxs-lookup"><span data-stu-id="663f9-457">When you copy many small files, parallel copies dramatically help throughput by using resources more effectively.</span></span>

![Cenário 1](./media/data-factory-copy-activity-performance/scenario-1.png)

<span data-ttu-id="663f9-459">**Cenário II**: copiar 20 blobs de 500 MB cada do armazenamento de Blobs para o Data Lake Store Analytics, em seguida, ajustar o desempenho.</span><span class="sxs-lookup"><span data-stu-id="663f9-459">**Scenario II**: Copy 20 blobs of 500 MB each from Blob storage to Data Lake Store Analytics, and then tune performance.</span></span>

<span data-ttu-id="663f9-460">**Análise e ajuste do desempenho**: nesse cenário, o Data Factory copia os dados do armazenamento de Blobs para o Data Lake Store usando as unidades de movimentação de dados de cópia única (**parallelCopies** definida para 1) e de nuvem única.</span><span class="sxs-lookup"><span data-stu-id="663f9-460">**Analysis and performance tuning**: In this scenario, Data Factory copies the data from Blob storage to Data Lake Store by using single-copy (**parallelCopies** set to 1) and single-cloud data movement units.</span></span> <span data-ttu-id="663f9-461">A taxa de transferência observada será semelhante à descrita na [seção de referência de desempenho](#performance-reference).</span><span class="sxs-lookup"><span data-stu-id="663f9-461">The throughput you observe will be close to that described in the [performance reference section](#performance-reference).</span></span>   

![Cenário 2](./media/data-factory-copy-activity-performance/scenario-2.png)

<span data-ttu-id="663f9-463">**Cenário III**: o tamanho de arquivo Individual é maior que dezenas de MBs e o volume total é grande.</span><span class="sxs-lookup"><span data-stu-id="663f9-463">**Scenario III**: Individual file size is greater than dozens of MBs and total volume is large.</span></span>

<span data-ttu-id="663f9-464">**Análise e ajuste do desempenho**: aumentar **parallelCopies** não resulta em um melhor desempenho da cópia devido às limitações de recursos de uma DMU de nuvem única.</span><span class="sxs-lookup"><span data-stu-id="663f9-464">**Analysis and performance turning**: Increasing **parallelCopies** doesn't result in better copy performance because of the resource limitations of a single-cloud DMU.</span></span> <span data-ttu-id="663f9-465">Em vez disso, você deve especificar mais DMUs de nuvem para obter mais recursos para realizar a movimentação de dados.</span><span class="sxs-lookup"><span data-stu-id="663f9-465">Instead, you should specify more cloud DMUs to get more resources to perform the data movement.</span></span> <span data-ttu-id="663f9-466">Não especifique um valor para a propriedade **parallelCopies** .</span><span class="sxs-lookup"><span data-stu-id="663f9-466">Do not specify a value for the **parallelCopies** property.</span></span> <span data-ttu-id="663f9-467">O Data Factory lida com o paralelismo para você.</span><span class="sxs-lookup"><span data-stu-id="663f9-467">Data Factory handles the parallelism for you.</span></span> <span data-ttu-id="663f9-468">Nesse caso, se você definir **cloudDataMovementUnits** para 4, ocorrerá uma taxa de transferência de mais ou menos quatro vezes.</span><span class="sxs-lookup"><span data-stu-id="663f9-468">In this case, if you set **cloudDataMovementUnits** to 4, a throughput of about four times occurs.</span></span>

![Cenário 3](./media/data-factory-copy-activity-performance/scenario-3.png)

## <a name="reference"></a><span data-ttu-id="663f9-470">Referência</span><span class="sxs-lookup"><span data-stu-id="663f9-470">Reference</span></span>
<span data-ttu-id="663f9-471">Aqui estão as referências de monitoramento e ajuste do desempenho para alguns dos armazenamentos de dados com suporte:</span><span class="sxs-lookup"><span data-stu-id="663f9-471">Here are performance monitoring and tuning references for some of the supported data stores:</span></span>

* <span data-ttu-id="663f9-472">Armazenamento do Azure (incluindo o armazenamento de Blobs e o armazenamento de Tabelas): [metas de escalabilidade do Armazenamento do Azure](../storage/common/storage-scalability-targets.md) e [Lista de verificação de escalabilidade e desempenho do Armazenamento do Azure](../storage/common/storage-performance-checklist.md)</span><span class="sxs-lookup"><span data-stu-id="663f9-472">Azure Storage (including Blob storage and Table storage): [Azure Storage scalability targets](../storage/common/storage-scalability-targets.md) and [Azure Storage performance and scalability checklist](../storage/common/storage-performance-checklist.md)</span></span>
* <span data-ttu-id="663f9-473">Banco de dados SQL do Azure: é possível [monitorar o desempenho](../sql-database/sql-database-single-database-monitor.md) e verificar o percentual DTU (unidade de transação do banco de dados)</span><span class="sxs-lookup"><span data-stu-id="663f9-473">Azure SQL Database: You can [monitor the performance](../sql-database/sql-database-single-database-monitor.md) and check the database transaction unit (DTU) percentage</span></span>
* <span data-ttu-id="663f9-474">SQL Data Warehouse do Azure: Sua capacidade é medida em unidades de data warehouse (DWUs); consulte [Gerenciar poder de computação no SQL Data Warehouse do Azure (Visão Geral)](../sql-data-warehouse/sql-data-warehouse-manage-compute-overview.md)</span><span class="sxs-lookup"><span data-stu-id="663f9-474">Azure SQL Data Warehouse: Its capability is measured in data warehouse units (DWUs); see [Manage compute power in Azure SQL Data Warehouse (Overview)](../sql-data-warehouse/sql-data-warehouse-manage-compute-overview.md)</span></span>
* <span data-ttu-id="663f9-475">Azure Cosmos DB: [níveis de desempenho no Azure Cosmos DB](../documentdb/documentdb-performance-levels.md)</span><span class="sxs-lookup"><span data-stu-id="663f9-475">Azure Cosmos DB: [Performance levels in Azure Cosmos DB](../documentdb/documentdb-performance-levels.md)</span></span>
* <span data-ttu-id="663f9-476">SQL Server local: [monitoramento e ajuste do desempenho](https://msdn.microsoft.com/library/ms189081.aspx)</span><span class="sxs-lookup"><span data-stu-id="663f9-476">On-premises SQL Server: [Monitor and tune for performance](https://msdn.microsoft.com/library/ms189081.aspx)</span></span>
* <span data-ttu-id="663f9-477">Servidor de arquivos local: [ajuste de desempenho para servidores de arquivos](https://msdn.microsoft.com/library/dn567661.aspx)</span><span class="sxs-lookup"><span data-stu-id="663f9-477">On-premises file server: [Performance tuning for file servers](https://msdn.microsoft.com/library/dn567661.aspx)</span></span>
