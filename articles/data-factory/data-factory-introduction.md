---
title: "Introdução ao Data Factory, um serviço de integração de dados | Microsoft Docs"
description: "Saiba o que é o Azure Data Factory: um serviço de integração de dados de nuvem que orquestra e automatiza a movimentação e a transformação dos dados."
keywords: "integração de dados, integração de dados de nuvem, o que é o azure data factory"
services: data-factory
documentationcenter: 
author: sharonlo101
manager: jhubbard
editor: monicar
ms.assetid: cec68cb5-ca0d-473b-8ae8-35de949a009e
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: get-started-article
ms.date: 08/14/2017
ms.author: shlo
ms.openlocfilehash: bc72c4d58b98f6521dbb7420a5d05a121b0ddbda
ms.sourcegitcommit: 50e23e8d3b1148ae2d36dad3167936b4e52c8a23
ms.translationtype: MT
ms.contentlocale: pt-BR
ms.lasthandoff: 08/18/2017
---
# <a name="introduction-to-azure-data-factory"></a><span data-ttu-id="44f21-104">Introdução à Fábrica de Dados do Azure</span><span class="sxs-lookup"><span data-stu-id="44f21-104">Introduction to Azure Data Factory</span></span> 
## <a name="what-is-azure-data-factory"></a><span data-ttu-id="44f21-105">O que é o Data Factory do Azure?</span><span class="sxs-lookup"><span data-stu-id="44f21-105">What is Azure Data Factory?</span></span>
<span data-ttu-id="44f21-106">No mundo de grandes volumes de dados, como os dados existentes são usados nos negócios?</span><span class="sxs-lookup"><span data-stu-id="44f21-106">In the world of big data, how is existing data leveraged in business?</span></span> <span data-ttu-id="44f21-107">É possível enriquecer os dados gerados na nuvem usando dados de referência de fontes de dados locais ou de outras fontes de dados diferentes?</span><span class="sxs-lookup"><span data-stu-id="44f21-107">Is it possible to enrich data generated in the cloud by using reference data from on-premises data sources or other disparate data sources?</span></span> <span data-ttu-id="44f21-108">Por exemplo, uma empresa de jogos coleta muitos logs gerados por jogos na nuvem.</span><span class="sxs-lookup"><span data-stu-id="44f21-108">For example, a gaming company collects many logs produced by games in the cloud.</span></span> <span data-ttu-id="44f21-109">Ela deseja analisar esses logs para obter informações sobre as preferências do cliente, dados demográficos, comportamento de uso, etc., para identificar oportunidades de venda e vendas cruzadas, desenvolver novos recursos atraentes para fomentar o crescimento do negócio e proporcionar uma melhor experiência para os clientes.</span><span class="sxs-lookup"><span data-stu-id="44f21-109">It wants to analyze these logs to gain insights in to customer preferences, demographics, usage behavior etc. to identify up-sell and cross-sell opportunities, develop new compelling features to drive business growth, and provide a better experience to customers.</span></span> 

<span data-ttu-id="44f21-110">Para analisar esses logs, a empresa precisa usar os dados de referência como informações do cliente, informações sobre o jogo, informações de campanha de marketing que estão em um repositório de dados local.</span><span class="sxs-lookup"><span data-stu-id="44f21-110">To analyze these logs, the company needs to use the reference data such as customer information, game information, marketing campaign information that is in an on-premises data store.</span></span> <span data-ttu-id="44f21-111">Portanto, a empresa quer ingerir dados de log do armazenamento de dados de nuvem e dados de referência do repositório de dados local.</span><span class="sxs-lookup"><span data-stu-id="44f21-111">Therefore, the company wants to ingest log data from the cloud data store and reference data from the on-premises data store.</span></span> <span data-ttu-id="44f21-112">Em seguida, processa os dados usando o Hadoop na nuvem (Azure HDInsight) e publica os dados de resultado em um data warehouse de nuvem, como o SQL Data Warehouse do Azure ou um repositório de dados local como o SQL Server.</span><span class="sxs-lookup"><span data-stu-id="44f21-112">Then, process the data by using Hadoop in the cloud (Azure HDInsight) and publish the result data into a cloud data warehouse such as Azure SQL Data Warehouse or an on-premises data store such as SQL Server.</span></span> <span data-ttu-id="44f21-113">Ela deseja executar esse fluxo de trabalho uma vez por semana.</span><span class="sxs-lookup"><span data-stu-id="44f21-113">It wants this workflow to run weekly once.</span></span> 

<span data-ttu-id="44f21-114">O que é necessário é uma plataforma que permite que a empresa crie um fluxo de trabalho que possa ingerir dados de repositórios de dados locais e em nuvem e transformar ou processar dados usando os serviços de computação existentes, como o Hadoop e publicar os resultados em um repositório de dados local ou em nuvem para consumo pelos aplicativos de BI.</span><span class="sxs-lookup"><span data-stu-id="44f21-114">What is needed is a platform that allows the company to create a workflow that can ingest data from both on-premises and cloud data stores, and transform or process data by using existing compute services such as Hadoop, and publish the results to an on-premises or cloud data store for BI applications to consume.</span></span> 

![Visão geral do Data Factory](media/data-factory-introduction/what-is-azure-data-factory.png) 

<span data-ttu-id="44f21-116">O Azure Data Factory é a plataforma para esses tipos de cenários.</span><span class="sxs-lookup"><span data-stu-id="44f21-116">Azure Data Factory is the platform for this kind of scenarios.</span></span> <span data-ttu-id="44f21-117">É um **serviço de integração de dados com baseado em nuvem que permite que você crie fluxos de trabalho orientados a dados na nuvem para orquestrar e automatizar a movimentação de dados e a transformação de dados**.</span><span class="sxs-lookup"><span data-stu-id="44f21-117">It is a **cloud-based data integration service that allows you to create data-driven workflows in the cloud for orchestrating and automating data movement and data transformation**.</span></span> <span data-ttu-id="44f21-118">Usando o Azure Data Factory, você pode criar e agendar fluxos de trabalho orientados a dados (chamados de pipelines) que podem ingerir dados de repositórios de dados diferentes, processar/transformr os dados usando serviços de computação como o Hadoop do Azure HDInsight, Spark, Azure Data Lake Analytics e Azure Machine Learning e publicar os dados de saída em repositórios de dados como o SQL Data Warehouse do Azure para consumo pelos aplicativos de business intelligence (BI).</span><span class="sxs-lookup"><span data-stu-id="44f21-118">Using Azure Data Factory, you can create and schedule data-driven workflows (called pipelines) that can ingest data from disparate data stores, process/transform the data by using compute services such as Azure HDInsight Hadoop, Spark, Azure Data Lake Analytics, and Azure Machine Learning, and publish output data to data stores such as Azure SQL Data Warehouse for business intelligence (BI) applications to consume.</span></span>  

<span data-ttu-id="44f21-119">Essa é uma plataforma mais de Extrair e Carregar (EL) e, em seguida, Transformar e Carregar (TL) do que uma plataforma de Extrair, Carregar e Transformar (ETL) tradicional.</span><span class="sxs-lookup"><span data-stu-id="44f21-119">It's more of an Extract-and-Load (EL) and then Transform-and-Load (TL) platform rather than a traditional Extract-Transform-and-Load (ETL) platform.</span></span> <span data-ttu-id="44f21-120">As transformações que são executadas são para transformar/processar dados usando os serviços de computação em vez de executar transformações como aquelas para adicionar colunas derivadas, contagem do número de linhas, classificação de dados, etc.</span><span class="sxs-lookup"><span data-stu-id="44f21-120">The transformations that are performed are to transform/process data by using compute services rather than to perform transformations like the ones for adding derived columns, counting number of rows, sorting data, etc.</span></span> 

<span data-ttu-id="44f21-121">Atualmente, no Azure Data Factory, os dados que são consumidos e produzidos pelos fluxos de trabalho são **dados divididos pelo tempo** (por hora, dia, semana, etc.).</span><span class="sxs-lookup"><span data-stu-id="44f21-121">Currently, in Azure Data Factory, the data that is consumed and produced by workflows is **time-sliced data** (hourly, daily, weekly, etc.).</span></span> <span data-ttu-id="44f21-122">Por exemplo, um pipeline pode ler dados de entrada, processar dados e produzir dados de saída uma vez por dia.</span><span class="sxs-lookup"><span data-stu-id="44f21-122">For example, a pipeline may read input data, process data, and produce output data once a day.</span></span> <span data-ttu-id="44f21-123">Você também pode executar um fluxo de trabalho apenas uma vez.</span><span class="sxs-lookup"><span data-stu-id="44f21-123">You can also run a workflow just one time.</span></span>  
  

## <a name="how-does-it-work"></a><span data-ttu-id="44f21-124">Como ele funciona?</span><span class="sxs-lookup"><span data-stu-id="44f21-124">How does it work?</span></span> 
<span data-ttu-id="44f21-125">Os pipelines (fluxos de trabalho orientados a dados) no Azure Data Factory normalmente executam as três etapas a seguir:</span><span class="sxs-lookup"><span data-stu-id="44f21-125">The pipelines (data-driven workflows) in Azure Data Factory typically perform the following three steps:</span></span>

![As três etapas do Azure Data Factory](media/data-factory-introduction/three-information-production-stages.png)

### <a name="connect-and-collect"></a><span data-ttu-id="44f21-127">Conectar e coletar</span><span class="sxs-lookup"><span data-stu-id="44f21-127">Connect and collect</span></span>
<span data-ttu-id="44f21-128">As empresas possuem dados de diferentes tipos, localizados em diferentes fontes.</span><span class="sxs-lookup"><span data-stu-id="44f21-128">Enterprises have data of various types located in disparate sources.</span></span> <span data-ttu-id="44f21-129">A primeira etapa na criação de um sistema de produção de informações é se conectar a todas as fontes necessárias de dados e processamento, como serviços SaaS, os serviços web compartilhamentos, FTP, arquivos e mover os dados conforme necessário para um local centralizado para processamento posterior.</span><span class="sxs-lookup"><span data-stu-id="44f21-129">The first step in building an information production system is to connect to all the required sources of data and processing, such as SaaS services, file shares, FTP, web services, and move the data as-needed to a centralized location for subsequent processing.</span></span>

<span data-ttu-id="44f21-130">Sem o Data Factory, as empresas devem criar componentes de movimentação de dados personalizados ou gravar serviços personalizados para integrar essas fontes de dados e processamento.</span><span class="sxs-lookup"><span data-stu-id="44f21-130">Without Data Factory, enterprises must build custom data movement components or write custom services to integrate these data sources and processing.</span></span> <span data-ttu-id="44f21-131">É caro e difícil integrar e manter esses sistemas, além disso, geralmente, eles não possuem o monitoramento e os alertas de nível corporativo e os controles que podem oferecer um serviço totalmente gerenciado.</span><span class="sxs-lookup"><span data-stu-id="44f21-131">It is expensive and hard to integrate and maintain such systems, and it often lacks the enterprise grade monitoring and alerting, and the controls that a fully managed service can offer.</span></span>

<span data-ttu-id="44f21-132">Com o Data Factory, você pode usar a Atividade de Cópia em um pipeline de dados para mover dados de repositórios de dados locais e na nuvem para um repositório de dados centralizado na nuvem para análise posterior.</span><span class="sxs-lookup"><span data-stu-id="44f21-132">With Data Factory, you can use the Copy Activity in a data pipeline to move data from both on-premises and cloud source data stores to a centralization data store in the cloud for further analysis.</span></span> <span data-ttu-id="44f21-133">Por exemplo, você pode coletar dados em um Azure Data Lake Store e transformar os dados posteriormente usando um serviço de computação do Azure Data Lake Analytics.</span><span class="sxs-lookup"><span data-stu-id="44f21-133">For example, you can collect data in an Azure Data Lake Store and transform the data later by using an Azure Data Lake Analytics compute service.</span></span> <span data-ttu-id="44f21-134">Ou, coletar dados em Armazenamento de Blobs do Azure e transformam dados posteriormente usando um cluster de Hadoop do Azure HDInsight.</span><span class="sxs-lookup"><span data-stu-id="44f21-134">Or, collect data in an Azure Blob Storage and transform data later by using an Azure HDInsight Hadoop cluster.</span></span>

### <a name="transform-and-enrich"></a><span data-ttu-id="44f21-135">Transformar e enriquecer</span><span class="sxs-lookup"><span data-stu-id="44f21-135">Transform and enrich</span></span>
<span data-ttu-id="44f21-136">Depois que os dados estiverem presentes em um repositório centralizado de dados na nuvem, você deseja que os dados coletados, sejam processados ou transformados usando serviços de computação como Hadoop do HDInsight, Spark, Data Lake Analytics e Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="44f21-136">Once data is present in a centralized data store in the cloud, you want the collected data to be processed or transformed by using compute services such as HDInsight Hadoop, Spark, Data Lake Analytics, and Machine Learning.</span></span> <span data-ttu-id="44f21-137">Você quer produzir confiavelmente os dados transformados em uma agenda controlada e passível de manutenção para alimentar os ambientes de produção com dados confiáveis.</span><span class="sxs-lookup"><span data-stu-id="44f21-137">You want to reliably produce transformed data on a maintainable and controlled schedule to feed production environments with trusted data.</span></span> 

### <a name="publish"></a><span data-ttu-id="44f21-138">Publicar</span><span class="sxs-lookup"><span data-stu-id="44f21-138">Publish</span></span> 
<span data-ttu-id="44f21-139">Forneça dados transformados de fontes na nuvem para locais como o SQL Server, ou os mantenha em suas fontes de armazenamento em nuvem para o consumo por BI (business intelligence), ferramentas analíticas e outros aplicativos.</span><span class="sxs-lookup"><span data-stu-id="44f21-139">Deliver transformed data from the cloud to on-premises sources like SQL Server, or keep it in your cloud storage sources for consumption by business intelligence (BI) and analytics tools and other applications.</span></span>

## <a name="key-components"></a><span data-ttu-id="44f21-140">Principais componentes</span><span class="sxs-lookup"><span data-stu-id="44f21-140">Key components</span></span>
<span data-ttu-id="44f21-141">Uma assinatura do Azure pode ter um ou mais instâncias do Azure Data Factory (ou fábricas de dados).</span><span class="sxs-lookup"><span data-stu-id="44f21-141">An Azure subscription may have one or more Azure Data Factory instances (or data factories).</span></span> <span data-ttu-id="44f21-142">O Azure Data Factory é composto por quatro componentes principais que trabalham juntos para fornecer a plataforma na qual você pode compor fluxos de trabalho orientados a dados com etapas para movimentação e transformação dos dados.</span><span class="sxs-lookup"><span data-stu-id="44f21-142">Azure Data Factory is composed of four key components that work together to provide the platform on which you can compose data-driven workflows with steps to move and transform data.</span></span> 

### <a name="pipeline"></a><span data-ttu-id="44f21-143">Pipeline</span><span class="sxs-lookup"><span data-stu-id="44f21-143">Pipeline</span></span>
<span data-ttu-id="44f21-144">Um data factory pode ter um ou mais pipelines.</span><span class="sxs-lookup"><span data-stu-id="44f21-144">A data factory may have one or more pipelines.</span></span> <span data-ttu-id="44f21-145">Um pipeline é um grupo de atividades.</span><span class="sxs-lookup"><span data-stu-id="44f21-145">A pipeline is a group of activities.</span></span> <span data-ttu-id="44f21-146">Juntas, as atividades em um pipeline executam uma tarefa.</span><span class="sxs-lookup"><span data-stu-id="44f21-146">Together, the activities in a pipeline perform a task.</span></span> <span data-ttu-id="44f21-147">Por exemplo, um pipeline pode conter um grupo de atividades que recebe dados de um blob do Azure e, em seguida, executar uma consulta de Hive em um cluster de HDInsight para particionar os dados.</span><span class="sxs-lookup"><span data-stu-id="44f21-147">For example, a pipeline could contain a group of activities that ingests data from an Azure blob, and then run a Hive query on an HDInsight cluster to partition the data.</span></span> <span data-ttu-id="44f21-148">A vantagem disso é que o pipeline permite que você gerencie atividades como um conjunto, em vez de cada uma individualmente.</span><span class="sxs-lookup"><span data-stu-id="44f21-148">The benefit of this is that the pipeline allows you to manage the activities as a set instead of each one individually.</span></span> <span data-ttu-id="44f21-149">Por exemplo, você pode implantar e agendar o pipeline, em vez de atividades de forma independente.</span><span class="sxs-lookup"><span data-stu-id="44f21-149">For example, you can deploy and schedule the pipeline, instead of the activities independently.</span></span> 

### <a name="activity"></a><span data-ttu-id="44f21-150">Atividade</span><span class="sxs-lookup"><span data-stu-id="44f21-150">Activity</span></span>
<span data-ttu-id="44f21-151">Um pipeline pode ter uma ou mais atividades.</span><span class="sxs-lookup"><span data-stu-id="44f21-151">A pipeline may have one or more activities.</span></span> <span data-ttu-id="44f21-152">As Atividades definem as ações a serem realizadas em seus dados.</span><span class="sxs-lookup"><span data-stu-id="44f21-152">Activities define the actions to perform on your data.</span></span> <span data-ttu-id="44f21-153">Por exemplo, você pode usar uma atividade de cópia para copiar dados de um repositório de dados para outro.</span><span class="sxs-lookup"><span data-stu-id="44f21-153">For example, you may use a Copy activity to copy data from one data store to another data store.</span></span> <span data-ttu-id="44f21-154">Da mesma forma, você pode usar uma atividade do Hive que executa uma consulta de Hive em um cluster do Azure HDInsight para transformar ou analisar seus dados.</span><span class="sxs-lookup"><span data-stu-id="44f21-154">Similarly, you may use a Hive activity, which runs a Hive query on an Azure HDInsight cluster to transform or analyze your data.</span></span> <span data-ttu-id="44f21-155">O Data Factory dá suporte a dois tipos de atividades: atividades de movimentação de dados e atividades de transformação de dados.</span><span class="sxs-lookup"><span data-stu-id="44f21-155">Data Factory supports two types of activities: data movement activities and data transformation activities.</span></span>

### <a name="data-movement-activities"></a><span data-ttu-id="44f21-156">Atividades de movimentação de dados</span><span class="sxs-lookup"><span data-stu-id="44f21-156">Data movement activities</span></span>
<span data-ttu-id="44f21-157">A Atividade de Cópia no Data Factory copia os dados de um repositório de dados de origem para um repositório de dados de coletor.</span><span class="sxs-lookup"><span data-stu-id="44f21-157">Copy Activity in Data Factory copies data from a source data store to a sink data store.</span></span> <span data-ttu-id="44f21-158">A Data Factory dá suporte aos repositórios de dados a seguir.</span><span class="sxs-lookup"><span data-stu-id="44f21-158">Data Factory supports the following data stores.</span></span> <span data-ttu-id="44f21-159">Os dados de qualquer origem podem ser gravados em qualquer coletor.</span><span class="sxs-lookup"><span data-stu-id="44f21-159">Data from any source can be written to any sink.</span></span> <span data-ttu-id="44f21-160">Clique em um repositório de dados para saber como copiar dados dentro e fora do repositório.</span><span class="sxs-lookup"><span data-stu-id="44f21-160">Click a data store to learn how to copy data to and from that store.</span></span>

[!INCLUDE [data-factory-supported-data-stores](../../includes/data-factory-supported-data-stores.md)]

<span data-ttu-id="44f21-161">Para obter mais informações, confira o artigo [Atividades de movimentação de dados](data-factory-data-movement-activities.md).</span><span class="sxs-lookup"><span data-stu-id="44f21-161">For more information, see [Data Movement Activities](data-factory-data-movement-activities.md) article.</span></span>

### <a name="data-transformation-activities"></a><span data-ttu-id="44f21-162">Atividades de transformação de dados</span><span class="sxs-lookup"><span data-stu-id="44f21-162">Data transformation activities</span></span>
[!INCLUDE [data-factory-transformation-activities](../../includes/data-factory-transformation-activities.md)]

<span data-ttu-id="44f21-163">Para obter mais informações, confira o artigo [Atividades de transformação de dados](data-factory-data-transformation-activities.md).</span><span class="sxs-lookup"><span data-stu-id="44f21-163">For more information, see [Data Transformation Activities](data-factory-data-transformation-activities.md) article.</span></span>

### <a name="custom-net-activities"></a><span data-ttu-id="44f21-164">Atividades personalizadas do .NET</span><span class="sxs-lookup"><span data-stu-id="44f21-164">Custom .NET activities</span></span>
<span data-ttu-id="44f21-165">Se você precisar mover dados de/para um repositório de dados a que a Atividade de Cópia não dê suporte, ou transformar seus dados usando sua própria lógica, crie uma **atividade personalizada do .NET**.</span><span class="sxs-lookup"><span data-stu-id="44f21-165">If you need to move data to/from a data store that Copy Activity doesn't support, or transform data using your own logic, create a **custom .NET activity**.</span></span> <span data-ttu-id="44f21-166">Para obter detalhes sobre como criar e usar uma atividade personalizada, confira [Usar atividades personalizadas em um pipeline do Azure Data Factory](data-factory-use-custom-activities.md).</span><span class="sxs-lookup"><span data-stu-id="44f21-166">For details on creating and using a custom activity, see [Use custom activities in an Azure Data Factory pipeline](data-factory-use-custom-activities.md).</span></span>

### <a name="datasets"></a><span data-ttu-id="44f21-167">Conjunto de dados</span><span class="sxs-lookup"><span data-stu-id="44f21-167">Datasets</span></span>
<span data-ttu-id="44f21-168">Uma atividade aceita zero ou mais conjuntos de dados como entrada e produz um ou mais conjuntos de dados como saídas.</span><span class="sxs-lookup"><span data-stu-id="44f21-168">An activity takes zero or more datasets as inputs and one or more datasets as outputs.</span></span> <span data-ttu-id="44f21-169">Os conjuntos de dados representam as estruturas de dados nos repositórios de dados, que simplesmente apontam ou fazem referência aos dados que você deseja usar em suas atividades como entradas ou saídas.</span><span class="sxs-lookup"><span data-stu-id="44f21-169">Datasets represent data structures within the data stores, which simply point or reference the data you want to use in your activities as inputs or outputs.</span></span> <span data-ttu-id="44f21-170">Por exemplo, um conjunto de dados de Blob do Azure especifica o contêiner de blobs e a pasta no Armazenamento de Blobs do Azure, de onde o pipeline deve ler os dados.</span><span class="sxs-lookup"><span data-stu-id="44f21-170">For example, an Azure Blob dataset specifies the blob container and folder in the Azure Blob Storage from which the pipeline should read the data.</span></span> <span data-ttu-id="44f21-171">Ou, um conjunto de dados de tabela do Azure SQL especifica a tabela na qual os dados de saída são gravados pela atividade.</span><span class="sxs-lookup"><span data-stu-id="44f21-171">Or, an Azure SQL Table dataset specifies the table to which the output data is written by the activity.</span></span> 

### <a name="linked-services"></a><span data-ttu-id="44f21-172">Serviços vinculados</span><span class="sxs-lookup"><span data-stu-id="44f21-172">Linked services</span></span>
<span data-ttu-id="44f21-173">Serviços vinculados são como cadeias de conexão, que definem as informações de conexão necessárias para o Data Factory para se conectar a recursos externos.</span><span class="sxs-lookup"><span data-stu-id="44f21-173">Linked services are much like connection strings, which define the connection information needed for Data Factory to connect to external resources.</span></span> <span data-ttu-id="44f21-174">Pense dessa maneira - um serviço vinculado define a conexão à fonte de dados e um conjunto de dados representa a estrutura dos dados.</span><span class="sxs-lookup"><span data-stu-id="44f21-174">Think of it this way - a linked service defines the connection to the data source and a dataset represents the structure of the data.</span></span> <span data-ttu-id="44f21-175">Por exemplo, um serviço vinculado do Azure Storage especifica a cadeia de conexão para conectar-se à conta do Data Factory.</span><span class="sxs-lookup"><span data-stu-id="44f21-175">For example, an Azure Storage linked service specifies connection string to connect to the Azure Storage account.</span></span> <span data-ttu-id="44f21-176">E, um conjunto de dados de Blob do Azure especifica o contêiner de blob e a pasta que contém os dados.</span><span class="sxs-lookup"><span data-stu-id="44f21-176">And, an Azure Blob dataset specifies the blob container and the folder that contains the data.</span></span>   

<span data-ttu-id="44f21-177">Serviços vinculados são usados para duas finalidades no Data Factory:</span><span class="sxs-lookup"><span data-stu-id="44f21-177">Linked services are used for two purposes in Data Factory:</span></span>

* <span data-ttu-id="44f21-178">Para representar um **repositório de dados** , incluindo, mas não se limitando a um SQL Server local, banco de dados Oracle, compartilhamento de arquivos ou uma conta de Armazenamento de Blobs do Azure.</span><span class="sxs-lookup"><span data-stu-id="44f21-178">To represent a **data store** including, but not limited to, an on-premises SQL Server, Oracle database, file share, or an Azure Blob Storage account.</span></span> <span data-ttu-id="44f21-179">Confira a seção [Atividades de movimentação de dados](#data-movement-activities) para obter uma lista de repositórios de dados com suporte.</span><span class="sxs-lookup"><span data-stu-id="44f21-179">See the [Data movement activities](#data-movement-activities) section for a list of supported data stores.</span></span>
* <span data-ttu-id="44f21-180">Para representar um **recurso de computação** que pode hospedar a execução de uma atividade.</span><span class="sxs-lookup"><span data-stu-id="44f21-180">To represent a **compute resource** that can host the execution of an activity.</span></span> <span data-ttu-id="44f21-181">Por exemplo, a atividade HDInsightHive é executada em um cluster Hadoop do HDInsight.</span><span class="sxs-lookup"><span data-stu-id="44f21-181">For example, the HDInsightHive activity runs on an HDInsight Hadoop cluster.</span></span> <span data-ttu-id="44f21-182">Confira a seção [Atividades de transformação de dados](#data-transformation-activities) para obter uma lista de ambientes de computação com suporte.</span><span class="sxs-lookup"><span data-stu-id="44f21-182">See [Data transformation activities](#data-transformation-activities) section for a list of supported compute environments.</span></span>

### <a name="relationship-between-data-factory-entities"></a><span data-ttu-id="44f21-183">Relação entre entidades de Data Factory</span><span class="sxs-lookup"><span data-stu-id="44f21-183">Relationship between Data Factory entities</span></span>
<span data-ttu-id="44f21-184">![Diagrama: Data Factory, um serviço de integração de dados de nuvem - conceitos principais](./media/data-factory-introduction/data-integration-service-key-concepts.png)
**Figure 2.**</span><span class="sxs-lookup"><span data-stu-id="44f21-184">![Diagram: Data Factory, a cloud data integration service - Key Concepts](./media/data-factory-introduction/data-integration-service-key-concepts.png)
**Figure 2.**</span></span> <span data-ttu-id="44f21-185">Relações entre o Conjunto de dados, Atividade, Pipeline e Serviço vinculado</span><span class="sxs-lookup"><span data-stu-id="44f21-185">Relationships between Dataset, Activity, Pipeline, and Linked service</span></span>

## <a name="supported-regions"></a><span data-ttu-id="44f21-186">Regiões com suporte</span><span class="sxs-lookup"><span data-stu-id="44f21-186">Supported regions</span></span>
<span data-ttu-id="44f21-187">No momento, você pode criar fábricas de dados nas regiões **Oeste dos EUA**, **Leste dos EUA** e **Europa Setentrional**.</span><span class="sxs-lookup"><span data-stu-id="44f21-187">Currently, you can create data factories in the **West US**, **East US**, and **North Europe** regions.</span></span> <span data-ttu-id="44f21-188">No entanto, uma fábrica de dados pode acessar repositórios de dados e serviços de computação em outras regiões do Azure para mover dados entre repositórios de dados ou processar dados usando serviços de computação.</span><span class="sxs-lookup"><span data-stu-id="44f21-188">However, a data factory can access data stores and compute services in other Azure regions to move data between data stores or process data using compute services.</span></span>

<span data-ttu-id="44f21-189">O Azure Data Factory em si não armazena dados.</span><span class="sxs-lookup"><span data-stu-id="44f21-189">Azure Data Factory itself does not store any data.</span></span> <span data-ttu-id="44f21-190">Ele permite criar fluxos de trabalho controlados por dados para orquestrar a movimentação de dados entre [armazenamentos de dados com suporte](#data-movement-activities) e o processamento de dados usando [serviços de computação](#data-transformation-activities) em outras regiões ou em um ambiente local.</span><span class="sxs-lookup"><span data-stu-id="44f21-190">It lets you create data-driven workflows to orchestrate movement of data between [supported data stores](#data-movement-activities) and processing of data using [compute services](#data-transformation-activities) in other regions or in an on-premises environment.</span></span> <span data-ttu-id="44f21-191">Ele também permite [monitorar e gerenciar fluxos de trabalho](data-factory-monitor-manage-pipelines.md) usando mecanismos programáticos e de interface do usuário.</span><span class="sxs-lookup"><span data-stu-id="44f21-191">It also allows you to [monitor and manage workflows](data-factory-monitor-manage-pipelines.md) using both programmatic and UI mechanisms.</span></span>

<span data-ttu-id="44f21-192">Embora o Data Factory só esteja disponível nas regiões **Oeste dos EUA**, **Leste dos EUA** e **Europa Setentrional**, o serviço que capacita a movimentação de dados no Data Factory está disponível [globalmente](data-factory-data-movement-activities.md#global) em várias regiões.</span><span class="sxs-lookup"><span data-stu-id="44f21-192">Even though Data Factory is available in only **West US**, **East US**, and **North Europe** regions, the service powering the data movement in Data Factory is available [globally](data-factory-data-movement-activities.md#global) in several regions.</span></span> <span data-ttu-id="44f21-193">Se um repositório de dados estiver por trás de um firewall, um [Gateway de Gerenciamento de Dados](data-factory-move-data-between-onprem-and-cloud.md) instalado no ambiente local moverá os dados.</span><span class="sxs-lookup"><span data-stu-id="44f21-193">If a data store is behind a firewall, then a [Data Management Gateway](data-factory-move-data-between-onprem-and-cloud.md) installed in your on-premises environment moves the data instead.</span></span>

<span data-ttu-id="44f21-194">Por exemplo, digamos que seus ambientes de computação, como o cluster Azure HDInsight e o Azure Machine Learning, estejam ficando sem a região Europa Ocidental.</span><span class="sxs-lookup"><span data-stu-id="44f21-194">For an example, let us assume that your compute environments such as Azure HDInsight cluster and Azure Machine Learning are running out of West Europe region.</span></span> <span data-ttu-id="44f21-195">Você pode criar e usar uma instância do Azure Data Factory na Europa Setentrional e usá-la para agendar trabalhos em seus ambientes de computação na Europa Ocidental.</span><span class="sxs-lookup"><span data-stu-id="44f21-195">You can create and use an Azure Data Factory instance in North Europe and use it to schedule jobs on your compute environments in West Europe.</span></span> <span data-ttu-id="44f21-196">Leva alguns milissegundos para o Data Factory disparar o trabalho em seu ambiente de computação, mas o tempo de execução do trabalho em seu ambiente de computação não é alterado.</span><span class="sxs-lookup"><span data-stu-id="44f21-196">It takes a few milliseconds for Data Factory to trigger the job on your compute environment but the time for running the job on your computing environment does not change.</span></span>

## <a name="get-started-with-creating-a-pipeline"></a><span data-ttu-id="44f21-197">Introdução à criação de um pipeline</span><span class="sxs-lookup"><span data-stu-id="44f21-197">Get started with creating a pipeline</span></span>
<span data-ttu-id="44f21-198">Você pode usar uma dessas ferramentas ou APIs para criar pipelines de dados no Azure Data Factory:</span><span class="sxs-lookup"><span data-stu-id="44f21-198">You can use one of these tools or APIs to create data pipelines in Azure Data Factory:</span></span> 

- <span data-ttu-id="44f21-199">Portal do Azure</span><span class="sxs-lookup"><span data-stu-id="44f21-199">Azure portal</span></span>
- <span data-ttu-id="44f21-200">Visual Studio</span><span class="sxs-lookup"><span data-stu-id="44f21-200">Visual Studio</span></span>
- <span data-ttu-id="44f21-201">PowerShell</span><span class="sxs-lookup"><span data-stu-id="44f21-201">PowerShell</span></span>
- <span data-ttu-id="44f21-202">API do .NET</span><span class="sxs-lookup"><span data-stu-id="44f21-202">.NET API</span></span>
- <span data-ttu-id="44f21-203">API REST</span><span class="sxs-lookup"><span data-stu-id="44f21-203">REST API</span></span>
- <span data-ttu-id="44f21-204">Modelo do Azure Resource Manager.</span><span class="sxs-lookup"><span data-stu-id="44f21-204">Azure Resource Manager template.</span></span> 

<span data-ttu-id="44f21-205">Para saber como criar data factories com pipeline de dados, siga as instruções passo a passo nos tutoriais a seguir:</span><span class="sxs-lookup"><span data-stu-id="44f21-205">To learn how to build data factories with data pipelines, follow step-by-step instructions in the following tutorials:</span></span>

| <span data-ttu-id="44f21-206">Tutorial</span><span class="sxs-lookup"><span data-stu-id="44f21-206">Tutorial</span></span> | <span data-ttu-id="44f21-207">Descrição</span><span class="sxs-lookup"><span data-stu-id="44f21-207">Description</span></span> |
| --- | --- |
| [<span data-ttu-id="44f21-208">Mover dados entre dois armazenamentos de dados em nuvem</span><span class="sxs-lookup"><span data-stu-id="44f21-208">Move data between two cloud data stores</span></span>](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md) |<span data-ttu-id="44f21-209">Neste tutorial, você cria um data factory com um pipeline que **move dados** do Armazenamento de Blobs para o banco de dados SQL.</span><span class="sxs-lookup"><span data-stu-id="44f21-209">In this tutorial, you create a data factory with a pipeline that **moves data** from Blob storage to SQL database.</span></span> |
| [<span data-ttu-id="44f21-210">Transformar dados usando o cluster Hadoop</span><span class="sxs-lookup"><span data-stu-id="44f21-210">Transform data using Hadoop cluster</span></span>](data-factory-build-your-first-pipeline.md) |<span data-ttu-id="44f21-211">Neste tutorial, você cria seu primeiro data factory no Azure com um pipeline de dados que **processa os dados** executando o script do Hive em um cluster Azure HDInsight (Hadoop).</span><span class="sxs-lookup"><span data-stu-id="44f21-211">In this tutorial, you build your first Azure data factory with a data pipeline that **processes data** by running Hive script on an Azure HDInsight (Hadoop) cluster.</span></span> |
| [<span data-ttu-id="44f21-212">Mover dados entre um armazenamento de dados local e um armazenamento de dados em nuvem usando o Gateway de Gerenciamento de Dados</span><span class="sxs-lookup"><span data-stu-id="44f21-212">Move data between an on-premises data store and a cloud data store using Data Management Gateway</span></span>](data-factory-move-data-between-onprem-and-cloud.md) |<span data-ttu-id="44f21-213">Neste tutorial, você cria um data factory com um pipeline que **move dados** de um banco de dados SQL Server **local** para um blob do Azure.</span><span class="sxs-lookup"><span data-stu-id="44f21-213">In this tutorial, you build a data factory with a pipeline that **moves data** from an **on-premises** SQL Server database to an Azure blob.</span></span> <span data-ttu-id="44f21-214">Como parte do passo a passo, você instala e configura o Gateway de Gerenciamento de Dados em seu computador.</span><span class="sxs-lookup"><span data-stu-id="44f21-214">As part of the walkthrough, you install and configure the Data Management Gateway on your machine.</span></span> |
