---
title: "Opções de contexto de computação para o R Server no HDInsight – Azure | Microsoft Docs"
description: "Conheça as diferentes opções de contexto de computação disponíveis para usuários com o Servidor R no HDInsight"
services: HDInsight
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: 0deb0b1c-4094-459b-94fc-ec9b774c1f8a
ms.service: HDInsight
ms.custom: hdinsightactive
ms.devlang: R
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: data-services
ms.date: 06/19/2017
ms.author: bradsev
ms.openlocfilehash: 47f4441612be4f363ba82cc22b09786a6f3bfdc3
ms.sourcegitcommit: 18ad9bc049589c8e44ed277f8f43dcaa483f3339
ms.translationtype: MT
ms.contentlocale: pt-BR
ms.lasthandoff: 08/29/2017
---
# <a name="compute-context-options-for-r-server-on-hdinsight"></a><span data-ttu-id="b966d-103">Opções de contexto de computação para o Servidor R no HDInsight</span><span class="sxs-lookup"><span data-stu-id="b966d-103">Compute context options for R Server on HDInsight</span></span>

<span data-ttu-id="b966d-104">O Microsoft R Server no Azure HDInsight controla como as chamadas são executadas, configurando o contexto de computação.</span><span class="sxs-lookup"><span data-stu-id="b966d-104">Microsoft R Server on Azure HDInsight controls how calls are executed by setting the compute context.</span></span> <span data-ttu-id="b966d-105">Este artigo descreve as opções que estão disponíveis para especificar se e como a execução é paralelizada entre núcleos do nó de borda ou o cluster HDInsight.</span><span class="sxs-lookup"><span data-stu-id="b966d-105">This article outlines the options that are available to specify whether and how execution is parallelized across cores of the edge node or HDInsight cluster.</span></span>

<span data-ttu-id="b966d-106">O nó de borda de um cluster fornece um local conveniente para se conectar ao cluster e executar os scripts de R.</span><span class="sxs-lookup"><span data-stu-id="b966d-106">The edge node of a cluster provides a convenient place to connect to the cluster and to run your R scripts.</span></span> <span data-ttu-id="b966d-107">Com um nó do borda, você tem a opção de executar funções distribuídas paralelizadas do ScaleR nos núcleos do servidor do nó de borda.</span><span class="sxs-lookup"><span data-stu-id="b966d-107">With an edge node, you have the option of running the parallelized distributed functions of ScaleR across the cores of the edge node server.</span></span> <span data-ttu-id="b966d-108">Você também pode executá-las em todos os nós do cluster usando o Hadoop Map Reduce do ScaleR ou os contextos de computação do Spark.</span><span class="sxs-lookup"><span data-stu-id="b966d-108">You can also run them across the nodes of the cluster by using ScaleR’s Hadoop Map Reduce or Spark compute contexts.</span></span>

## <a name="microsoft-r-server-on-azure-hdinsight"></a><span data-ttu-id="b966d-109">Microsoft R Server no Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="b966d-109">Microsoft R Server on Azure HDInsight</span></span>
<span data-ttu-id="b966d-110">O [Microsoft R Server no Azure HDInsight](hdinsight-hadoop-r-server-overview.md) fornece os recursos mais recentes para a análise baseada em R.</span><span class="sxs-lookup"><span data-stu-id="b966d-110">[Microsoft R Server on Azure HDInsight](hdinsight-hadoop-r-server-overview.md) provides the latest capabilities for R-based analytics.</span></span> <span data-ttu-id="b966d-111">Ele pode usar dados armazenados em um contêiner HDFS em sua conta de armazenamento de [Blob do Azure](../storage/common/storage-introduction.md "Armazenamento de Blobs do Azure"), em um Data Lake Store ou no sistema de arquivos local do Linux.</span><span class="sxs-lookup"><span data-stu-id="b966d-111">It can use data that is stored in an HDFS container in your [Azure Blob](../storage/common/storage-introduction.md "Azure Blob storage") storage account, a Data Lake store, or the local Linux file system.</span></span> <span data-ttu-id="b966d-112">Uma vez que o R Server é criado no R de software livre, os aplicativos baseados em R que você compilar podem aplicar qualquer um dos mais de 8.000 pacotes de R de software livre.</span><span class="sxs-lookup"><span data-stu-id="b966d-112">Since R Server is built on open source R, the R-based applications you build can apply any of the 8000+ open source R packages.</span></span> <span data-ttu-id="b966d-113">Eles também podem usar as rotinas no [RevoScaleR](https://msdn.microsoft.com/microsoft-r/scaler/scaler), o pacote de análise de Big Data da Microsoft que está incluído no R Server.</span><span class="sxs-lookup"><span data-stu-id="b966d-113">They can also use the routines in [RevoScaleR](https://msdn.microsoft.com/microsoft-r/scaler/scaler), Microsoft’s big data analytics package that is included with R Server.</span></span>  

## <a name="compute-contexts-for-an-edge-node"></a><span data-ttu-id="b966d-114">Contextos de computação para um nó de extremidade</span><span class="sxs-lookup"><span data-stu-id="b966d-114">Compute contexts for an edge node</span></span>
<span data-ttu-id="b966d-115">Em geral, um script de R que é executado no Servidor R no nó de borda é executado no interpretador de R nesse nó.</span><span class="sxs-lookup"><span data-stu-id="b966d-115">In general, an R script that's run in R Server on the edge node runs within the R interpreter on that node.</span></span> <span data-ttu-id="b966d-116">As exceções são aquelas etapas que chamam uma função ScaleR.</span><span class="sxs-lookup"><span data-stu-id="b966d-116">The exceptions are those steps that call a ScaleR function.</span></span> <span data-ttu-id="b966d-117">As chamadas de ScaleR são executadas em um ambiente de computação que é determinado pela configuração do contexto de computação do ScaleR.</span><span class="sxs-lookup"><span data-stu-id="b966d-117">The ScaleR calls run in a compute environment that is determined by how you set the ScaleR compute context.</span></span>  <span data-ttu-id="b966d-118">Quando você executa o script R de um nó de borda, os valores possíveis de contexto de computação são:</span><span class="sxs-lookup"><span data-stu-id="b966d-118">When you run your R script from an edge node, the possible values of the compute context are:</span></span>

- <span data-ttu-id="b966d-119">local sequencial (*‘local’*)</span><span class="sxs-lookup"><span data-stu-id="b966d-119">local sequential (*‘local’*)</span></span>
- <span data-ttu-id="b966d-120">local paralelo (*‘localpar’*)</span><span class="sxs-lookup"><span data-stu-id="b966d-120">local parallel (*‘localpar’*)</span></span>
- <span data-ttu-id="b966d-121">Map Reduce</span><span class="sxs-lookup"><span data-stu-id="b966d-121">Map Reduce</span></span>
- <span data-ttu-id="b966d-122">Spark</span><span class="sxs-lookup"><span data-stu-id="b966d-122">Spark</span></span>

<span data-ttu-id="b966d-123">As opções *‘local’* e *‘localpar’* diferem apenas em como chamadas do **rxExec** são executadas.</span><span class="sxs-lookup"><span data-stu-id="b966d-123">The *‘local’* and *‘localpar’* options differ only in how **rxExec** calls are executed.</span></span> <span data-ttu-id="b966d-124">As duas executam outras chamadas de função rx de forma paralela entre os núcleos disponíveis, a menos que seja especificado de outra forma por meio do uso da opção **numCoresToUse** de ScaleR, por exemplo, `rxOptions(numCoresToUse=6)`.</span><span class="sxs-lookup"><span data-stu-id="b966d-124">They both execute other rx-function calls in a parallel manner across all available cores unless specified otherwise through use of the ScaleR **numCoresToUse** option, for example `rxOptions(numCoresToUse=6)`.</span></span> <span data-ttu-id="b966d-125">Opções de execução paralela oferecem um desempenho ideal.</span><span class="sxs-lookup"><span data-stu-id="b966d-125">Parallel execution options offer optimal performance.</span></span>

<span data-ttu-id="b966d-126">A tabela a seguir resume as várias opções de contexto de computação para definir como as chamadas são executadas:</span><span class="sxs-lookup"><span data-stu-id="b966d-126">The following table summarizes the various compute context options to set how calls are executed:</span></span>

| <span data-ttu-id="b966d-127">Contexto de computação</span><span class="sxs-lookup"><span data-stu-id="b966d-127">Compute context</span></span>  | <span data-ttu-id="b966d-128">Como definir</span><span class="sxs-lookup"><span data-stu-id="b966d-128">How to set</span></span>                      | <span data-ttu-id="b966d-129">Contexto de execução</span><span class="sxs-lookup"><span data-stu-id="b966d-129">Execution context</span></span>                        |
| ---------------- | ------------------------------- | ---------------------------------------- |
| <span data-ttu-id="b966d-130">Local sequencial</span><span class="sxs-lookup"><span data-stu-id="b966d-130">Local sequential</span></span> | <span data-ttu-id="b966d-131">rxSetComputeContext(‘local’)</span><span class="sxs-lookup"><span data-stu-id="b966d-131">rxSetComputeContext(‘local’)</span></span>    | <span data-ttu-id="b966d-132">Execução em paralelo entre os núcleos do servidor de nó de borda, exceto para chamadas rxExec, que são executadas em série</span><span class="sxs-lookup"><span data-stu-id="b966d-132">Parallelized execution across the cores of the edge node server, except for rxExec calls, which are executed serially</span></span> |
| <span data-ttu-id="b966d-133">Local paralelo</span><span class="sxs-lookup"><span data-stu-id="b966d-133">Local parallel</span></span>   | <span data-ttu-id="b966d-134">rxSetComputeContext(‘localpar’)</span><span class="sxs-lookup"><span data-stu-id="b966d-134">rxSetComputeContext(‘localpar’)</span></span> | <span data-ttu-id="b966d-135">Execução paralela entre os núcleos do servidor de nó de borda</span><span class="sxs-lookup"><span data-stu-id="b966d-135">Parallelized execution across the cores of the edge node server</span></span> |
| <span data-ttu-id="b966d-136">Spark</span><span class="sxs-lookup"><span data-stu-id="b966d-136">Spark</span></span>            | <span data-ttu-id="b966d-137">RxSpark()</span><span class="sxs-lookup"><span data-stu-id="b966d-137">RxSpark()</span></span>                       | <span data-ttu-id="b966d-138">Execução distribuída em paralelo por meio do Spark em todos os nós do cluster do HDI</span><span class="sxs-lookup"><span data-stu-id="b966d-138">Parallelized distributed execution via Spark across the nodes of the HDI cluster</span></span> |
| <span data-ttu-id="b966d-139">Map Reduce</span><span class="sxs-lookup"><span data-stu-id="b966d-139">Map Reduce</span></span>       | <span data-ttu-id="b966d-140">RxHadoopMR()</span><span class="sxs-lookup"><span data-stu-id="b966d-140">RxHadoopMR()</span></span>                    | <span data-ttu-id="b966d-141">Execução distribuída em paralelo por meio do Map Reduce em todos os nós do cluster do HDI</span><span class="sxs-lookup"><span data-stu-id="b966d-141">Parallelized distributed execution via Map Reduce across the nodes of the HDI cluster</span></span> |

## <a name="guidelines-for-deciding-on-a-compute-context"></a><span data-ttu-id="b966d-142">Diretrizes para decidir em um contexto de computação</span><span class="sxs-lookup"><span data-stu-id="b966d-142">Guidelines for deciding on a compute context</span></span>

<span data-ttu-id="b966d-143">Qual das três opções que fornecem execução em paralelo você ddeve escolher depende da natureza de seu trabalho de análise, do tamanho e do local dos seus dados.</span><span class="sxs-lookup"><span data-stu-id="b966d-143">Which of the three options you choose that provide parallelized execution depends on the nature of your analytics work, the size, and the location of your data.</span></span> <span data-ttu-id="b966d-144">Não há uma fórmula simples que diga a você qual contexto de computação usar.</span><span class="sxs-lookup"><span data-stu-id="b966d-144">There is no simple formula that tells you which compute context to use.</span></span> <span data-ttu-id="b966d-145">No entanto, há alguns princípios importantes que podem ajudar você a fazer a escolha certa ou, pelo menos, ajudar a refinar suas escolhas antes de executar um benchmark.</span><span class="sxs-lookup"><span data-stu-id="b966d-145">There are, however, some guiding principles that can help you make the right choice, or, at least, help you narrow down your choices before you run a benchmark.</span></span> <span data-ttu-id="b966d-146">Esses princípios básicos incluem:</span><span class="sxs-lookup"><span data-stu-id="b966d-146">These guiding principles include:</span></span>

- <span data-ttu-id="b966d-147">O sistema de arquivos Linux local é mais rápido do que o HDFS.</span><span class="sxs-lookup"><span data-stu-id="b966d-147">The local Linux file system is faster than HDFS.</span></span>
- <span data-ttu-id="b966d-148">As análises repetidas serão mais rápidas se os dados forem locais e em XDF.</span><span class="sxs-lookup"><span data-stu-id="b966d-148">Repeated analyses are faster if the data is local, and if it's in XDF.</span></span>
- <span data-ttu-id="b966d-149">É preferível transmitir pequenas quantidades de dados de uma fonte de dados de texto.</span><span class="sxs-lookup"><span data-stu-id="b966d-149">It's preferable to stream small amounts of data from a text data source.</span></span> <span data-ttu-id="b966d-150">Se a quantidade de dados for maior, converta-os em XDF antes da análise.</span><span class="sxs-lookup"><span data-stu-id="b966d-150">If the amount of data is larger, convert it to XDF before analysis.</span></span>
- <span data-ttu-id="b966d-151">A sobrecarga da cópia ou transmissão dos dados para o nó de borda para análise se torna incontrolável para grandes quantidades de dados.</span><span class="sxs-lookup"><span data-stu-id="b966d-151">The overhead of copying or streaming the data to the edge node for analysis becomes unmanageable for very large amounts of data.</span></span>
- <span data-ttu-id="b966d-152">Spark é mais rápido do que Map Reduce para análise no Hadoop.</span><span class="sxs-lookup"><span data-stu-id="b966d-152">Spark is faster than Map Reduce for analysis in Hadoop.</span></span>

<span data-ttu-id="b966d-153">Com esses princípios, as seções a seguir oferecem algumas regras gerais para selecionar um contexto de computação.</span><span class="sxs-lookup"><span data-stu-id="b966d-153">Given these principles, the following sections offer some general rules of thumb for selecting a compute context.</span></span>

### <a name="local"></a><span data-ttu-id="b966d-154">Local</span><span class="sxs-lookup"><span data-stu-id="b966d-154">Local</span></span>
* <span data-ttu-id="b966d-155">Se a quantidade de dados a ser analisada for pequena e não demandar análise repetida, transmita-a diretamente para a rotina de análise usando *'local'* ou *'localpar'*.</span><span class="sxs-lookup"><span data-stu-id="b966d-155">If the amount of data to analyze is small and does not require repeated analysis, then stream it directly into the analysis routine using *'local'* or *'localpar'*.</span></span>
* <span data-ttu-id="b966d-156">Se a quantidade de dados a ser analisada for de pequeno ou médio porte e necessitar de análise repetida, copie-a para o sistema de arquivos local, importe-a para XDF e analise-a por meio de *'local'* ou *'localpar'*.</span><span class="sxs-lookup"><span data-stu-id="b966d-156">If the amount of data to analyze is small or medium-sized and requires repeated analysis, then copy it to the local file system, import it to XDF, and analyze it via *'local'* or *'localpar'*.</span></span>

### <a name="hadoop-spark"></a><span data-ttu-id="b966d-157">Hadoop Spark</span><span class="sxs-lookup"><span data-stu-id="b966d-157">Hadoop Spark</span></span>
* <span data-ttu-id="b966d-158">Se a quantidade de dados a serem analisados for grande, importe-os para um Spark DataFrame usando **RxHiveData** ou **RxParquetData** ou para o XDF no HDFS (exceto se o armazenamento for um problema) e analise-os usando o contexto de computação do Spark.</span><span class="sxs-lookup"><span data-stu-id="b966d-158">If the amount of data to analyze is large, then import it to a Spark DataFrame using **RxHiveData** or **RxParquetData**, or to XDF in HDFS (unless storage is an issue), and analyze it using the Spark compute context.</span></span>

### <a name="hadoop-map-reduce"></a><span data-ttu-id="b966d-159">Hadoop Map Reduce</span><span class="sxs-lookup"><span data-stu-id="b966d-159">Hadoop Map Reduce</span></span>
* <span data-ttu-id="b966d-160">Use o contexto de computação do Map Reduce somente se você encontrar um problema intransponível com o contexto de computação do Spark, pois geralmente ele é mais lento.</span><span class="sxs-lookup"><span data-stu-id="b966d-160">Use the Map Reduce compute context only if you encounter an insurmountable problem with the Spark compute context since it is generally slower.</span></span>  

## <a name="inline-help-on-rxsetcomputecontext"></a><span data-ttu-id="b966d-161">Ajuda embutida em rxSetComputeContext</span><span class="sxs-lookup"><span data-stu-id="b966d-161">Inline help on rxSetComputeContext</span></span>
<span data-ttu-id="b966d-162">Para obter mais informações e exemplos de contextos de computação de ScaleR, confira a ajuda embutida sobre R no método rxSetComputeContext, por exemplo:</span><span class="sxs-lookup"><span data-stu-id="b966d-162">For more information and examples of ScaleR compute contexts, see the inline help in R on the rxSetComputeContext method, for example:</span></span>

    > ?rxSetComputeContext

<span data-ttu-id="b966d-163">Você também pode consultar o “[Guia de computação distribuída do ScaleR](https://msdn.microsoft.com/microsoft-r/scaler-distributed-computing)” disponível na biblioteca [MSDN do R Server](https://msdn.microsoft.com/library/mt674634.aspx "R Server no MSDN").</span><span class="sxs-lookup"><span data-stu-id="b966d-163">You can also refer to the “[ScaleR Distributed Computing Guide](https://msdn.microsoft.com/microsoft-r/scaler-distributed-computing)” that's available from the [R Server MSDN](https://msdn.microsoft.com/library/mt674634.aspx "R Server on MSDN") library.</span></span>

## <a name="next-steps"></a><span data-ttu-id="b966d-164">Próximas etapas</span><span class="sxs-lookup"><span data-stu-id="b966d-164">Next steps</span></span>
<span data-ttu-id="b966d-165">Neste artigo você aprendeu sobre as opções que estão disponíveis para especificar se e como a execução é paralelizada entre núcleos do nó de borda ou o cluster HDInsight.</span><span class="sxs-lookup"><span data-stu-id="b966d-165">In this article, you learned about the options that are available to specify whether and how execution is parallelized across cores of the edge node or HDInsight cluster.</span></span> <span data-ttu-id="b966d-166">Para aprender mais sobre como usar o R Server com clusters HDInsight, veja os tópicos a seguir:</span><span class="sxs-lookup"><span data-stu-id="b966d-166">To learn more about how to use R Server with HDInsight clusters, see the following topics:</span></span>

* [<span data-ttu-id="b966d-167">Visão geral do Servidor R no Hadoop</span><span class="sxs-lookup"><span data-stu-id="b966d-167">Overview of R Server for Hadoop</span></span>](hdinsight-hadoop-r-server-overview.md)
* [<span data-ttu-id="b966d-168">Introdução ao Servidor R para o Hadoop</span><span class="sxs-lookup"><span data-stu-id="b966d-168">Get started with R Server for Hadoop</span></span>](hdinsight-hadoop-r-server-get-started.md)
* [<span data-ttu-id="b966d-169">Adicionar Servidor do RStudio ao HDInsight (se não instalado durante a criação de cluster)</span><span class="sxs-lookup"><span data-stu-id="b966d-169">Add RStudio Server to HDInsight (if not added during cluster creation)</span></span>](hdinsight-hadoop-r-server-install-r-studio.md)
* [<span data-ttu-id="b966d-170">Opções de Armazenamento do Azure para o Servidor R no HDInsight</span><span class="sxs-lookup"><span data-stu-id="b966d-170">Azure Storage options for R Server on HDInsight</span></span>](hdinsight-hadoop-r-server-storage.md)

