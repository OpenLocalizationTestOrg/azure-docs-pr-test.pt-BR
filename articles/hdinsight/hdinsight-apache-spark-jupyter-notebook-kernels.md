---
title: "clusters de aaaKernels para anotações do Jupyter no Spark no HDInsight do Azure | Microsoft Docs"
description: "Saiba mais sobre os kernels PySpark, PySpark3 e Spark Olá para anotações do Jupyter com clusters Spark no HDInsight do Azure."
keywords: "bloco de anotações do jupyter no spark, jupyter spark"
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 0719e503-ee6d-41ac-b37e-3d77db8b121b
ms.service: hdinsight
ms.custom: hdinsightactive,hdiseo17may2017
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 05/15/2017
ms.author: nitinme
ms.openlocfilehash: 560c944fe850c5753ac9fa90550b804f0c47d14c
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: pt-BR
ms.lasthandoff: 10/06/2017
---
# <a name="kernels-for-jupyter-notebook-on-spark-clusters-in-azure-hdinsight"></a><span data-ttu-id="aad85-104">Kernels para o bloco de anotações do Jupyter em clusters do Spark no Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="aad85-104">Kernels for Jupyter notebook on Spark clusters in Azure HDInsight</span></span> 

<span data-ttu-id="aad85-105">Os clusters de HDInsight Spark fornecem kernels que você pode usar anotações do Jupyter Olá no Spark para testar seus aplicativos.</span><span class="sxs-lookup"><span data-stu-id="aad85-105">HDInsight Spark clusters provide kernels that you can use with hello Jupyter notebook on Spark for testing your applications.</span></span> <span data-ttu-id="aad85-106">Um kernel é um programa que é executado e que interpreta seu código.</span><span class="sxs-lookup"><span data-stu-id="aad85-106">A kernel is a program that runs and interprets your code.</span></span> <span data-ttu-id="aad85-107">três kernels Olá são:</span><span class="sxs-lookup"><span data-stu-id="aad85-107">hello three kernels are:</span></span>

- <span data-ttu-id="aad85-108">**PySpark** - para aplicativos escritos em Python2</span><span class="sxs-lookup"><span data-stu-id="aad85-108">**PySpark** - for applications written in Python2</span></span>
- <span data-ttu-id="aad85-109">**PySpark3** - para aplicativos escritos em Python3</span><span class="sxs-lookup"><span data-stu-id="aad85-109">**PySpark3** - for applications written in Python3</span></span>
- <span data-ttu-id="aad85-110">**Spark** - para aplicativos escritos em Scala</span><span class="sxs-lookup"><span data-stu-id="aad85-110">**Spark** - for applications written in Scala</span></span>

<span data-ttu-id="aad85-111">Neste artigo, você aprenderá como toouse esses kernels e os benefícios de saudação de usá-los.</span><span class="sxs-lookup"><span data-stu-id="aad85-111">In this article, you learn how toouse these kernels and hello benefits of using them.</span></span>

## <a name="prerequisites"></a><span data-ttu-id="aad85-112">Pré-requisitos</span><span class="sxs-lookup"><span data-stu-id="aad85-112">Prerequisites</span></span>

* <span data-ttu-id="aad85-113">Um cluster do Apache Spark no HDInsight.</span><span class="sxs-lookup"><span data-stu-id="aad85-113">An Apache Spark cluster in HDInsight.</span></span> <span data-ttu-id="aad85-114">Para obter instruções, consulte o artigo sobre como [Criar clusters do Apache Spark no Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="aad85-114">For instructions, see [Create Apache Spark clusters in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>

## <a name="create-a-jupyter-notebook-on-spark-hdinsight"></a><span data-ttu-id="aad85-115">Criar um bloco de anotações do Jupyter no Spark HDInsight</span><span class="sxs-lookup"><span data-stu-id="aad85-115">Create a Jupyter notebook on Spark HDInsight</span></span>

1. <span data-ttu-id="aad85-116">De saudação [portal do Azure](https://portal.azure.com/), abra seu cluster.</span><span class="sxs-lookup"><span data-stu-id="aad85-116">From hello [Azure portal](https://portal.azure.com/), open your cluster.</span></span>  <span data-ttu-id="aad85-117">Consulte [lista e mostrar clusters](hdinsight-administer-use-portal-linux.md#list-and-show-clusters) para obter instruções de saudação.</span><span class="sxs-lookup"><span data-stu-id="aad85-117">See [List and show clusters](hdinsight-administer-use-portal-linux.md#list-and-show-clusters) for hello instructions.</span></span> <span data-ttu-id="aad85-118">cluster de saudação é aberto em uma nova folha de portal.</span><span class="sxs-lookup"><span data-stu-id="aad85-118">hello cluster is opened in a new portal blade.</span></span>

2. <span data-ttu-id="aad85-119">De saudação **links rápidos** seção, clique em **Cluster painéis** tooopen Olá **painéis do Cluster** folha.</span><span class="sxs-lookup"><span data-stu-id="aad85-119">From hello **Quick links** section, click **Cluster dashboards** tooopen hello **Cluster dashboards** blade.</span></span>  <span data-ttu-id="aad85-120">Se você não vir **Links rápidos**, clique em **visão geral** no menu esquerdo de saudação na folha de saudação.</span><span class="sxs-lookup"><span data-stu-id="aad85-120">If you don't see **Quick Links**, click **Overview** from hello left menu on hello blade.</span></span>

    <span data-ttu-id="aad85-121">![Bloco de anotações do Jupyter no Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/hdinsight-jupyter-notebook-on-spark.png "Bloco de anotações do Jupyter no Spark")</span><span class="sxs-lookup"><span data-stu-id="aad85-121">![Jupyter notebook on Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/hdinsight-jupyter-notebook-on-spark.png "Jupyter notebook on Spark")</span></span> 

3. <span data-ttu-id="aad85-122">Clique em **Notebook Jupyter**.</span><span class="sxs-lookup"><span data-stu-id="aad85-122">Click **Jupyter Notebook**.</span></span> <span data-ttu-id="aad85-123">Se solicitado, insira as credenciais de administrador de saudação para cluster hello.</span><span class="sxs-lookup"><span data-stu-id="aad85-123">If prompted, enter hello admin credentials for hello cluster.</span></span>
   
   > [!NOTE]
   > <span data-ttu-id="aad85-124">Você também pode acessar anotações do Jupyter Olá no cluster do Spark por Olá abrir URL a seguir em seu navegador.</span><span class="sxs-lookup"><span data-stu-id="aad85-124">You may also reach hello Jupyter notebook on Spark cluster by opening hello following URL in your browser.</span></span> <span data-ttu-id="aad85-125">Substituir **CLUSTERNAME** com nome de saudação do cluster:</span><span class="sxs-lookup"><span data-stu-id="aad85-125">Replace **CLUSTERNAME** with hello name of your cluster:</span></span>
   >
   > `https://CLUSTERNAME.azurehdinsight.net/jupyter`
   > 
   > 

3. <span data-ttu-id="aad85-126">Clique em **novo**e, em seguida, clique em **Pyspark**, **PySpark3**, ou **Spark** toocreate um bloco de anotações.</span><span class="sxs-lookup"><span data-stu-id="aad85-126">Click **New**, and then click either **Pyspark**, **PySpark3**, or **Spark** toocreate a notebook.</span></span> <span data-ttu-id="aad85-127">Use kernel do Spark Olá para aplicativos Scala kernel PySpark para aplicativos Python2 e PySpark3 kernel para aplicativos de Python3.</span><span class="sxs-lookup"><span data-stu-id="aad85-127">Use hello Spark kernel for Scala applications, PySpark kernel for Python2 applications, and PySpark3 kernel for Python3 applications.</span></span>
   
    <span data-ttu-id="aad85-128">![Kernels para bloco de anotações do Jupyter no Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/kernel-jupyter-notebook-on-spark.png "Kernels para bloco de anotações do Jupyter no Spark")</span><span class="sxs-lookup"><span data-stu-id="aad85-128">![Kernels for Jupyter notebook on Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/kernel-jupyter-notebook-on-spark.png "Kernels for Jupyter notebook on Spark")</span></span> 

4. <span data-ttu-id="aad85-129">Abre um bloco de anotações com kernel Olá selecionado.</span><span class="sxs-lookup"><span data-stu-id="aad85-129">A notebook opens with hello kernel you selected.</span></span>

## <a name="benefits-of-using-hello-kernels"></a><span data-ttu-id="aad85-130">Benefícios do uso de kernels Olá</span><span class="sxs-lookup"><span data-stu-id="aad85-130">Benefits of using hello kernels</span></span>

<span data-ttu-id="aad85-131">Aqui estão algumas vantagens de usar kernels novo Olá com anotações do Jupyter em clusters de HDInsight Spark.</span><span class="sxs-lookup"><span data-stu-id="aad85-131">Here are a few benefits of using hello new kernels with Jupyter notebook on Spark HDInsight clusters.</span></span>

- <span data-ttu-id="aad85-132">**Contextos de predefinição**.</span><span class="sxs-lookup"><span data-stu-id="aad85-132">**Preset contexts**.</span></span> <span data-ttu-id="aad85-133">Com **PySpark**, **PySpark3**, ou hello **Spark** kernels, você não precisa tooset Olá Spark ou Hive contextos explicitamente antes de começar a trabalhar com seus aplicativos.</span><span class="sxs-lookup"><span data-stu-id="aad85-133">With  **PySpark**, **PySpark3**, or hello **Spark** kernels, you do not need tooset hello Spark or Hive contexts explicitly before you start working with your applications.</span></span> <span data-ttu-id="aad85-134">Eles estão disponíveis para você por padrão.</span><span class="sxs-lookup"><span data-stu-id="aad85-134">These are available by default.</span></span> <span data-ttu-id="aad85-135">Esses contextos são:</span><span class="sxs-lookup"><span data-stu-id="aad85-135">These contexts are:</span></span>
   
   * <span data-ttu-id="aad85-136">**sc** - para o contexto do Spark</span><span class="sxs-lookup"><span data-stu-id="aad85-136">**sc** - for Spark context</span></span>
   * <span data-ttu-id="aad85-137">**sqlContext** : para o contexto Hive</span><span class="sxs-lookup"><span data-stu-id="aad85-137">**sqlContext** - for Hive context</span></span>

    <span data-ttu-id="aad85-138">Portanto, você não tem instruções toorun como Olá contextos de saudação tooset a seguir:</span><span class="sxs-lookup"><span data-stu-id="aad85-138">So, you don't have toorun statements like hello following tooset hello contexts:</span></span>

        <span data-ttu-id="aad85-139">sc = SparkContext('yarn-client')    sqlContext = HiveContext(sc)</span><span class="sxs-lookup"><span data-stu-id="aad85-139">sc = SparkContext('yarn-client')    sqlContext = HiveContext(sc)</span></span>

    <span data-ttu-id="aad85-140">Em vez disso, você pode usar diretamente Olá predefinição contextos em seu aplicativo.</span><span class="sxs-lookup"><span data-stu-id="aad85-140">Instead, you can directly use hello preset contexts in your application.</span></span>

- <span data-ttu-id="aad85-141">**A mágica da célula**.</span><span class="sxs-lookup"><span data-stu-id="aad85-141">**Cell magics**.</span></span> <span data-ttu-id="aad85-142">Olá PySpark kernel fornece algumas predefinidas "magics", que são comandos especiais que podem ser chamados com `%%` (por exemplo, `%%MAGIC` <args>).</span><span class="sxs-lookup"><span data-stu-id="aad85-142">hello PySpark kernel provides some predefined “magics”, which are special commands that you can call with `%%` (for example, `%%MAGIC` <args>).</span></span> <span data-ttu-id="aad85-143">comando magic Olá deve ser a primeira palavra hello em uma célula de código e permitir várias linhas de conteúdo.</span><span class="sxs-lookup"><span data-stu-id="aad85-143">hello magic command must be hello first word in a code cell and allow for multiple lines of content.</span></span> <span data-ttu-id="aad85-144">palavra mágica Olá deve ser a primeira palavra hello na célula de saudação.</span><span class="sxs-lookup"><span data-stu-id="aad85-144">hello magic word should be hello first word in hello cell.</span></span> <span data-ttu-id="aad85-145">Adicionar qualquer coisa antes magic hello, até mesmo comentários, causa um erro.</span><span class="sxs-lookup"><span data-stu-id="aad85-145">Adding anything before hello magic, even comments, causes an error.</span></span>     <span data-ttu-id="aad85-146">Para saber mais sobre palavras mágicas, clique [aqui](http://ipython.readthedocs.org/en/stable/interactive/magics.html).</span><span class="sxs-lookup"><span data-stu-id="aad85-146">For more information on magics, see [here](http://ipython.readthedocs.org/en/stable/interactive/magics.html).</span></span>
   
    <span data-ttu-id="aad85-147">Olá tabela a seguir lista magics diferente da saudação disponíveis por meio de kernels hello.</span><span class="sxs-lookup"><span data-stu-id="aad85-147">hello following table lists hello different magics available through hello kernels.</span></span>

   | <span data-ttu-id="aad85-148">Mágica</span><span class="sxs-lookup"><span data-stu-id="aad85-148">Magic</span></span> | <span data-ttu-id="aad85-149">Exemplo</span><span class="sxs-lookup"><span data-stu-id="aad85-149">Example</span></span> | <span data-ttu-id="aad85-150">Descrição</span><span class="sxs-lookup"><span data-stu-id="aad85-150">Description</span></span> |
   | --- | --- | --- |
   | <span data-ttu-id="aad85-151">ajuda</span><span class="sxs-lookup"><span data-stu-id="aad85-151">help</span></span> |`%%help` |<span data-ttu-id="aad85-152">Gera uma tabela de todos os magics de saudação disponíveis com o exemplo e uma descrição</span><span class="sxs-lookup"><span data-stu-id="aad85-152">Generates a table of all hello available magics with example and description</span></span> |
   | <span data-ttu-id="aad85-153">informações</span><span class="sxs-lookup"><span data-stu-id="aad85-153">info</span></span> |`%%info` |<span data-ttu-id="aad85-154">Informações de sessão de saídas para o ponto de extremidade de Livy atual Olá</span><span class="sxs-lookup"><span data-stu-id="aad85-154">Outputs session information for hello current Livy endpoint</span></span> |
   | <span data-ttu-id="aad85-155">CONFIGURAR</span><span class="sxs-lookup"><span data-stu-id="aad85-155">configure</span></span> |`%%configure -f`<br><span data-ttu-id="aad85-156">`{"executorMemory": "1000M"`,</span><span class="sxs-lookup"><span data-stu-id="aad85-156">`{"executorMemory": "1000M"`,</span></span><br><span data-ttu-id="aad85-157">`"executorCores": 4`}</span><span class="sxs-lookup"><span data-stu-id="aad85-157">`"executorCores": 4`}</span></span> |<span data-ttu-id="aad85-158">Configura os parâmetros de saudação para criar uma sessão.</span><span class="sxs-lookup"><span data-stu-id="aad85-158">Configures hello parameters for creating a session.</span></span> <span data-ttu-id="aad85-159">Olá sinalizador force (-f) é obrigatório se uma sessão já foi criada, que garante que essa sessão Olá será descartada e recriada.</span><span class="sxs-lookup"><span data-stu-id="aad85-159">hello force flag (-f) is mandatory if a session has already been created, which ensures that hello session is dropped and recreated.</span></span> <span data-ttu-id="aad85-160">Veja o [Corpo da Solicitação POST /sessions da Livy](https://github.com/cloudera/livy#request-body) para obter uma lista de parâmetros válidos.</span><span class="sxs-lookup"><span data-stu-id="aad85-160">Look at [Livy's POST /sessions Request Body](https://github.com/cloudera/livy#request-body) for a list of valid parameters.</span></span> <span data-ttu-id="aad85-161">Parâmetros devem ser passados como uma cadeia de caracteres JSON e devem estar na próxima linha de saudação após magic Olá, conforme mostrado na coluna de exemplo hello.</span><span class="sxs-lookup"><span data-stu-id="aad85-161">Parameters must be passed in as a JSON string and must be on hello next line after hello magic, as shown in hello example column.</span></span> |
   | <span data-ttu-id="aad85-162">sql</span><span class="sxs-lookup"><span data-stu-id="aad85-162">sql</span></span> |`%%sql -o <variable name>`<br> `SHOW TABLES` |<span data-ttu-id="aad85-163">Executa uma consulta de Hive em Olá sqlContext.</span><span class="sxs-lookup"><span data-stu-id="aad85-163">Executes a Hive query against hello sqlContext.</span></span> <span data-ttu-id="aad85-164">Se hello `-o` parâmetro for passado, o resultado de saudação de consulta de saudação é mantido no Olá % % contexto Python local como um [Pandas](http://pandas.pydata.org/) dataframe.</span><span class="sxs-lookup"><span data-stu-id="aad85-164">If hello `-o` parameter is passed, hello result of hello query is persisted in hello %%local Python context as a [Pandas](http://pandas.pydata.org/) dataframe.</span></span> |
   | <span data-ttu-id="aad85-165">local</span><span class="sxs-lookup"><span data-stu-id="aad85-165">local</span></span> |`%%local`<br>`a=1` |<span data-ttu-id="aad85-166">Todo o código Olá linhas subsequentes é executado localmente.</span><span class="sxs-lookup"><span data-stu-id="aad85-166">All hello code in subsequent lines is executed locally.</span></span> <span data-ttu-id="aad85-167">Código deve ser o código Python2 válido mesmo independentemente do kernel Olá que você está usando.</span><span class="sxs-lookup"><span data-stu-id="aad85-167">Code must be valid Python2 code even irrespective of hello kernel you are using.</span></span> <span data-ttu-id="aad85-168">Portanto, mesmo se você selecionou **PySpark3** ou **Spark** kernels durante a criação de notebook hello, se você usar o hello `%%local` magic em uma célula, essa célula só deve ter código Python2 válido.</span><span class="sxs-lookup"><span data-stu-id="aad85-168">So, even if you selected **PySpark3** or **Spark** kernels while creating hello notebook, if you use hello `%%local` magic in a cell, that cell must only have valid Python2 code..</span></span> |
   | <span data-ttu-id="aad85-169">logs</span><span class="sxs-lookup"><span data-stu-id="aad85-169">logs</span></span> |`%%logs` |<span data-ttu-id="aad85-170">Saídas hello logs para a sessão atual de Livy hello.</span><span class="sxs-lookup"><span data-stu-id="aad85-170">Outputs hello logs for hello current Livy session.</span></span> |
   | <span data-ttu-id="aad85-171">excluir</span><span class="sxs-lookup"><span data-stu-id="aad85-171">delete</span></span> |`%%delete -f -s <session number>` |<span data-ttu-id="aad85-172">Exclui uma sessão específica do ponto de extremidade de Livy atual hello.</span><span class="sxs-lookup"><span data-stu-id="aad85-172">Deletes a specific session of hello current Livy endpoint.</span></span> <span data-ttu-id="aad85-173">Observe que você não pode excluir a sessão Olá iniciado para o kernel Olá em si.</span><span class="sxs-lookup"><span data-stu-id="aad85-173">Note that you cannot delete hello session that is initiated for hello kernel itself.</span></span> |
   | <span data-ttu-id="aad85-174">limpeza</span><span class="sxs-lookup"><span data-stu-id="aad85-174">cleanup</span></span> |`%%cleanup -f` |<span data-ttu-id="aad85-175">Exclui todas as sessões de Olá Olá atual Livy ponto de extremidade, incluindo sessão deste bloco de anotações.</span><span class="sxs-lookup"><span data-stu-id="aad85-175">Deletes all hello sessions for hello current Livy endpoint, including this notebook's session.</span></span> <span data-ttu-id="aad85-176">Olá force sinalizador -f é obrigatório.</span><span class="sxs-lookup"><span data-stu-id="aad85-176">hello force flag -f is mandatory.</span></span> |

   > [!NOTE]
   > <span data-ttu-id="aad85-177">Além disso toohello magics adicionado pelo kernel de PySpark hello, você também pode usar o hello [magics internos do IPython](https://ipython.org/ipython-doc/3/interactive/magics.html#cell-magics), incluindo `%%sh`.</span><span class="sxs-lookup"><span data-stu-id="aad85-177">In addition toohello magics added by hello PySpark kernel, you can also use hello [built-in IPython magics](https://ipython.org/ipython-doc/3/interactive/magics.html#cell-magics), including `%%sh`.</span></span> <span data-ttu-id="aad85-178">Você pode usar o hello `%%sh` magic toorun scripts e blocos de código em um nó de cluster principal hello.</span><span class="sxs-lookup"><span data-stu-id="aad85-178">You can use hello `%%sh` magic toorun scripts and block of code on hello cluster headnode.</span></span>
   >
   >
2. <span data-ttu-id="aad85-179">**Visualização automática**.</span><span class="sxs-lookup"><span data-stu-id="aad85-179">**Auto visualization**.</span></span> <span data-ttu-id="aad85-180">Olá **Pyspark** kernel automaticamente visualiza a saída de saudação de consultas de Hive e SQL.</span><span class="sxs-lookup"><span data-stu-id="aad85-180">hello **Pyspark** kernel automatically visualizes hello output of Hive and SQL queries.</span></span> <span data-ttu-id="aad85-181">Escolha entre vários tipos diferentes de visualização, incluindo Tabela, Pizza, Linha, Área, Barra.</span><span class="sxs-lookup"><span data-stu-id="aad85-181">You can choose between several different types of visualizations including Table, Pie, Line, Area, Bar.</span></span>

## <a name="parameters-supported-with-hello-sql-magic"></a><span data-ttu-id="aad85-182">Parâmetros de suporte com hello % % mágico do sql</span><span class="sxs-lookup"><span data-stu-id="aad85-182">Parameters supported with hello %%sql magic</span></span>
<span data-ttu-id="aad85-183">Olá `%%sql` magic dá suporte a parâmetros diferentes que você pode usar o tipo de saudação do toocontrol de saída que você recebe ao executar consultas.</span><span class="sxs-lookup"><span data-stu-id="aad85-183">hello `%%sql` magic supports different parameters that you can use toocontrol hello kind of output that you receive when you run queries.</span></span> <span data-ttu-id="aad85-184">Olá a tabela a seguir lista a saída de hello.</span><span class="sxs-lookup"><span data-stu-id="aad85-184">hello following table lists hello output.</span></span>

| <span data-ttu-id="aad85-185">Parâmetro</span><span class="sxs-lookup"><span data-stu-id="aad85-185">Parameter</span></span> | <span data-ttu-id="aad85-186">Exemplo</span><span class="sxs-lookup"><span data-stu-id="aad85-186">Example</span></span> | <span data-ttu-id="aad85-187">Descrição</span><span class="sxs-lookup"><span data-stu-id="aad85-187">Description</span></span> |
| --- | --- | --- |
| <span data-ttu-id="aad85-188">-o</span><span class="sxs-lookup"><span data-stu-id="aad85-188">-o</span></span> |`-o <VARIABLE NAME>` |<span data-ttu-id="aad85-189">Use esse resultado parâmetro toopersist Olá Olá consulta, em Olá % % contexto Python local, como um [Pandas](http://pandas.pydata.org/) dataframe.</span><span class="sxs-lookup"><span data-stu-id="aad85-189">Use this parameter toopersist hello result of hello query, in hello %%local Python context, as a [Pandas](http://pandas.pydata.org/) dataframe.</span></span> <span data-ttu-id="aad85-190">nome de saudação da variável de dataframe de saudação é o nome de variável de saudação que você especificar.</span><span class="sxs-lookup"><span data-stu-id="aad85-190">hello name of hello dataframe variable is hello variable name you specify.</span></span> |
| <span data-ttu-id="aad85-191">-q</span><span class="sxs-lookup"><span data-stu-id="aad85-191">-q</span></span> |`-q` |<span data-ttu-id="aad85-192">Use este tooturn desativar visualizações de célula hello.</span><span class="sxs-lookup"><span data-stu-id="aad85-192">Use this tooturn off visualizations for hello cell.</span></span> <span data-ttu-id="aad85-193">Se você não quiser tooauto-visualizar o conteúdo de saudação de uma célula e deseja apenas toocapture-lo como um dataframe, em seguida, use `-q -o <VARIABLE>`.</span><span class="sxs-lookup"><span data-stu-id="aad85-193">If you don't want tooauto-visualize hello content of a cell and just want toocapture it as a dataframe, then use `-q -o <VARIABLE>`.</span></span> <span data-ttu-id="aad85-194">Se você quiser tooturn desativar visualizações sem capturando Olá resultados (por exemplo, para executar uma consulta SQL, como um `CREATE TABLE` instrução), use `-q` sem especificar um `-o` argumento.</span><span class="sxs-lookup"><span data-stu-id="aad85-194">If you want tooturn off visualizations without capturing hello results (for example, for running a SQL query, like a `CREATE TABLE` statement), use `-q` without specifying a `-o` argument.</span></span> |
| <span data-ttu-id="aad85-195">-m</span><span class="sxs-lookup"><span data-stu-id="aad85-195">-m</span></span> |`-m <METHOD>` |<span data-ttu-id="aad85-196">Onde **METHOD** é **take** ou **sample** (o padrão é **take**).</span><span class="sxs-lookup"><span data-stu-id="aad85-196">Where **METHOD** is either **take** or **sample** (default is **take**).</span></span> <span data-ttu-id="aad85-197">Se o método hello é **levar**, kernel Olá escolhe elementos da parte superior de saudação do conjunto de resultados de saudação especificado pelo MAXROWS (descrito posteriormente nesta tabela).</span><span class="sxs-lookup"><span data-stu-id="aad85-197">If hello method is **take**, hello kernel picks elements from hello top of hello result data set specified by MAXROWS (described later in this table).</span></span> <span data-ttu-id="aad85-198">Se o método hello é **exemplo**, kernel Olá aleatoriamente exemplos de elementos de saudação do conjunto de dados de acordo com muito`-r` parâmetro, como descrito a seguir nesta tabela.</span><span class="sxs-lookup"><span data-stu-id="aad85-198">If hello method is **sample**, hello kernel randomly samples elements of hello data set according too`-r` parameter, described next in this table.</span></span> |
| <span data-ttu-id="aad85-199">-r</span><span class="sxs-lookup"><span data-stu-id="aad85-199">-r</span></span> |`-r <FRACTION>` |<span data-ttu-id="aad85-200">Aqui **FRACTION** é um número de ponto flutuante entre 0.0 e 1.0.</span><span class="sxs-lookup"><span data-stu-id="aad85-200">Here **FRACTION** is a floating-point number between 0.0 and 1.0.</span></span> <span data-ttu-id="aad85-201">Se o método do exemplo hello para consulta SQL Olá é `sample`, em seguida, o kernel Olá aleatoriamente amostras de fração de saudação especificado de elementos de saudação do hello conjunto de resultados para você.</span><span class="sxs-lookup"><span data-stu-id="aad85-201">If hello sample method for hello SQL query is `sample`, then hello kernel randomly samples hello specified fraction of hello elements of hello result set for you.</span></span> <span data-ttu-id="aad85-202">Por exemplo, se você executar uma consulta SQL com argumentos Olá `-m sample -r 0.01`, em seguida, % 1 Olá de linhas de resultado são amostrados aleatoriamente.</span><span class="sxs-lookup"><span data-stu-id="aad85-202">For example, if you run a SQL query with hello arguments `-m sample -r 0.01`, then 1% of hello result rows are randomly sampled.</span></span> |
| -n |`-n <MAXROWS>` |<span data-ttu-id="aad85-203">**MAXROWS** é um valor inteiro.</span><span class="sxs-lookup"><span data-stu-id="aad85-203">**MAXROWS** is an integer value.</span></span> <span data-ttu-id="aad85-204">kernel Olá limita o número de saudação de linhas de saída muito**MAXROWS**.</span><span class="sxs-lookup"><span data-stu-id="aad85-204">hello kernel limits hello number of output rows too**MAXROWS**.</span></span> <span data-ttu-id="aad85-205">Se **MAXROWS** é um número negativo como **-1**, em seguida, Olá número de linhas no conjunto de resultados de saudação não é limitado.</span><span class="sxs-lookup"><span data-stu-id="aad85-205">If **MAXROWS** is a negative number such as **-1**, then hello number of rows in hello result set is not limited.</span></span> |

<span data-ttu-id="aad85-206">**Exemplo:**</span><span class="sxs-lookup"><span data-stu-id="aad85-206">**Example:**</span></span>

    %%sql -q -m sample -r 0.1 -n 500 -o query2
    SELECT * FROM hivesampletable

<span data-ttu-id="aad85-207">instrução de saudação acima Olá a seguir:</span><span class="sxs-lookup"><span data-stu-id="aad85-207">hello statement above does hello following:</span></span>

* <span data-ttu-id="aad85-208">Seleciona todos os registros de **hivesampletable**.</span><span class="sxs-lookup"><span data-stu-id="aad85-208">Selects all records from **hivesampletable**.</span></span>
* <span data-ttu-id="aad85-209">Como usamos - q, ele desativa a visualização automática.</span><span class="sxs-lookup"><span data-stu-id="aad85-209">Because we use -q, it turns off auto-visualization.</span></span>
* <span data-ttu-id="aad85-210">Porque usamos `-m sample -r 0.1 -n 500` -amostras de 10% das linhas Olá Olá hivesampletable aleatoriamente e Olá de limites de tamanho de linhas de too500 do conjunto de resultados de saudação.</span><span class="sxs-lookup"><span data-stu-id="aad85-210">Because we use `-m sample -r 0.1 -n 500` it randomly samples 10% of hello rows in hello hivesampletable and limits hello size of hello result set too500 rows.</span></span>
* <span data-ttu-id="aad85-211">Por fim, porque usamos `-o query2` saída Olá também salva em um dataframe chamado **consulta2**.</span><span class="sxs-lookup"><span data-stu-id="aad85-211">Finally, because we used `-o query2` it also saves hello output into a dataframe called **query2**.</span></span>

## <a name="considerations-while-using-hello-new-kernels"></a><span data-ttu-id="aad85-212">Considerações ao usar o hello kernels novo</span><span class="sxs-lookup"><span data-stu-id="aad85-212">Considerations while using hello new kernels</span></span>

<span data-ttu-id="aad85-213">Seja qual for o kernel usar, deixar notebooks Olá com consome recursos de cluster de saudação.</span><span class="sxs-lookup"><span data-stu-id="aad85-213">Whichever kernel you use, leaving hello notebooks running consumes hello cluster resources.</span></span>  <span data-ttu-id="aad85-214">Com esses kernels, porque os contextos de saudação são predefinidos, simplesmente sair notebooks Olá não kill contexto hello e, portanto, os recursos de cluster Olá continuam toobe em uso.</span><span class="sxs-lookup"><span data-stu-id="aad85-214">With these kernels, because hello contexts are preset, simply exiting hello notebooks does not kill hello context and hence hello cluster resources continue toobe in use.</span></span> <span data-ttu-id="aad85-215">Uma prática recomendada é Olá toouse **fechar e interromper** opção a partir do bloco de anotações Olá **arquivo** menu quando terminar de usar notebook hello, o que elimina o contexto de saudação e, em seguida, sai Olá notebook.</span><span class="sxs-lookup"><span data-stu-id="aad85-215">A good practice is toouse hello **Close and Halt** option from hello notebook's **File** menu when you are finished using hello notebook, which kills hello context and then exits hello notebook.</span></span>     

## <a name="show-me-some-examples"></a><span data-ttu-id="aad85-216">Mostre-me alguns exemplos</span><span class="sxs-lookup"><span data-stu-id="aad85-216">Show me some examples</span></span>

<span data-ttu-id="aad85-217">Quando você abre um bloco de anotações do Jupyter, verá duas pastas disponíveis no nível raiz de saudação.</span><span class="sxs-lookup"><span data-stu-id="aad85-217">When you open a Jupyter notebook, you see two folders available at hello root level.</span></span>

* <span data-ttu-id="aad85-218">Olá **PySpark** pasta tiver blocos de anotações do exemplo hello que use novo **Python** kernel.</span><span class="sxs-lookup"><span data-stu-id="aad85-218">hello **PySpark** folder has sample notebooks that use hello new **Python** kernel.</span></span>
* <span data-ttu-id="aad85-219">Olá **Scala** pasta tiver blocos de anotações do exemplo hello que use novo **Spark** kernel.</span><span class="sxs-lookup"><span data-stu-id="aad85-219">hello **Scala** folder has sample notebooks that use hello new **Spark** kernel.</span></span>

<span data-ttu-id="aad85-220">Você pode abrir Olá **00 - [LEIA-ME primeiro] recursos de Kernel do Spark Magic** notebook de saudação **PySpark** ou **Spark** toolearn pasta sobre magics diferente da saudação disponíveis.</span><span class="sxs-lookup"><span data-stu-id="aad85-220">You can open hello **00 - [READ ME FIRST] Spark Magic Kernel Features** notebook from hello **PySpark** or **Spark** folder toolearn about hello different magics available.</span></span> <span data-ttu-id="aad85-221">Você também pode usar Olá outros blocos de anotações do exemplo disponíveis em Olá duas pastas toolearn como tooachieve diferentes cenários de uso de anotações do Jupyter com clusters de HDInsight Spark.</span><span class="sxs-lookup"><span data-stu-id="aad85-221">You can also use hello other sample notebooks available under hello two folders toolearn how tooachieve different scenarios using Jupyter notebooks with HDInsight Spark clusters.</span></span>

## <a name="where-are-hello-notebooks-stored"></a><span data-ttu-id="aad85-222">Onde estão armazenados os blocos de anotações Olá?</span><span class="sxs-lookup"><span data-stu-id="aad85-222">Where are hello notebooks stored?</span></span>

<span data-ttu-id="aad85-223">Blocos de anotações do Jupyter são salvos toohello conta de armazenamento associada Olá cluster em Olá **/HdiNotebooks** pasta.</span><span class="sxs-lookup"><span data-stu-id="aad85-223">Jupyter notebooks are saved toohello storage account associated with hello cluster under hello **/HdiNotebooks** folder.</span></span>  <span data-ttu-id="aad85-224">Blocos de anotações, arquivos de texto e pastas que você criar no Jupyter são acessíveis Olá da conta de armazenamento.</span><span class="sxs-lookup"><span data-stu-id="aad85-224">Notebooks, text files, and folders that you create from within Jupyter are accessible from hello storage account.</span></span>  <span data-ttu-id="aad85-225">Por exemplo, se você usar uma pasta de toocreate de Jupyter **minhapasta** e um bloco de anotações **myfolder/mynotebook.ipynb**, você pode acessar esse bloco no `/HdiNotebooks/myfolder/mynotebook.ipynb` na conta de armazenamento hello.</span><span class="sxs-lookup"><span data-stu-id="aad85-225">For example, if you use Jupyter toocreate a folder **myfolder** and a notebook **myfolder/mynotebook.ipynb**, you can access that notebook at `/HdiNotebooks/myfolder/mynotebook.ipynb` within hello storage account.</span></span>  <span data-ttu-id="aad85-226">Olá inverso também é verdadeiro, ou seja, se você carregar um bloco de anotações diretamente a conta de armazenamento tooyour em `/HdiNotebooks/mynotebook1.ipynb`, notebook Olá também é visível do Jupyter.</span><span class="sxs-lookup"><span data-stu-id="aad85-226">hello reverse is also true, that is, if you upload a notebook directly tooyour storage account at `/HdiNotebooks/mynotebook1.ipynb`, hello notebook is visible from Jupyter as well.</span></span>  <span data-ttu-id="aad85-227">Blocos de anotações permanecem na conta de armazenamento Olá mesmo após Olá cluster é excluído.</span><span class="sxs-lookup"><span data-stu-id="aad85-227">Notebooks remain in hello storage account even after hello cluster is deleted.</span></span>

<span data-ttu-id="aad85-228">modo de Olá anotações são salvas toohello conta de armazenamento é compatível com o HDFS.</span><span class="sxs-lookup"><span data-stu-id="aad85-228">hello way notebooks are saved toohello storage account is compatible with HDFS.</span></span> <span data-ttu-id="aad85-229">Portanto, se você SSH em cluster Olá que você pode usar comandos de gerenciamento de arquivos conforme Olá trecho de código a seguir:</span><span class="sxs-lookup"><span data-stu-id="aad85-229">So, if you SSH into hello cluster you can use file management commands as shown in hello following snippet:</span></span>

    hdfs dfs -ls /HdiNotebooks                               # List everything at hello root directory – everything in this directory is visible tooJupyter from hello home page
    hdfs dfs –copyToLocal /HdiNotebooks                    # Download hello contents of hello HdiNotebooks folder
    hdfs dfs –copyFromLocal example.ipynb /HdiNotebooks   # Upload a notebook example.ipynb toohello root folder so it’s visible from Jupyter


<span data-ttu-id="aad85-230">Caso haja problemas para acessar a conta de armazenamento Olá para cluster hello, notebooks Olá também são salvas em um nó principal do hello `/var/lib/jupyter`.</span><span class="sxs-lookup"><span data-stu-id="aad85-230">In case there are issues accessing hello storage account for hello cluster, hello notebooks are also saved on hello headnode `/var/lib/jupyter`.</span></span>

## <a name="supported-browser"></a><span data-ttu-id="aad85-231">Navegador com suporte</span><span class="sxs-lookup"><span data-stu-id="aad85-231">Supported browser</span></span>

<span data-ttu-id="aad85-232">Os blocos de anotações do Jupyter em clusters do Spark HDInsight só têm suporte no Google Chrome.</span><span class="sxs-lookup"><span data-stu-id="aad85-232">Jupyter notebooks on Spark HDInsight clusters are supported only on Google Chrome.</span></span>

## <a name="feedback"></a><span data-ttu-id="aad85-233">Comentários</span><span class="sxs-lookup"><span data-stu-id="aad85-233">Feedback</span></span>
<span data-ttu-id="aad85-234">kernels novo Olá estão em evolução estágio e serão amadurecer ao longo do tempo.</span><span class="sxs-lookup"><span data-stu-id="aad85-234">hello new kernels are in evolving stage and will mature over time.</span></span> <span data-ttu-id="aad85-235">Isso também pode significar que as APIs podem mudar à medida que esses kernels amadurecem.</span><span class="sxs-lookup"><span data-stu-id="aad85-235">This could also mean that APIs could change as these kernels mature.</span></span> <span data-ttu-id="aad85-236">Agradecemos o envio quaisquer comentários que você tenha ao usar esses novos kernels.</span><span class="sxs-lookup"><span data-stu-id="aad85-236">We would appreciate any feedback that you have while using these new kernels.</span></span> <span data-ttu-id="aad85-237">Isso é útil na versão final de saudação desses kernels de formatação.</span><span class="sxs-lookup"><span data-stu-id="aad85-237">This is useful in shaping hello final release of these kernels.</span></span> <span data-ttu-id="aad85-238">Você pode deixar seus comentários/comentários em Olá **comentários** seção Olá final deste artigo.</span><span class="sxs-lookup"><span data-stu-id="aad85-238">You can leave your comments/feedback under hello **Comments** section at hello bottom of this article.</span></span>

## <span data-ttu-id="aad85-239"><a name="seealso"></a>Consulte também</span><span class="sxs-lookup"><span data-stu-id="aad85-239"><a name="seealso"></a>See also</span></span>
* [<span data-ttu-id="aad85-240">Visão geral: Apache Spark no Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="aad85-240">Overview: Apache Spark on Azure HDInsight</span></span>](hdinsight-apache-spark-overview.md)

### <a name="scenarios"></a><span data-ttu-id="aad85-241">Cenários</span><span class="sxs-lookup"><span data-stu-id="aad85-241">Scenarios</span></span>
* [<span data-ttu-id="aad85-242">Spark com BI: executar análise de dados interativa usando o Spark no HDInsight com ferramentas de BI</span><span class="sxs-lookup"><span data-stu-id="aad85-242">Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools</span></span>](hdinsight-apache-spark-use-bi-tools.md)
* [<span data-ttu-id="aad85-243">Spark com Aprendizado de Máquina: usar o Spark no HDInsight para analisar a temperatura de prédios usando dados do sistema HVAC</span><span class="sxs-lookup"><span data-stu-id="aad85-243">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="aad85-244">Spark com o aprendizado de máquina: Use Spark nos resultados de inspeção de alimentos HDInsight toopredict</span><span class="sxs-lookup"><span data-stu-id="aad85-244">Spark with Machine Learning: Use Spark in HDInsight toopredict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="aad85-245">Streaming Spark: usar o Spark no HDInsight para a criação de aplicativos de streaming em tempo real</span><span class="sxs-lookup"><span data-stu-id="aad85-245">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="aad85-246">Análise de log do site usando o Spark no HDInsight</span><span class="sxs-lookup"><span data-stu-id="aad85-246">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)

### <a name="create-and-run-applications"></a><span data-ttu-id="aad85-247">Criar e executar aplicativos</span><span class="sxs-lookup"><span data-stu-id="aad85-247">Create and run applications</span></span>
* [<span data-ttu-id="aad85-248">Criar um aplicativo autônomo usando Scala</span><span class="sxs-lookup"><span data-stu-id="aad85-248">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="aad85-249">Executar trabalhos remotamente em um cluster do Spark usando Livy</span><span class="sxs-lookup"><span data-stu-id="aad85-249">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)

### <a name="tools-and-extensions"></a><span data-ttu-id="aad85-250">Ferramentas e extensões</span><span class="sxs-lookup"><span data-stu-id="aad85-250">Tools and extensions</span></span>
* [<span data-ttu-id="aad85-251">Usar o plug-in de ferramentas de HDInsight para toocreate IntelliJ IDEIA e enviar Spark Scala aplicativos</span><span class="sxs-lookup"><span data-stu-id="aad85-251">Use HDInsight Tools Plugin for IntelliJ IDEA toocreate and submit Spark Scala applications</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="aad85-252">Usar o plug-in de ferramentas de HDInsight para aplicativos de Spark toodebug IntelliJ IDEIA remotamente</span><span class="sxs-lookup"><span data-stu-id="aad85-252">Use HDInsight Tools Plugin for IntelliJ IDEA toodebug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="aad85-253">Usar blocos de anotações do Zeppelin com um cluster Spark no HDInsight</span><span class="sxs-lookup"><span data-stu-id="aad85-253">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="aad85-254">Usar pacotes externos com blocos de notas Jupyter</span><span class="sxs-lookup"><span data-stu-id="aad85-254">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="aad85-255">Instalar Jupyter em seu computador e conecte-se tooan cluster HDInsight Spark</span><span class="sxs-lookup"><span data-stu-id="aad85-255">Install Jupyter on your computer and connect tooan HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)

### <a name="manage-resources"></a><span data-ttu-id="aad85-256">Gerenciar recursos</span><span class="sxs-lookup"><span data-stu-id="aad85-256">Manage resources</span></span>
* [<span data-ttu-id="aad85-257">Gerenciar os recursos de cluster do hello Apache Spark no HDInsight do Azure</span><span class="sxs-lookup"><span data-stu-id="aad85-257">Manage resources for hello Apache Spark cluster in Azure HDInsight</span></span>](hdinsight-apache-spark-resource-manager.md)
* [<span data-ttu-id="aad85-258">Rastrear e depurar trabalhos em execução em um cluster do Apache Spark no HDInsight</span><span class="sxs-lookup"><span data-stu-id="aad85-258">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)
