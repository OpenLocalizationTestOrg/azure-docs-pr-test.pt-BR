---
title: cluster de aaaManage recursos para o Apache Spark no HDInsight do Azure | Microsoft Docs
description: Saiba como toouse gerenciar os recursos de clusters Spark no Azure HDInsight para melhorar o desempenho.
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 9da7d4e3-458e-4296-a628-77b14643f7e4
ms.service: hdinsight
ms.custom: hdinsightactive
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 07/21/2017
ms.author: nitinme
ms.openlocfilehash: e18682a24f77494db884105f9db03c0a350ddad6
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: pt-BR
ms.lasthandoff: 10/06/2017
---
# <a name="manage-resources-for-apache-spark-cluster-on-azure-hdinsight"></a><span data-ttu-id="8dc9e-103">Gerenciar os recursos para o cluster do Apache Spark no Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="8dc9e-103">Manage resources for Apache Spark cluster on Azure HDInsight</span></span> 

<span data-ttu-id="8dc9e-104">Neste artigo, você aprenderá como interfaces de saudação tooaccess como Ambari UI, YARN da interface do usuário e Olá Spark histórico servidor associado ao seu cluster Spark.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-104">In this article you will learn how tooaccess hello interfaces like Ambari UI, YARN UI, and hello Spark History Server associated with your Spark cluster.</span></span> <span data-ttu-id="8dc9e-105">Você também aprenderá como tootune Olá configuração de cluster para o desempenho ideal.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-105">You will also learn about how tootune hello cluster configuration for optimal performance.</span></span>

<span data-ttu-id="8dc9e-106">**Pré-requisitos:**</span><span class="sxs-lookup"><span data-stu-id="8dc9e-106">**Prerequisites:**</span></span>

<span data-ttu-id="8dc9e-107">Você deve ter o seguinte hello:</span><span class="sxs-lookup"><span data-stu-id="8dc9e-107">You must have hello following:</span></span>

* <span data-ttu-id="8dc9e-108">Uma assinatura do Azure.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-108">An Azure subscription.</span></span> <span data-ttu-id="8dc9e-109">Consulte [Obter avaliação gratuita do Azure](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span><span class="sxs-lookup"><span data-stu-id="8dc9e-109">See [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span></span>
* <span data-ttu-id="8dc9e-110">Um cluster do Apache Spark no HDInsight.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-110">An Apache Spark cluster on HDInsight.</span></span> <span data-ttu-id="8dc9e-111">Para obter instruções, consulte o artigo sobre como [Criar clusters do Apache Spark no Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="8dc9e-111">For instructions, see [Create Apache Spark clusters in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>

## <a name="how-do-i-launch-hello-ambari-web-ui"></a><span data-ttu-id="8dc9e-112">Como iniciar o hello da interface do usuário do Ambari Web?</span><span class="sxs-lookup"><span data-stu-id="8dc9e-112">How do I launch hello Ambari Web UI?</span></span>
1. <span data-ttu-id="8dc9e-113">De saudação [Portal do Azure](https://portal.azure.com/), do quadro de saudação inicial, clique em bloco de saudação para seu cluster Spark (se tê-fixado quadro toohello inicial).</span><span class="sxs-lookup"><span data-stu-id="8dc9e-113">From hello [Azure Portal](https://portal.azure.com/), from hello startboard, click hello tile for your Spark cluster (if you pinned it toohello startboard).</span></span> <span data-ttu-id="8dc9e-114">Você também pode navegar cluster tooyour em **procurar todos os** > **Clusters HDInsight**.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-114">You can also navigate tooyour cluster under **Browse All** > **HDInsight Clusters**.</span></span>
2. <span data-ttu-id="8dc9e-115">Na folha de cluster do Spark hello, clique em **painel**.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-115">From hello Spark cluster blade, click **Dashboard**.</span></span> <span data-ttu-id="8dc9e-116">Quando solicitado, insira as credenciais de administrador Olá para o cluster do Spark hello.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-116">When prompted, enter hello admin credentials for hello Spark cluster.</span></span>

    <span data-ttu-id="8dc9e-117">![Inicie o Ambari](./media/hdinsight-apache-spark-resource-manager/hdinsight-launch-cluster-dashboard.png "iniciar o Gerenciador de recursos")</span><span class="sxs-lookup"><span data-stu-id="8dc9e-117">![Launch Ambari](./media/hdinsight-apache-spark-resource-manager/hdinsight-launch-cluster-dashboard.png "Start Resource Manager")</span></span>
3. <span data-ttu-id="8dc9e-118">Isso deve abrir Olá Ambari Web da interface do usuário, conforme mostrado abaixo.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-118">This should launch hello Ambari Web UI, as shown below.</span></span>

    <span data-ttu-id="8dc9e-119">![Interface da Web Ambari](./media/hdinsight-apache-spark-resource-manager/ambari-web-ui.png "Ambari Web da interface do usuário")</span><span class="sxs-lookup"><span data-stu-id="8dc9e-119">![Ambari Web UI](./media/hdinsight-apache-spark-resource-manager/ambari-web-ui.png "Ambari Web UI")</span></span>   

## <a name="how-do-i-launch-hello-spark-history-server"></a><span data-ttu-id="8dc9e-120">Como iniciar o hello Spark histórico servidor?</span><span class="sxs-lookup"><span data-stu-id="8dc9e-120">How do I launch hello Spark History Server?</span></span>
1. <span data-ttu-id="8dc9e-121">De saudação [Portal do Azure](https://portal.azure.com/), do quadro de saudação inicial, clique em bloco de saudação para seu cluster Spark (se tê-fixado quadro toohello inicial).</span><span class="sxs-lookup"><span data-stu-id="8dc9e-121">From hello [Azure Portal](https://portal.azure.com/), from hello startboard, click hello tile for your Spark cluster (if you pinned it toohello startboard).</span></span>
2. <span data-ttu-id="8dc9e-122">De saudação do cluster folha, em **Links rápidos**, clique em **painel Cluster**.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-122">From hello cluster blade, under **Quick Links**, click **Cluster Dashboard**.</span></span> <span data-ttu-id="8dc9e-123">Em Olá **painel Cluster** folha, clique em **Spark histórico servidor**.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-123">In hello **Cluster Dashboard** blade, click **Spark History Server**.</span></span>

    <span data-ttu-id="8dc9e-124">![Spark History Server](./media/hdinsight-apache-spark-resource-manager/launch-history-server.png "Spark History Server")</span><span class="sxs-lookup"><span data-stu-id="8dc9e-124">![Spark History Server](./media/hdinsight-apache-spark-resource-manager/launch-history-server.png "Spark History Server")</span></span>

    <span data-ttu-id="8dc9e-125">Quando solicitado, insira as credenciais de administrador Olá para o cluster do Spark hello.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-125">When prompted, enter hello admin credentials for hello Spark cluster.</span></span>

## <a name="how-do-i-launch-hello-yarn-ui"></a><span data-ttu-id="8dc9e-126">Como iniciar o hello Yarn da interface do usuário?</span><span class="sxs-lookup"><span data-stu-id="8dc9e-126">How do I launch hello Yarn UI?</span></span>
<span data-ttu-id="8dc9e-127">Você pode usar o hello YARN UI toomonitor os aplicativos que estão sendo executados no cluster do Spark hello.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-127">You can use hello YARN UI toomonitor applications that are currently running on hello Spark cluster.</span></span>

1. <span data-ttu-id="8dc9e-128">Na folha de cluster hello, clique em **painel Cluster**e, em seguida, clique em **YARN**.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-128">From hello cluster blade, click **Cluster Dashboard**, and then click **YARN**.</span></span>

    ![Iniciar Interface do usuário do YARN](./media/hdinsight-apache-spark-resource-manager/launch-yarn-ui.png)

   > [!TIP]
   > <span data-ttu-id="8dc9e-130">Como alternativa, você também pode iniciar Olá YARN da interface do usuário do hello Ambari UI.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-130">Alternatively, you can also launch hello YARN UI from hello Ambari UI.</span></span> <span data-ttu-id="8dc9e-131">Olá toolaunch Ambari UI, na folha de cluster hello, clique em **painel Cluster**e, em seguida, clique em **painel do Cluster HDInsight**.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-131">toolaunch hello Ambari UI, from hello cluster blade, click **Cluster Dashboard**, and then click **HDInsight Cluster Dashboard**.</span></span> <span data-ttu-id="8dc9e-132">De Olá Ambari UI, clique em **YARN**, clique em **Links rápidos**, clique em Gerenciador de recursos ativo hello e, em seguida, clique em **ResourceManager UI**.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-132">From hello Ambari UI, click **YARN**, click **Quick Links**, click hello active resource manager, and then click **ResourceManager UI**.</span></span>
   >
   >

## <a name="what-is-hello-optimum-cluster-configuration-toorun-spark-applications"></a><span data-ttu-id="8dc9e-133">O que é Olá ideal configuração toorun Spark de aplicativos de cluster?</span><span class="sxs-lookup"><span data-stu-id="8dc9e-133">What is hello optimum cluster configuration toorun Spark applications?</span></span>
<span data-ttu-id="8dc9e-134">Olá três parâmetros de chave que podem ser usados para a configuração do Spark dependendo dos requisitos de aplicativo são `spark.executor.instances`, `spark.executor.cores`, e `spark.executor.memory`.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-134">hello three key parameters that can be used for Spark configuration depending on application requirements are `spark.executor.instances`, `spark.executor.cores`, and `spark.executor.memory`.</span></span> <span data-ttu-id="8dc9e-135">Um Executor é um processo iniciado por um aplicativo Spark.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-135">An Executor is a process launched for a Spark application.</span></span> <span data-ttu-id="8dc9e-136">Ele é executado no nó do operador hello e é responsável toocarry tarefas Olá para o aplicativo hello.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-136">It runs on hello worker node and is responsible toocarry out hello tasks for hello application.</span></span> <span data-ttu-id="8dc9e-137">número padrão de saudação de executores e tamanhos de executor de saudação para cada cluster é calculado com base no número de saudação de nós de trabalho e tamanho de nó do operador de saudação.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-137">hello default number of executors and hello executor sizes for each cluster is calculated based on hello number of worker nodes and hello worker node size.</span></span> <span data-ttu-id="8dc9e-138">Eles são armazenados no `spark-defaults.conf` em nós de cluster de Olá cabeçalho.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-138">These are stored in `spark-defaults.conf` on hello cluster head nodes.</span></span>

<span data-ttu-id="8dc9e-139">três parâmetros de configuração Olá podem ser configurados no nível do cluster hello (para todos os aplicativos executados no cluster Olá) ou podem ser especificados para cada aplicativo individual também.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-139">hello three configuration parameters can be configured at hello cluster level (for all applications that run on hello cluster) or can be specified for each individual application as well.</span></span>

### <a name="change-hello-parameters-using-ambari-ui"></a><span data-ttu-id="8dc9e-140">Alterar os parâmetros de saudação usando Ambari UI</span><span class="sxs-lookup"><span data-stu-id="8dc9e-140">Change hello parameters using Ambari UI</span></span>
1. <span data-ttu-id="8dc9e-141">De saudação Ambari UI clique **Spark**, clique em **configurações**e, em seguida, expanda **padrões spark personalizado**.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-141">From hello Ambari UI click **Spark**, click **Configs**, and then expand **Custom spark-defaults**.</span></span>

    ![Definir parâmetros usando o Ambari](./media/hdinsight-apache-spark-resource-manager/set-parameters-using-ambari.png)
2. <span data-ttu-id="8dc9e-143">valores padrão de saudação são aplicativos de Spark de BOM toohave 4 executados simultaneamente em cluster hello.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-143">hello default values are good toohave 4 Spark applications run concurrently on hello cluster.</span></span> <span data-ttu-id="8dc9e-144">Você pode alterações esses valores da interface do usuário hello, conforme mostrado abaixo.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-144">You can changes these values from hello user interface, as shown below.</span></span>

    ![Definir parâmetros usando o Ambari](./media/hdinsight-apache-spark-resource-manager/set-executor-parameters.png)
3. <span data-ttu-id="8dc9e-146">Clique em **salvar** toosave alterações de configuração de saudação.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-146">Click **Save** toosave hello configuration changes.</span></span> <span data-ttu-id="8dc9e-147">Na parte superior de saudação da página hello, você será solicitado toorestart todos Olá afetados serviços.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-147">At hello top of hello page, you will be prompted toorestart all hello affected services.</span></span> <span data-ttu-id="8dc9e-148">Clique em **Reiniciar**.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-148">Click **Restart**.</span></span>

    ![Reiniciar serviços](./media/hdinsight-apache-spark-resource-manager/restart-services.png)

### <a name="change-hello-parameters-for-an-application-running-in-jupyter-notebook"></a><span data-ttu-id="8dc9e-150">Alterar os parâmetros de saudação para um aplicativo em execução no bloco de anotações do Jupyter</span><span class="sxs-lookup"><span data-stu-id="8dc9e-150">Change hello parameters for an application running in Jupyter notebook</span></span>
<span data-ttu-id="8dc9e-151">Para aplicativos executados em anotações do Jupyter hello, você pode usar o hello `%%configure` magic toomake alterações de configuração de saudação.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-151">For applications running in hello Jupyter notebook, you can use hello `%%configure` magic toomake hello configuration changes.</span></span> <span data-ttu-id="8dc9e-152">Idealmente, você deve fazer essas alterações no início de saudação do aplicativo hello, antes de executar a primeira célula de código.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-152">Ideally, you must make such changes at hello beginning of hello application, before you run your first code cell.</span></span> <span data-ttu-id="8dc9e-153">Isso garante que a configuração hello está aplicada toohello Livy sessão, quando ele é criado.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-153">This ensures that hello configuration is applied toohello Livy session, when it gets created.</span></span> <span data-ttu-id="8dc9e-154">Se desejar que a configuração de saudação toochange em um estágio posterior no aplicativo hello, você deve usar o hello `-f` parâmetro.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-154">If you want toochange hello configuration at a later stage in hello application, you must use hello `-f` parameter.</span></span> <span data-ttu-id="8dc9e-155">No entanto, ao fazer isso, todos de progresso em hello aplicativo serão perdido.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-155">However, by doing so all progress in hello application will be lost.</span></span>

<span data-ttu-id="8dc9e-156">trecho de saudação abaixo mostra como toochange Olá a configuração de um aplicativo em execução no Jupyter.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-156">hello snippet below shows how toochange hello configuration for an application running in Jupyter.</span></span>

    %%configure
    {"executorMemory": "3072M", "executorCores": 4, "numExecutors":10}

<span data-ttu-id="8dc9e-157">Parâmetros de configuração devem ser passados como uma cadeia de caracteres JSON e devem estar na próxima linha de saudação após magic Olá, conforme mostrado na coluna de exemplo hello.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-157">Configuration parameters must be passed in as a JSON string and must be on hello next line after hello magic, as shown in hello example column.</span></span>

### <a name="change-hello-parameters-for-an-application-submitted-using-spark-submit"></a><span data-ttu-id="8dc9e-158">Alterar Olá parâmetros para um aplicativo enviada usando o envio spark</span><span class="sxs-lookup"><span data-stu-id="8dc9e-158">Change hello parameters for an application submitted using spark-submit</span></span>
<span data-ttu-id="8dc9e-159">Comando a seguir está um exemplo de como toochange Olá parâmetros de configuração para um aplicativo de lote que é enviado usando `spark-submit`.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-159">Following command is an example of how toochange hello configuration parameters for a batch application that is submitted using `spark-submit`.</span></span>

    spark-submit --class <hello application class tooexecute> --executor-memory 3072M --executor-cores 4 –-num-executors 10 <location of application jar file> <application parameters>

### <a name="change-hello-parameters-for-an-application-submitted-using-curl"></a><span data-ttu-id="8dc9e-160">Alterar os parâmetros de saudação para um aplicativo enviado usando ondulação</span><span class="sxs-lookup"><span data-stu-id="8dc9e-160">Change hello parameters for an application submitted using cURL</span></span>
<span data-ttu-id="8dc9e-161">Comando a seguir é um exemplo de como toochange Olá parâmetros de configuração para um aplicativo de lote que é enviado usando a rotação.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-161">Following command is an example of how toochange hello configuration parameters for a batch application that is submitted using using cURL.</span></span>

    curl -k -v -H 'Content-Type: application/json' -X POST -d '{"file":"<location of application jar file>", "className":"<hello application class tooexecute>", "args":[<application parameters>], "numExecutors":10, "executorMemory":"2G", "executorCores":5' localhost:8998/batches

### <a name="how-do-i-change-these-parameters-on-a-spark-thrift-server"></a><span data-ttu-id="8dc9e-162">Como altero esses parâmetros em um Servidor Thrift Spark?</span><span class="sxs-lookup"><span data-stu-id="8dc9e-162">How do I change these parameters on a Spark Thrift Server?</span></span>
<span data-ttu-id="8dc9e-163">Spark Thrift Server fornece cluster Spark do JDBC/ODBC acesso tooa e é usado tooservice consultas Spark SQL.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-163">Spark Thrift Server provides JDBC/ODBC access tooa Spark cluster and is used tooservice Spark SQL queries.</span></span> <span data-ttu-id="8dc9e-164">Ferramentas como Power BI, Tableau, etc.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-164">Tools like Power BI, Tableau etc.</span></span> <span data-ttu-id="8dc9e-165">Use ODBC protocolo toocommunicate com consultas do servidor do Spark Thrift tooexecute Spark SQL como um aplicativo do Spark.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-165">use ODBC protocol toocommunicate with Spark Thrift Server tooexecute Spark SQL queries as a Spark Application.</span></span> <span data-ttu-id="8dc9e-166">Quando um cluster Spark é criado, duas instâncias do hello Spark Thrift Server forem iniciados, uma em cada nó de cabeçalho.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-166">When a Spark cluster is created, two instances of hello Spark Thrift Server are started, one on each head node.</span></span> <span data-ttu-id="8dc9e-167">Cada servidor do Spark Thrift está visível como um aplicativo Spark Olá YARN da interface do usuário.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-167">Each Spark Thrift Server is visible as a Spark application in hello YARN UI.</span></span>

<span data-ttu-id="8dc9e-168">Spark Thrift Server usa despertar alocação dinâmica de executor e, portanto, Olá `spark.executor.instances` não é usado.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-168">Spark Thrift Server uses Spark dynamic executor allocation and hence hello `spark.executor.instances` is not used.</span></span> <span data-ttu-id="8dc9e-169">Em vez disso, usa o servidor do Spark Thrift `spark.dynamicAllocation.minExecutors` e `spark.dynamicAllocation.maxExecutors` toospecify contagem de executor de saudação.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-169">Instead, Spark Thrift Server uses `spark.dynamicAllocation.minExecutors` and `spark.dynamicAllocation.maxExecutors` toospecify hello executor count.</span></span> <span data-ttu-id="8dc9e-170">parâmetros de configuração de Olá `spark.executor.cores` e `spark.executor.memory` é toomodify Olá executor tamanho usado.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-170">hello configuration parameters `spark.executor.cores` and `spark.executor.memory` is used toomodify hello executor size.</span></span> <span data-ttu-id="8dc9e-171">É possível alterar esses parâmetros, conforme mostrado abaixo.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-171">You can change these parameters as shown below.</span></span>

* <span data-ttu-id="8dc9e-172">Expanda Olá **avançado spark-thrift-sparkconf** parâmetros de saudação do categoria tooupdate `spark.dynamicAllocation.minExecutors`, `spark.dynamicAllocation.maxExecutors`, e `spark.executor.memory`.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-172">Expand hello **Advanced spark-thrift-sparkconf** category tooupdate hello parameters `spark.dynamicAllocation.minExecutors`, `spark.dynamicAllocation.maxExecutors`, and `spark.executor.memory`.</span></span>

    ![Configurar o servidor Thrift Spark](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-1.png)    
* <span data-ttu-id="8dc9e-174">Expanda Olá **personalizado spark thrift sparkconf** parâmetro hello da categoria tooupdate `spark.executor.cores`.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-174">Expand hello **Custom spark-thrift-sparkconf** category tooupdate hello parameter `spark.executor.cores`.</span></span>

    ![Configurar o servidor Thrift Spark](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-2.png)

### <a name="how-do-i-change-hello-driver-memory-of-hello-spark-thrift-server"></a><span data-ttu-id="8dc9e-176">Como alterar a memória de driver de saudação do hello Spark Thrift servidor?</span><span class="sxs-lookup"><span data-stu-id="8dc9e-176">How do I change hello driver memory of hello Spark Thrift Server?</span></span>
<span data-ttu-id="8dc9e-177">Memória do servidor do Spark Thrift driver é configurado too25% do tamanho do nó principal RAM hello, desde que o tamanho total de RAM saudação do nó principal Olá é maior do que 14GB.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-177">Spark Thrift Server driver memory is configured too25% of hello head node RAM size, provided hello total RAM size of hello head node is greater than 14GB.</span></span> <span data-ttu-id="8dc9e-178">Você pode usar o hello configuração de memória do driver Ambari UI toochange hello, conforme mostrado abaixo.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-178">You can use hello Ambari UI toochange hello driver memory configuration, as shown below.</span></span>

* <span data-ttu-id="8dc9e-179">De saudação Ambari UI, clique em **Spark**, clique em **configurações**, expanda **avançado spark env**e, em seguida, forneça o valor de saudação para **spark_thrift_cmd_opts**.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-179">From hello Ambari UI click **Spark**, click **Configs**, expand **Advanced spark-env**, and then provide hello value for **spark_thrift_cmd_opts**.</span></span>

    ![Configurar a RAM do servidor Thrift Spark](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-ram.png)

## <a name="i-do-not-use-bi-with-spark-cluster-how-do-i-take-hello-resources-back"></a><span data-ttu-id="8dc9e-181">Não uso o BI com cluster Spark.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-181">I do not use BI with Spark cluster.</span></span> <span data-ttu-id="8dc9e-182">Como obter os recursos de saudação novamente?</span><span class="sxs-lookup"><span data-stu-id="8dc9e-182">How do I take hello resources back?</span></span>
<span data-ttu-id="8dc9e-183">Uma vez que usamos alocação dinâmica Spark, hello somente os recursos consumidos pelo servidor thrift são Olá recursos para dois mestres de aplicativo hello.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-183">Since we use Spark dynamic allocation, hello only resources that are consumed by thrift server are hello resources for hello two application masters.</span></span> <span data-ttu-id="8dc9e-184">tooreclaim esses recursos, que você deve interromper Olá serviços Thrift Server em execução no cluster de saudação.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-184">tooreclaim these resources you must stop hello Thrift Server services running on hello cluster.</span></span>

1. <span data-ttu-id="8dc9e-185">De saudação Ambari UI, no painel esquerdo do hello, clique em **Spark**.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-185">From hello Ambari UI, from hello left pane, click **Spark**.</span></span>
2. <span data-ttu-id="8dc9e-186">Na página seguinte do hello, clique em **Spark Thrift servidores**.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-186">In hello next page, click **Spark Thrift Servers**.</span></span>

    ![Reiniciar o servidor Thrift](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-1.png)
3. <span data-ttu-id="8dc9e-188">Você deve ver Olá dois headnodes no qual Olá Spark Thrift Server está em execução.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-188">You should see hello two headnodes on which hello Spark Thrift Server is running.</span></span> <span data-ttu-id="8dc9e-189">Clique em uma saudação headnodes.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-189">Click one of hello headnodes.</span></span>

    ![Reiniciar o servidor Thrift](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-2.png)
4. <span data-ttu-id="8dc9e-191">próxima página de saudação lista todos os serviços de saudação em execução em que um nó principal.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-191">hello next page lists all hello services running on that headnode.</span></span> <span data-ttu-id="8dc9e-192">Na lista de saudação clique tooSpark próximo do botão suspenso de saudação Thrift servidor e, em seguida, clique em **parar**.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-192">From hello list click hello drop-down button next tooSpark Thrift Server, and then click **Stop**.</span></span>

    ![Reiniciar o servidor Thrift](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-3.png)
5. <span data-ttu-id="8dc9e-194">Repita essas etapas em Olá também outros um nó principal.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-194">Repeat these steps on hello other headnode as well.</span></span>

## <a name="my-jupyter-notebooks-are-not-running-as-expected-how-can-i-restart-hello-service"></a><span data-ttu-id="8dc9e-195">Meus blocos de anotações do Jupyter não estão sendo executados conforme esperado.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-195">My Jupyter notebooks are not running as expected.</span></span> <span data-ttu-id="8dc9e-196">Como reiniciar o serviço Olá?</span><span class="sxs-lookup"><span data-stu-id="8dc9e-196">How can I restart hello service?</span></span>
<span data-ttu-id="8dc9e-197">Inicie a saudação da interface do usuário do Ambari Web como mostrado acima.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-197">Launch hello Ambari Web UI as shown above.</span></span> <span data-ttu-id="8dc9e-198">Olá à esquerda no painel de navegação, clique em **Jupyter**, clique em **ações de serviço**e, em seguida, clique em **reiniciar todos os**.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-198">From hello left navigation pane, click **Jupyter**, click **Service Actions**, and then click **Restart All**.</span></span> <span data-ttu-id="8dc9e-199">Isso iniciará o serviço de Jupyter de saudação em todos os headnodes de saudação.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-199">This will start hello Jupyter service on all hello headnodes.</span></span>

    ![Restart Jupyter](./media/hdinsight-apache-spark-resource-manager/restart-jupyter.png "Restart Jupyter")

## <a name="how-do-i-know-if-i-am-running-out-of-resources"></a><span data-ttu-id="8dc9e-200">Como fazer para saber se estou ficando sem recursos?</span><span class="sxs-lookup"><span data-stu-id="8dc9e-200">How do I know if I am running out of resources?</span></span>
<span data-ttu-id="8dc9e-201">Inicie Olá Yarn da interface do usuário, como mostrado acima.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-201">Launch hello Yarn UI as shown above.</span></span> <span data-ttu-id="8dc9e-202">Na tabela de métricas de Cluster na parte superior da tela hello, verifique os valores de **memória usada** e **memória Total** colunas.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-202">In Cluster Metrics table on top of hello screen, check values of **Memory Used** and **Memory Total** columns.</span></span> <span data-ttu-id="8dc9e-203">Se os valores hello 2 são muito próximos, pode não haver próximo aplicativo suficiente recursos toostart hello.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-203">If hello 2 values are very close, there might not be enough resources toostart hello next application.</span></span> <span data-ttu-id="8dc9e-204">Olá mesmo se aplica a toohello **VCores usado** e **VCores Total** colunas.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-204">hello same applies toohello **VCores Used** and **VCores Total** columns.</span></span> <span data-ttu-id="8dc9e-205">Além disso, no modo de exibição principal hello, se houver um aplicativo continuaram em **aceito** estado e não a transição para **executando** nem **falha** estado, isso também pode ser uma indicação Se não estiver recebendo suficiente toostart de recursos.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-205">Also, in hello main view, if there is an application stayed in **ACCEPTED** state and not transitioning into **RUNNING** nor **FAILED** state, this could also be an indication that it is not getting enough resources toostart.</span></span>

    ![Resource Limit](./media/hdinsight-apache-spark-resource-manager/resource-limit.png "Resource Limit")

## <a name="how-do-i-kill-a-running-application-toofree-up-resource"></a><span data-ttu-id="8dc9e-206">Como interromper a execução toofree aplicativo recurso?</span><span class="sxs-lookup"><span data-stu-id="8dc9e-206">How do I kill a running application toofree up resource?</span></span>
1. <span data-ttu-id="8dc9e-207">No hello Yarn da interface do usuário, no painel esquerdo do hello, clique em **executando**.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-207">In hello Yarn UI, from hello left panel, click **Running**.</span></span> <span data-ttu-id="8dc9e-208">Na lista de saudação de aplicativos em execução, determinar Olá aplicativo toobe interrompida e clique em Olá **ID**.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-208">From hello list of running applications, determine hello application toobe killed and click on hello **ID**.</span></span>

    <span data-ttu-id="8dc9e-209">![Eliminar App1](./media/hdinsight-apache-spark-resource-manager/kill-app1.png "Eliminar App1")</span><span class="sxs-lookup"><span data-stu-id="8dc9e-209">![Kill App1](./media/hdinsight-apache-spark-resource-manager/kill-app1.png "Kill App1")</span></span>

2. <span data-ttu-id="8dc9e-210">Clique em **aplicativo Kill** na Olá canto superior direito, em seguida, clique em **Okey**.</span><span class="sxs-lookup"><span data-stu-id="8dc9e-210">Click **Kill Application** on hello top right corner, then click **OK**.</span></span>

    <span data-ttu-id="8dc9e-211">![Eliminar App2](./media/hdinsight-apache-spark-resource-manager/kill-app2.png "Eliminar App2")</span><span class="sxs-lookup"><span data-stu-id="8dc9e-211">![Kill App2](./media/hdinsight-apache-spark-resource-manager/kill-app2.png "Kill App2")</span></span>

## <a name="see-also"></a><span data-ttu-id="8dc9e-212">Consulte também</span><span class="sxs-lookup"><span data-stu-id="8dc9e-212">See also</span></span>
* [<span data-ttu-id="8dc9e-213">Rastrear e depurar trabalhos em execução em um cluster do Apache Spark no HDInsight</span><span class="sxs-lookup"><span data-stu-id="8dc9e-213">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)

### <a name="for-data-analysts"></a><span data-ttu-id="8dc9e-214">Para analistas de dados</span><span class="sxs-lookup"><span data-stu-id="8dc9e-214">For data analysts</span></span>

* [<span data-ttu-id="8dc9e-215">Spark com Aprendizado de Máquina: usar o Spark no HDInsight para analisar a temperatura de prédios usando dados do sistema HVAC</span><span class="sxs-lookup"><span data-stu-id="8dc9e-215">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="8dc9e-216">Spark com o aprendizado de máquina: Use Spark nos resultados de inspeção de alimentos HDInsight toopredict</span><span class="sxs-lookup"><span data-stu-id="8dc9e-216">Spark with Machine Learning: Use Spark in HDInsight toopredict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="8dc9e-217">Análise de log do site usando o Spark no HDInsight</span><span class="sxs-lookup"><span data-stu-id="8dc9e-217">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)
* [<span data-ttu-id="8dc9e-218">Análise da telemetria de dados do Application Insight usando o Spark no HDInsight</span><span class="sxs-lookup"><span data-stu-id="8dc9e-218">Application Insight telemetry data analysis using Spark in HDInsight</span></span>](hdinsight-spark-analyze-application-insight-logs.md)
* [<span data-ttu-id="8dc9e-219">Usar o Caffe no Azure HDInsight Spark para aprendizado aprofundado distribuído</span><span class="sxs-lookup"><span data-stu-id="8dc9e-219">Use Caffe on Azure HDInsight Spark for distributed deep learning</span></span>](hdinsight-deep-learning-caffe-spark.md)

### <a name="for-spark-developers"></a><span data-ttu-id="8dc9e-220">Para desenvolvedores do Spark</span><span class="sxs-lookup"><span data-stu-id="8dc9e-220">For Spark developers</span></span>

* [<span data-ttu-id="8dc9e-221">Criar um aplicativo autônomo usando Scala</span><span class="sxs-lookup"><span data-stu-id="8dc9e-221">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="8dc9e-222">Executar trabalhos remotamente em um cluster do Spark usando Livy</span><span class="sxs-lookup"><span data-stu-id="8dc9e-222">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)
* [<span data-ttu-id="8dc9e-223">Usar o plug-in de ferramentas de HDInsight para toocreate IntelliJ IDEIA e enviar Spark Scala aplicativos</span><span class="sxs-lookup"><span data-stu-id="8dc9e-223">Use HDInsight Tools Plugin for IntelliJ IDEA toocreate and submit Spark Scala applications</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="8dc9e-224">Streaming Spark: usar o Spark no HDInsight para a criação de aplicativos de streaming em tempo real</span><span class="sxs-lookup"><span data-stu-id="8dc9e-224">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="8dc9e-225">Usar o plug-in de ferramentas de HDInsight para aplicativos de Spark toodebug IntelliJ IDEIA remotamente</span><span class="sxs-lookup"><span data-stu-id="8dc9e-225">Use HDInsight Tools Plugin for IntelliJ IDEA toodebug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="8dc9e-226">Usar blocos de anotações do Zeppelin com um cluster Spark no HDInsight</span><span class="sxs-lookup"><span data-stu-id="8dc9e-226">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="8dc9e-227">Kernels disponíveis para o bloco de anotações Jupyter no cluster do Spark para HDInsight</span><span class="sxs-lookup"><span data-stu-id="8dc9e-227">Kernels available for Jupyter notebook in Spark cluster for HDInsight</span></span>](hdinsight-apache-spark-jupyter-notebook-kernels.md)
* [<span data-ttu-id="8dc9e-228">Usar pacotes externos com blocos de notas Jupyter</span><span class="sxs-lookup"><span data-stu-id="8dc9e-228">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="8dc9e-229">Instalar Jupyter em seu computador e conecte-se tooan cluster HDInsight Spark</span><span class="sxs-lookup"><span data-stu-id="8dc9e-229">Install Jupyter on your computer and connect tooan HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)
