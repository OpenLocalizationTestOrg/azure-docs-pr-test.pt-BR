---
title: "Criar modelos de análise de texto no Azure Machine Learning Studio | Microsoft Docs"
description: "Como criar modelos de análise de texto no Azure Machine Learning Studio usando módulos de pré-processamento de texto, N-gramas ou hash de recursos"
services: machine-learning
documentationcenter: 
author: rastala
manager: jhubbard
editor: 
ms.assetid: 08cd6723-3ae6-4e99-a924-e650942e461b
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 12/06/2016
ms.author: roastala
ms.openlocfilehash: 342e81e2497d292ca730bea59e03182d316ffec3
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: pt-BR
ms.lasthandoff: 07/11/2017
---
# <a name="create-text-analytics-models-in-azure-machine-learning-studio"></a><span data-ttu-id="56e8a-103">Criar modelos de análise de texto no Azure Machine Learning Studio</span><span class="sxs-lookup"><span data-stu-id="56e8a-103">Create text analytics models in Azure Machine Learning Studio</span></span>
<span data-ttu-id="56e8a-104">Você pode usar o Azure Machine Learning para criar e operacionalizar modelos de análise de texto.</span><span class="sxs-lookup"><span data-stu-id="56e8a-104">You can use Azure Machine Learning to build and operationalize text analytics models.</span></span> <span data-ttu-id="56e8a-105">Esses modelos podem ajudá-lo a resolver, por exemplo, problemas de classificação de documento ou análise de sentimento.</span><span class="sxs-lookup"><span data-stu-id="56e8a-105">These models can help you solve, for example, document classification or sentiment analysis problems.</span></span>

<span data-ttu-id="56e8a-106">Em um experimento de análise de texto, geralmente, você pode:</span><span class="sxs-lookup"><span data-stu-id="56e8a-106">In a text analytics experiment, you would typically:</span></span>

1. <span data-ttu-id="56e8a-107">Limpar e pré-processar o conjunto de dados de texto</span><span class="sxs-lookup"><span data-stu-id="56e8a-107">Clean and preprocess text dataset</span></span>
2. <span data-ttu-id="56e8a-108">Extrair vetores de recurso numérico de um texto pré-processado</span><span class="sxs-lookup"><span data-stu-id="56e8a-108">Extract numeric feature vectors from pre-processed text</span></span>
3. <span data-ttu-id="56e8a-109">Treinar o modelo de classificação ou regressão</span><span class="sxs-lookup"><span data-stu-id="56e8a-109">Train classification or regression model</span></span>
4. <span data-ttu-id="56e8a-110">Pontuar e validar o modelo</span><span class="sxs-lookup"><span data-stu-id="56e8a-110">Score and validate the model</span></span>
5. <span data-ttu-id="56e8a-111">Implantar o modelo na produção</span><span class="sxs-lookup"><span data-stu-id="56e8a-111">Deploy the model to production</span></span>

<span data-ttu-id="56e8a-112">Neste tutorial, você aprenderá essas etapas conforme examinamos um modelo de análise de sentimento usando o conjunto de dados Amazon Book Reviews (consulte o artigo de pesquisa “Biographies, Bollywood, Boom-boxes and Blenders: Domain Adaptation for Sentiment Classification” de John Blitzer, Mark Dredze e Fernando Pereira; Association of Computational Linguistics (ACL), 2007). Esse conjunto de dados consiste em pontuações de crítica (1-2 ou 4-5) e um texto de forma livre.</span><span class="sxs-lookup"><span data-stu-id="56e8a-112">In this tutorial, you learn these steps as we walk through a sentiment analysis model using Amazon Book Reviews dataset (see this research paper “Biographies, Bollywood, Boom-boxes and Blenders: Domain Adaptation for Sentiment Classification” by John Blitzer, Mark Dredze, and Fernando Pereira; Association of Computational Linguistics (ACL), 2007.) This dataset consists of review scores (1-2 or 4-5) and a free-form text.</span></span> <span data-ttu-id="56e8a-113">O objetivo é prever a pontuação da crítica: baixa (1-2) ou alta (4-5).</span><span class="sxs-lookup"><span data-stu-id="56e8a-113">The goal is to predict the review score: low (1-2) or high (4-5).</span></span>

<span data-ttu-id="56e8a-114">Você pode encontrar os experimentos abordados neste tutorial na Galeria do Cortana Intelligence:</span><span class="sxs-lookup"><span data-stu-id="56e8a-114">You can find experiments covered in this tutorial at Cortana Intelligence Gallery:</span></span>

[<span data-ttu-id="56e8a-115">Prever crítica literária</span><span class="sxs-lookup"><span data-stu-id="56e8a-115">Predict Book Reviews</span></span>](https://gallery.cortanaintelligence.com/Experiment/Predict-Book-Reviews-1)

[<span data-ttu-id="56e8a-116">Prever crítica literária – Experimento preditivo</span><span class="sxs-lookup"><span data-stu-id="56e8a-116">Predict Book Reviews - Predictive Experiment</span></span>](https://gallery.cortanaintelligence.com/Experiment/Predict-Book-Reviews-Predictive-Experiment-1)

## <a name="step-1-clean-and-preprocess-text-dataset"></a><span data-ttu-id="56e8a-117">Etapa 1: Limpar e pré-processar o conjunto de dados de texto</span><span class="sxs-lookup"><span data-stu-id="56e8a-117">Step 1: Clean and preprocess text dataset</span></span>
<span data-ttu-id="56e8a-118">Começamos o experimento dividindo as pontuações de crítica em buckets categóricos altos e baixos para formular o problema como uma classificação de duas classes.</span><span class="sxs-lookup"><span data-stu-id="56e8a-118">We begin the experiment by dividing the review scores into categorical low and high buckets to formulate the problem as two-class classification.</span></span> <span data-ttu-id="56e8a-119">Usamos os módulos [Editar Metadados](https://msdn.microsoft.com/library/azure/dn905986.aspx) e [Agrupar Valores Categóricos](https://msdn.microsoft.com/library/azure/dn906014.aspx).</span><span class="sxs-lookup"><span data-stu-id="56e8a-119">We use [Edit Metadata](https://msdn.microsoft.com/library/azure/dn905986.aspx) and [Group Categorical Values](https://msdn.microsoft.com/library/azure/dn906014.aspx) modules.</span></span>

![Criar rótulo](./media/machine-learning-text-analytics-module-tutorial/create-label.png)

<span data-ttu-id="56e8a-121">Em seguida, limpamos o texto usando o módulo [Pré-processar Texto](https://msdn.microsoft.com/library/azure/mt762915.aspx) .</span><span class="sxs-lookup"><span data-stu-id="56e8a-121">Then, we clean the text using [Preprocess Text](https://msdn.microsoft.com/library/azure/mt762915.aspx) module.</span></span> <span data-ttu-id="56e8a-122">A limpeza reduz o ruído no conjunto de dados, ajuda a encontrar os recursos mais importantes e melhora a precisão do modelo final.</span><span class="sxs-lookup"><span data-stu-id="56e8a-122">The cleaning reduces the noise in the dataset, help you find the most important features, and improve the accuracy of the final model.</span></span> <span data-ttu-id="56e8a-123">Removemos palavras irrelevantes (stop words) – palavras comuns, como “o” ou “um” – bem como números, caracteres especiais, caracteres duplicados, endereços de email e URLs.</span><span class="sxs-lookup"><span data-stu-id="56e8a-123">We remove stopwords - common words such as "the" or "a" - and numbers, special characters, duplicated characters, email addresses, and URLs.</span></span> <span data-ttu-id="56e8a-124">Também convertemos o texto em minúsculas, fazemos a lematização das palavras e detectamos os limites de sentença, que são então indicados pelo símbolo “|||” no texto pré-processado.</span><span class="sxs-lookup"><span data-stu-id="56e8a-124">We also convert the text to lowercase, lemmatize the words, and detect sentence boundaries that are then indicated by "|||" symbol in pre-processed text.</span></span>

![Pré-processar Texto](./media/machine-learning-text-analytics-module-tutorial/preprocess-text.png)

<span data-ttu-id="56e8a-126">E se você quiser usar uma lista personalizada de palavras irrelevantes?</span><span class="sxs-lookup"><span data-stu-id="56e8a-126">What if you want to use a custom list of stopwords?</span></span> <span data-ttu-id="56e8a-127">Você pode passá-la como uma entrada opcional.</span><span class="sxs-lookup"><span data-stu-id="56e8a-127">You can pass it in as optional input.</span></span> <span data-ttu-id="56e8a-128">Também é possível usar uma expressão regular personalizada da sintaxe em C# para substituir subcadeias de caracteres e remover palavras por parte da fala: substantivos, verbos ou adjetivos.</span><span class="sxs-lookup"><span data-stu-id="56e8a-128">You can also use custom C# syntax regular expression to replace substrings, and remove words by part of speech: nouns, verbs, or adjectives.</span></span>

<span data-ttu-id="56e8a-129">Após a conclusão do pré-processamento, dividimos os dados em conjuntos de treinamento e teste.</span><span class="sxs-lookup"><span data-stu-id="56e8a-129">After the preprocessing is complete, we split the data into train and test sets.</span></span>

## <a name="step-2-extract-numeric-feature-vectors-from-pre-processed-text"></a><span data-ttu-id="56e8a-130">Etapa 2: Extrair vetores de recurso numérico de um texto pré-processado</span><span class="sxs-lookup"><span data-stu-id="56e8a-130">Step 2: Extract numeric feature vectors from pre-processed text</span></span>
<span data-ttu-id="56e8a-131">Para criar um modelo para dados de texto, normalmente, você precisa converter o texto de forma livre em vetores de recurso numérico.</span><span class="sxs-lookup"><span data-stu-id="56e8a-131">To build a model for text data, you typically have to convert free-form text into numeric feature vectors.</span></span> <span data-ttu-id="56e8a-132">Neste exemplo, usamos o módulo [Extrair Recursos de N-grama de Texto](https://msdn.microsoft.com/library/azure/mt762916.aspx) para transformar os dados de texto em um formato desse tipo.</span><span class="sxs-lookup"><span data-stu-id="56e8a-132">In this example, we use [Extract N-Gram Features from Text](https://msdn.microsoft.com/library/azure/mt762916.aspx) module to transform the text data to such format.</span></span> <span data-ttu-id="56e8a-133">Este módulo usa uma coluna de palavras separadas por espaço em branco e calcula um dicionário de palavras ou N-gramas de palavras, que aparecem no conjunto de dados.</span><span class="sxs-lookup"><span data-stu-id="56e8a-133">This module takes a column of whitespace-separated words and computes a dictionary of words, or N-grams of words, that appear in your dataset.</span></span> <span data-ttu-id="56e8a-134">Em seguida, ele conta quantas vezes cada palavra, ou N-gram, é exibida em cada registro e cria vetores de recurso das contagens.</span><span class="sxs-lookup"><span data-stu-id="56e8a-134">Then, it counts how many times each word, or N-gram, appears in each record, and creates feature vectors from those counts.</span></span> <span data-ttu-id="56e8a-135">Neste tutorial, definimos o tamanho do N-grama como 2, para que nossos vetores de recurso incluam palavras individuais e combinações de duas palavras subsequentes.</span><span class="sxs-lookup"><span data-stu-id="56e8a-135">In this tutorial, we set N-gram size to 2, so our feature vectors include single words and combinations of two subsequent words.</span></span>

![Extrair N-gramas](./media/machine-learning-text-analytics-module-tutorial/extract-ngrams.png)

<span data-ttu-id="56e8a-137">Aplicamos a pesagem TF*IDF (Frequência de Termo Frequência Inversa do Documento) a contagens de N-grama.</span><span class="sxs-lookup"><span data-stu-id="56e8a-137">We apply TF*IDF (Term Frequency Inverse Document Frequency) weighting to N-gram counts.</span></span> <span data-ttu-id="56e8a-138">Essa abordagem adiciona o peso de palavras que aparecem frequentemente em um único registro, mas que são raras em todo o conjunto de dados.</span><span class="sxs-lookup"><span data-stu-id="56e8a-138">This approach adds weight of words that appear frequently in a single record but are rare across the entire dataset.</span></span> <span data-ttu-id="56e8a-139">Outras opções incluem o binário, TF e a pesagem de gráfico.</span><span class="sxs-lookup"><span data-stu-id="56e8a-139">Other options include binary, TF, and graph weighing.</span></span>

<span data-ttu-id="56e8a-140">Geralmente, esses recursos de texto têm alta dimensionalidade.</span><span class="sxs-lookup"><span data-stu-id="56e8a-140">Such text features often have high dimensionality.</span></span> <span data-ttu-id="56e8a-141">Por exemplo, se seu corpus tiver 100.000 palavras exclusivas, seu espaço de recurso terá 100.000 dimensões ou mais, caso sejam usados N-gramas.</span><span class="sxs-lookup"><span data-stu-id="56e8a-141">For example, if your corpus has 100,000 unique words, your feature space would have 100,000 dimensions, or more if N-grams are used.</span></span> <span data-ttu-id="56e8a-142">O módulo Extrair Recursos de N-grama fornece um conjunto de opções para reduzir a dimensionalidade.</span><span class="sxs-lookup"><span data-stu-id="56e8a-142">The Extract N-Gram Features module gives you a set of options to reduce the dimensionality.</span></span> <span data-ttu-id="56e8a-143">Você pode optar por excluir palavras que são curtas ou longas, muito incomuns ou muito frequentes que têm um valor preditivo significativo.</span><span class="sxs-lookup"><span data-stu-id="56e8a-143">You can choose to exclude words that are short or long, or too uncommon or too frequent to have significant predictive value.</span></span> <span data-ttu-id="56e8a-144">Neste tutorial, excluímos N-gramas que aparecem em menos de 5 registros ou em mais de 80% dos registros.</span><span class="sxs-lookup"><span data-stu-id="56e8a-144">In this tutorial, we exclude N-grams that appear in fewer than 5 records or in more than 80% of records.</span></span>

<span data-ttu-id="56e8a-145">Além disso, você pode usar a seleção de recursos para selecionar apenas os recursos que estão mais correlacionados ao seu destino de previsão.</span><span class="sxs-lookup"><span data-stu-id="56e8a-145">Also, you can use feature selection to select only those features that are the most correlated with your prediction target.</span></span> <span data-ttu-id="56e8a-146">Usamos a seleção de recursos Qui Quadrado para selecionar 1.000 recursos.</span><span class="sxs-lookup"><span data-stu-id="56e8a-146">We use Chi-Squared feature selection to select 1000 features.</span></span> <span data-ttu-id="56e8a-147">Você pode exibir o vocabulário de palavras selecionadas ou N-gramas clicando na saída correta do módulo Extrair N-gramas.</span><span class="sxs-lookup"><span data-stu-id="56e8a-147">You can view the vocabulary of selected words or N-grams by clicking the right output of Extract N-grams module.</span></span>

<span data-ttu-id="56e8a-148">Como uma abordagem alternativa ao uso de Extrair Recursos de N-grama, você pode usar o módulo Hash de Recursos.</span><span class="sxs-lookup"><span data-stu-id="56e8a-148">As an alternative approach to using Extract N-Gram Features, you can use Feature Hashing module.</span></span> <span data-ttu-id="56e8a-149">No entanto, observe que o [Hash de Recursos](https://msdn.microsoft.com/library/azure/dn906018.aspx) não traz funcionalidades de seleção de recursos internos nem a pesagem TF*IDF.</span><span class="sxs-lookup"><span data-stu-id="56e8a-149">Note though that [Feature Hashing](https://msdn.microsoft.com/library/azure/dn906018.aspx) does not have build-in feature selection capabilities, or TF*IDF weighing.</span></span>

## <a name="step-3-train-classification-or-regression-model"></a><span data-ttu-id="56e8a-150">Etapa 3: Treinar o modelo de classificação ou regressão</span><span class="sxs-lookup"><span data-stu-id="56e8a-150">Step 3: Train classification or regression model</span></span>
<span data-ttu-id="56e8a-151">Agora o texto foi transformado em colunas de recurso numérico.</span><span class="sxs-lookup"><span data-stu-id="56e8a-151">Now the text has been transformed to numeric feature columns.</span></span> <span data-ttu-id="56e8a-152">O conjunto de dados ainda contém colunas de cadeia de caracteres de estágios anteriores e, portanto, usamos Selecionar Colunas no Conjunto de Dados para excluí-las.</span><span class="sxs-lookup"><span data-stu-id="56e8a-152">The dataset still contains string columns from previous stages, so we use Select Columns in Dataset to exclude them.</span></span>

<span data-ttu-id="56e8a-153">Em seguida, usamos a [Regressão Logística de Duas Classes](https://msdn.microsoft.com/library/azure/dn905994.aspx) para prever nosso destino: pontuação de crítica alta ou baixa.</span><span class="sxs-lookup"><span data-stu-id="56e8a-153">We then use [Two-Class Logistic Regression](https://msdn.microsoft.com/library/azure/dn905994.aspx) to predict our target: high or low review score.</span></span> <span data-ttu-id="56e8a-154">Neste ponto, o problema de análise de texto foi transformado em um problema de classificação regular.</span><span class="sxs-lookup"><span data-stu-id="56e8a-154">At this point, the text analytics problem has been transformed into a regular classification problem.</span></span> <span data-ttu-id="56e8a-155">Você pode usar as ferramentas disponíveis no Azure Machine Learning para melhorar o modelo.</span><span class="sxs-lookup"><span data-stu-id="56e8a-155">You can use the tools available in Azure Machine Learning to improve the model.</span></span> <span data-ttu-id="56e8a-156">Por exemplo, você pode experimentar com diferentes classificadores para descobrir quão precisos são os resultados fornecidos ou usar o ajuste de hiperparâmetro para melhorar a precisão.</span><span class="sxs-lookup"><span data-stu-id="56e8a-156">For example, you can experiment with different classifiers to find out how accurate results they give, or use hyperparameter tuning to improve the accuracy.</span></span>

![Treinar e pontuar](./media/machine-learning-text-analytics-module-tutorial/scoring-text.png)

## <a name="step-4-score-and-validate-the-model"></a><span data-ttu-id="56e8a-158">Etapa 4: Pontuar e validar o modelo</span><span class="sxs-lookup"><span data-stu-id="56e8a-158">Step 4: Score and validate the model</span></span>
<span data-ttu-id="56e8a-159">Como você validará o modelo treinado?</span><span class="sxs-lookup"><span data-stu-id="56e8a-159">How would you validate the trained model?</span></span> <span data-ttu-id="56e8a-160">Pontuamos o modelo em relação ao conjunto de dados de teste e avaliamos a precisão.</span><span class="sxs-lookup"><span data-stu-id="56e8a-160">We score it against the test dataset and evaluate the accuracy.</span></span> <span data-ttu-id="56e8a-161">No entanto, o modelo aprendeu o vocabulário de N-gramas e seus pesos do conjunto de dados de treinamento.</span><span class="sxs-lookup"><span data-stu-id="56e8a-161">However, the model learned the vocabulary of N-grams and their weights from the training dataset.</span></span> <span data-ttu-id="56e8a-162">Por isso, devemos usar esse vocabulário e os pesos ao extrair recursos dos dados de teste, em vez de criar o vocabulário novamente.</span><span class="sxs-lookup"><span data-stu-id="56e8a-162">Therefore, we should use that vocabulary and those weights when extracting features from test data, as opposed to creating the vocabulary anew.</span></span> <span data-ttu-id="56e8a-163">Portanto, adicionamos o módulo Extrair Recursos de N-grama à ramificação de pontuação do experimento, conectamos o vocabulário de saída da ramificação de treinamento e definimos o modo de vocabulário como somente leitura.</span><span class="sxs-lookup"><span data-stu-id="56e8a-163">Therefore, we add Extract N-Gram Features module to the scoring branch of the experiment, connect the output vocabulary from training branch, and set the vocabulary mode to read-only.</span></span> <span data-ttu-id="56e8a-164">Também desabilitamos a filtragem de N-gramas por frequência, definindo o mínimo como 1 instância e o máximo como 100%, bem como desativamos a seleção de recursos.</span><span class="sxs-lookup"><span data-stu-id="56e8a-164">We also disable the filtering of N-grams by frequency by setting the minimum to 1 instance and maximum to 100%, and turn off the feature selection.</span></span>

<span data-ttu-id="56e8a-165">Depois que a coluna de texto nos dados de teste foi transformada em colunas de recurso numérico, excluímos as colunas de cadeia de caracteres de estágios anteriores como fizemos na ramificação de treinamento.</span><span class="sxs-lookup"><span data-stu-id="56e8a-165">After the text column in test data has been transformed to numeric feature columns, we exclude the string columns from previous stages like in training branch.</span></span> <span data-ttu-id="56e8a-166">Em seguida, usamos o módulo Pontuar Modelo para fazer previsões e o módulo Avaliar Modelo para avaliar a precisão.</span><span class="sxs-lookup"><span data-stu-id="56e8a-166">We then use Score Model module to make predictions and Evaluate Model module to evaluate the accuracy.</span></span>

## <a name="step-5-deploy-the-model-to-production"></a><span data-ttu-id="56e8a-167">Etapa 5: Implantar o modelo na produção</span><span class="sxs-lookup"><span data-stu-id="56e8a-167">Step 5: Deploy the model to production</span></span>
<span data-ttu-id="56e8a-168">O modelo está quase pronto para ser implantado na produção.</span><span class="sxs-lookup"><span data-stu-id="56e8a-168">The model is almost ready to be deployed to production.</span></span> <span data-ttu-id="56e8a-169">Quando implantado como um serviço Web, ele usa a cadeia de caracteres de texto de forma livre como entrada e retorna uma previsão “alta” ou “baixa”.</span><span class="sxs-lookup"><span data-stu-id="56e8a-169">When deployed as web service, it takes free-form text string as input, and return a prediction "high" or "low."</span></span> <span data-ttu-id="56e8a-170">Ele usa o vocabulário de N-gram aprendido para transformar o texto em recursos e o modelo de regressão logística treinado para fazer uma previsão desses recursos.</span><span class="sxs-lookup"><span data-stu-id="56e8a-170">It uses the learned N-gram vocabulary to transform the text to features, and trained logistic regression model to make a prediction from those features.</span></span> 

<span data-ttu-id="56e8a-171">Para configurar o experimento preditivo, primeiro salvamos o vocabulário de N-grama como conjunto de dados e o modelo de regressão logística treinado da ramificação de treinamento do experimento.</span><span class="sxs-lookup"><span data-stu-id="56e8a-171">To set up the predictive experiment, we first save the N-gram vocabulary as dataset, and the trained logistic regression model from the training branch of the experiment.</span></span> <span data-ttu-id="56e8a-172">Em seguida, salvamos o experimento usando “Salvar Como” para criar um gráfico de experimento para o experimento preditivo.</span><span class="sxs-lookup"><span data-stu-id="56e8a-172">Then, we save the experiment using "Save As" to create an experiment graph for predictive experiment.</span></span> <span data-ttu-id="56e8a-173">Removemos o módulo Dividir Dados e a ramificação de treinamento do experimento.</span><span class="sxs-lookup"><span data-stu-id="56e8a-173">We remove the Split Data module and the training branch from the experiment.</span></span> <span data-ttu-id="56e8a-174">Em seguida, conectamos o vocabulário de N-grama salvo e o modelo anteriormente aos módulos Extrair Recursos de N-grama e Pontuar Modelo, respectivamente.</span><span class="sxs-lookup"><span data-stu-id="56e8a-174">We then connect the previously saved N-gram vocabulary and model to Extract N-Gram Features and Score Model modules, respectively.</span></span> <span data-ttu-id="56e8a-175">Também removemos o módulo Avaliar Modelo.</span><span class="sxs-lookup"><span data-stu-id="56e8a-175">We also remove the Evaluate Model module.</span></span>

<span data-ttu-id="56e8a-176">Inserimos o módulo Selecionar Colunas no Conjunto de Dados antes do módulo Pré-processar Texto para remover a coluna de rótulo e desmarcamos a opção “Acrescentar a coluna de pontuação ao conjunto de dados” em Pontuar Módulo.</span><span class="sxs-lookup"><span data-stu-id="56e8a-176">We insert Select Columns in Dataset module before Preprocess Text module to remove the label column, and unselect "Append score column to dataset" option in Score Module.</span></span> <span data-ttu-id="56e8a-177">Dessa forma, o serviço Web não solicita o rótulo que está tentando prever e não retorna os recursos de entrada em resposta.</span><span class="sxs-lookup"><span data-stu-id="56e8a-177">That way, the web service does not request the label it is trying to predict, and does not echo the input features in response.</span></span>

![Experimento preditivo](./media/machine-learning-text-analytics-module-tutorial/predictive-text.png)

<span data-ttu-id="56e8a-179">Agora temos um experimento que pode ser publicado como um serviço Web e chamado com APIs de execução em lotes ou solicitação-resposta.</span><span class="sxs-lookup"><span data-stu-id="56e8a-179">Now we have an experiment that can be published as a web service and called using request-response or batch execution APIs.</span></span>

## <a name="next-steps"></a><span data-ttu-id="56e8a-180">Próximas etapas</span><span class="sxs-lookup"><span data-stu-id="56e8a-180">Next Steps</span></span>
<span data-ttu-id="56e8a-181">Saiba mais sobre os módulos de análise de texto na [documentação do MSDN](https://msdn.microsoft.com/library/azure/dn905886.aspx).</span><span class="sxs-lookup"><span data-stu-id="56e8a-181">Learn about text analytics modules from [MSDN documentation](https://msdn.microsoft.com/library/azure/dn905886.aspx).</span></span>

