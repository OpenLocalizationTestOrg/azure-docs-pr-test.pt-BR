---
title: Avaliar o desempenho do modelo no Machine Learning | Microsoft Docs
description: Explica como avaliar o desempenho do modelo no Azure Machine Learning.
services: machine-learning
documentationcenter: 
author: garyericson
manager: jhubbard
editor: cgronlun
ms.assetid: 5dc5348a-4488-4536-99eb-ff105be9b160
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/20/2017
ms.author: bradsev;garye
ms.openlocfilehash: d9576e0059f2e77a684e518389182e713f0a4f09
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: pt-BR
ms.lasthandoff: 07/11/2017
---
# <a name="how-to-evaluate-model-performance-in-azure-machine-learning"></a><span data-ttu-id="28137-103">Como avaliar o desempenho do modelo no Azure Machine Learning</span><span class="sxs-lookup"><span data-stu-id="28137-103">How to evaluate model performance in Azure Machine Learning</span></span>
<span data-ttu-id="28137-104">Este tópico demonstra como avaliar o desempenho de um modelo no Azure Machine Learning Studio e fornece uma breve explicação sobre as métricas disponíveis para essa tarefa.</span><span class="sxs-lookup"><span data-stu-id="28137-104">This article demonstrates how to evaluate the performance of a model in Azure Machine Learning Studio and provides a brief explanation of the metrics available for this task.</span></span> <span data-ttu-id="28137-105">Três cenários comuns de aprendizado supervisionado são apresentados:</span><span class="sxs-lookup"><span data-stu-id="28137-105">Three common supervised learning scenarios are presented:</span></span> 

* <span data-ttu-id="28137-106">regressão</span><span class="sxs-lookup"><span data-stu-id="28137-106">regression</span></span>
* <span data-ttu-id="28137-107">classificação binária</span><span class="sxs-lookup"><span data-stu-id="28137-107">binary classification</span></span> 
* <span data-ttu-id="28137-108">classificação multiclasse</span><span class="sxs-lookup"><span data-stu-id="28137-108">multiclass classification</span></span>

[!INCLUDE [machine-learning-free-trial](../../includes/machine-learning-free-trial.md)]

<span data-ttu-id="28137-109">Avaliar o desempenho de um modelo é um dos estágios principais do processo de ciência de dados.</span><span class="sxs-lookup"><span data-stu-id="28137-109">Evaluating the performance of a model is one of the core stages in the data science process.</span></span> <span data-ttu-id="28137-110">Indica o êxito da pontuação (previsões) de um conjunto de dados feitas por meio de um modelo treinado.</span><span class="sxs-lookup"><span data-stu-id="28137-110">It indicates how successful the scoring (predictions) of a dataset has been by a trained model.</span></span> 

<span data-ttu-id="28137-111">O Azure Machine Learning dá suporte à avaliação de modelo por meio de dois dos seus principais módulos de aprendizado de máquina: [Avaliar Modelo][evaluate-model] e [Modelo de Validação Cruzada][cross-validate-model].</span><span class="sxs-lookup"><span data-stu-id="28137-111">Azure Machine Learning supports model evaluation through two of its main machine learning modules: [Evaluate Model][evaluate-model] and [Cross-Validate Model][cross-validate-model].</span></span> <span data-ttu-id="28137-112">Esses módulos permitem que você veja como o seu modelo é executado em termos de um número de métricas que são usados normalmente em estatísticas e aprendizado de máquina.</span><span class="sxs-lookup"><span data-stu-id="28137-112">These modules allow you to see how your model performs in terms of a number of metrics that are commonly used in machine learning and statistics.</span></span>

## <a name="evaluation-vs-cross-validation"></a><span data-ttu-id="28137-113">Avaliação versus Validação cruzada</span><span class="sxs-lookup"><span data-stu-id="28137-113">Evaluation vs. Cross Validation</span></span>
<span data-ttu-id="28137-114">Avaliação e Validação cruzada são as formas padrão de medir o desempenho do seu modelo.</span><span class="sxs-lookup"><span data-stu-id="28137-114">Evaluation and cross validation are standard ways to measure the performance of your model.</span></span> <span data-ttu-id="28137-115">Ambas geram métricas de avaliação que você pode inspecionar ou comparar com os outros modelos.</span><span class="sxs-lookup"><span data-stu-id="28137-115">They both generate evaluation metrics that you can inspect or compare against those of other models.</span></span>

<span data-ttu-id="28137-116">[Avaliar Modelo][evaluate-model] espera um conjunto de dados de pontuação como entrada (ou 2 caso você deseje comparar o desempenho de 2 modelos diferentes).</span><span class="sxs-lookup"><span data-stu-id="28137-116">[Evaluate Model][evaluate-model] expects a scored dataset as input (or 2 in case you would like to compare the performance of 2 different models).</span></span> <span data-ttu-id="28137-117">Isso significa que você precisa treinar o modelo usando o módulo [Treinar Modelo][train-model] e fazer previsões em um conjunto de dados usando o módulo [Modelo de Pontuação][score-model] para poder avaliar os resultados.</span><span class="sxs-lookup"><span data-stu-id="28137-117">This means that you need to train your model using the [Train Model][train-model] module and make predictions on some dataset using the [Score Model][score-model] module, before you can evaluate the results.</span></span> <span data-ttu-id="28137-118">A avaliação se baseia nas probabilidades/rótulos pontuados juntamente com os rótulos verdadeiros, que são produzidos pelo módulo [Modelo de Pontuação][score-model].</span><span class="sxs-lookup"><span data-stu-id="28137-118">The evaluation is based on the scored labels/probabilities along with the true labels, all of which are output by the [Score Model][score-model] module.</span></span>

<span data-ttu-id="28137-119">Como alternativa, você pode usar a validação cruzada para executar várias operações para avaliar-treinar-pontuar (10 partições) automaticamente em diferentes subconjuntos dos dados de entrada.</span><span class="sxs-lookup"><span data-stu-id="28137-119">Alternatively, you can use cross validation to perform a number of train-score-evaluate operations (10 folds) automatically on different subsets of the input data.</span></span> <span data-ttu-id="28137-120">Os dados de entrada são divididos em 10 partes, em que uma está reservada para teste, e as outras 9 para treinamento.</span><span class="sxs-lookup"><span data-stu-id="28137-120">The input data is split into 10 parts, where one is reserved for testing, and the other 9 for training.</span></span> <span data-ttu-id="28137-121">Esse processo é repetido 10 vezes e as métricas de avaliação são transformadas em médias.</span><span class="sxs-lookup"><span data-stu-id="28137-121">This process is repeated 10 times and the evaluation metrics are averaged.</span></span> <span data-ttu-id="28137-122">Isso ajuda a determinar como um modelo seria generalizado para novos conjuntos de dados.</span><span class="sxs-lookup"><span data-stu-id="28137-122">This helps in determining how well a model would generalize to new datasets.</span></span> <span data-ttu-id="28137-123">O módulo [Modelo de Validação Cruzada][cross-validate-model] aproveita um modelo não treinado e alguns conjuntos de dados rotulados e gera os resultados da avaliação de cada uma das 10 partições, além dos resultados médios.</span><span class="sxs-lookup"><span data-stu-id="28137-123">The [Cross-Validate Model][cross-validate-model] module takes in an untrained model and some labeled dataset and outputs the evaluation results of each of the 10 folds, in addition to the averaged results.</span></span>

<span data-ttu-id="28137-124">Nas seções a seguir, compilaremos modelos de regressão e classificação simples e avaliaremos o desempenho usando os módulos [Avaliar Modelo][evaluate-model] e [Modelo de Validação Cruzada][cross-validate-model].</span><span class="sxs-lookup"><span data-stu-id="28137-124">In the following sections, we will build simple regression and classification models and evaluate their performance, using both the [Evaluate Model][evaluate-model] and the [Cross-Validate Model][cross-validate-model] modules.</span></span>

## <a name="evaluating-a-regression-model"></a><span data-ttu-id="28137-125">Avaliar um Modelo de regressão</span><span class="sxs-lookup"><span data-stu-id="28137-125">Evaluating a Regression Model</span></span>
<span data-ttu-id="28137-126">Suponha que desejamos prever o preço do carro usando alguns recursos, como dimensões, potência, especificações de mecanismo e assim por diante.</span><span class="sxs-lookup"><span data-stu-id="28137-126">Assume we want to predict a car’s price using some features such as dimensions, horsepower, engine specs, and so on.</span></span> <span data-ttu-id="28137-127">Este é um problema comum de regressão, em que a variável de destino (*preço*) é um valor numérico contínuo.</span><span class="sxs-lookup"><span data-stu-id="28137-127">This is a typical regression problem, where the target variable (*price*) is a continuous numeric value.</span></span> <span data-ttu-id="28137-128">Conseguimos ajustar um modelo de regressão linear simples que, considerando os valores das características de um determinado carro, pode prever o preço daquele carro.</span><span class="sxs-lookup"><span data-stu-id="28137-128">We can fit a simple linear regression model that, given the feature values of a certain car, can predict the price of that car.</span></span> <span data-ttu-id="28137-129">Esse modelo de regressão pode ser usado para a pontuação do mesmo conjunto de dados no qual treinamos.</span><span class="sxs-lookup"><span data-stu-id="28137-129">This regression model can be used to score the same dataset we trained on.</span></span> <span data-ttu-id="28137-130">Assim que tivermos os preços previstos para todos os carros, poderemos avaliar o desempenho do modelo observando quanto, em média, as previsões se desviam dos preços reais.</span><span class="sxs-lookup"><span data-stu-id="28137-130">Once we have the predicted prices for all of the cars, we can evaluate the performance of the model by looking at how much the predictions deviate from the actual prices on average.</span></span> <span data-ttu-id="28137-131">Para ilustrar isso, usamos o *conjunto de dados Dados de preço de automóvel (Brutos)* disponível na seção **Conjuntos de Dados Salvos** no Azure Machine Learning Studio.</span><span class="sxs-lookup"><span data-stu-id="28137-131">To illustrate this, we use the *Automobile price data (Raw) dataset* available in the **Saved Datasets** section in Azure Machine Learning Studio.</span></span>

### <a name="creating-the-experiment"></a><span data-ttu-id="28137-132">Criando o experimento</span><span class="sxs-lookup"><span data-stu-id="28137-132">Creating the Experiment</span></span>
<span data-ttu-id="28137-133">Adicione os seguintes módulos ao seu espaço de trabalho no Machine Learning Studio do Microsoft Azure:</span><span class="sxs-lookup"><span data-stu-id="28137-133">Add the following modules to your workspace in Azure Machine Learning Studio:</span></span>

* <span data-ttu-id="28137-134">Dados de preço de automóvel (Brutos)</span><span class="sxs-lookup"><span data-stu-id="28137-134">Automobile price data (Raw)</span></span>
* <span data-ttu-id="28137-135">[Regressão linear][linear-regression]</span><span class="sxs-lookup"><span data-stu-id="28137-135">[Linear Regression][linear-regression]</span></span>
* <span data-ttu-id="28137-136">[Modelo de Treinamento][train-model]</span><span class="sxs-lookup"><span data-stu-id="28137-136">[Train Model][train-model]</span></span>
* <span data-ttu-id="28137-137">[Modelo de Pontuação][score-model]</span><span class="sxs-lookup"><span data-stu-id="28137-137">[Score Model][score-model]</span></span>
* <span data-ttu-id="28137-138">[Avaliar Modelo][evaluate-model]</span><span class="sxs-lookup"><span data-stu-id="28137-138">[Evaluate Model][evaluate-model]</span></span>

<span data-ttu-id="28137-139">Conecte as portas, conforme mostrado abaixo na Figura 1 e defina a coluna Rótulo do módulo [Treinar Modelo][train-model] como *preço*.</span><span class="sxs-lookup"><span data-stu-id="28137-139">Connect the ports as shown below in Figure 1 and set the Label column of the [Train Model][train-model] module to *price*.</span></span>

![Avaliar um Modelo de regressão](media/machine-learning-evaluate-model-performance/1.png)

<span data-ttu-id="28137-141">Figura 1.</span><span class="sxs-lookup"><span data-stu-id="28137-141">Figure 1.</span></span> <span data-ttu-id="28137-142">Avaliar um Modelo de regressão.</span><span class="sxs-lookup"><span data-stu-id="28137-142">Evaluating a Regression Model.</span></span>

### <a name="inspecting-the-evaluation-results"></a><span data-ttu-id="28137-143">Inspecionando os Resultados da avaliação</span><span class="sxs-lookup"><span data-stu-id="28137-143">Inspecting the Evaluation Results</span></span>
<span data-ttu-id="28137-144">Depois de executar o experimento, você pode clicar na porta de saída do módulo [Avaliar Modelo][evaluate-model] e selecionar *Visualizar* para ver os resultados da avaliação.</span><span class="sxs-lookup"><span data-stu-id="28137-144">After running the experiment, you can click on the output port of the [Evaluate Model][evaluate-model] module and select *Visualize* to see the evaluation results.</span></span> <span data-ttu-id="28137-145">As métricas de avaliação disponíveis para modelos de regressão são: *Erro Absoluto Médio*, *Erro Absoluto Médio de Raiz*, *Erro Absoluto Relativo*, *Erro Quadrado Relativo* e *Coeficiente de Determinação*.</span><span class="sxs-lookup"><span data-stu-id="28137-145">The evaluation metrics available for regression models are: *Mean Absolute Error*, *Root Mean Absolute Error*, *Relative Absolute Error*, *Relative Squared Error*, and the *Coefficient of Determination*.</span></span>

<span data-ttu-id="28137-146">O termo "erro" aqui representa a diferença entre o valor previsto e o valor verdadeiro.</span><span class="sxs-lookup"><span data-stu-id="28137-146">The term "error" here represents the difference between the predicted value and the true value.</span></span> <span data-ttu-id="28137-147">O valor absoluto ou o quadrado dessa diferença geralmente são computados para capturar a magnitude total do erro em todas as instâncias, como a diferença entre o valor previsto e o verdadeiro pode ser negativa em alguns casos.</span><span class="sxs-lookup"><span data-stu-id="28137-147">The absolute value or the square of this difference are usually computed to capture the total magnitude of error across all instances, as the difference between the predicted and true value could be negative in some cases.</span></span> <span data-ttu-id="28137-148">As métricas de erro medem o desempenho de previsão de um modelo de regressão em termos do desvio da média de suas previsões dos valores verdadeiros.</span><span class="sxs-lookup"><span data-stu-id="28137-148">The error metrics measure the predictive performance of a regression model in terms of the mean deviation of its predictions from the true values.</span></span> <span data-ttu-id="28137-149">Valores mais baixos de erro significam que o modelo é mais preciso para fazer previsões.</span><span class="sxs-lookup"><span data-stu-id="28137-149">Lower error values mean the model is more accurate in making predictions.</span></span> <span data-ttu-id="28137-150">Uma métrica de erro geral 0 significa que o modelo se ajusta aos dados perfeitamente.</span><span class="sxs-lookup"><span data-stu-id="28137-150">An overall error metric of 0 means that the model fits the data perfectly.</span></span>

<span data-ttu-id="28137-151">O coeficiente de determinação, que também é conhecido como R ao quadrado, também é uma maneira padrão de medir o quão bem o modelo se ajusta aos dados.</span><span class="sxs-lookup"><span data-stu-id="28137-151">The coefficient of determination, which is also known as R squared, is also a standard way of measuring how well the model fits the data.</span></span> <span data-ttu-id="28137-152">Ele pode ser interpretado como a proporção da variação explicada pelo modelo.</span><span class="sxs-lookup"><span data-stu-id="28137-152">It can be interpreted as the proportion of variation explained by the model.</span></span> <span data-ttu-id="28137-153">Uma proporção mais alta é melhor nesse caso, em que 1 indica um ajuste perfeito.</span><span class="sxs-lookup"><span data-stu-id="28137-153">A higher proportion is better in this case, where 1 indicates a perfect fit.</span></span>

![Métrica de avaliação de regressão linear](media/machine-learning-evaluate-model-performance/2.png)

<span data-ttu-id="28137-155">Figura 2.</span><span class="sxs-lookup"><span data-stu-id="28137-155">Figure 2.</span></span> <span data-ttu-id="28137-156">Métrica de avaliação de regressão linear.</span><span class="sxs-lookup"><span data-stu-id="28137-156">Linear Regression Evaluation Metrics.</span></span>

### <a name="using-cross-validation"></a><span data-ttu-id="28137-157">Usando Validação Cruzada</span><span class="sxs-lookup"><span data-stu-id="28137-157">Using Cross Validation</span></span>
<span data-ttu-id="28137-158">Como mencionado anteriormente, você pode executar treinamento, pontuação e avaliações repetidas automaticamente usando o módulo [Modelo de Validação Cruzada][cross-validate-model].</span><span class="sxs-lookup"><span data-stu-id="28137-158">As mentioned earlier, you can perform repeated training, scoring and evaluations automatically using the [Cross-Validate Model][cross-validate-model] module.</span></span> <span data-ttu-id="28137-159">Tudo o que você precisa nesse caso é um conjunto de dados, um modelo não treinado e um módulo [Modelo de Validação Cruzada][cross-validate-model] (veja a figura abaixo).</span><span class="sxs-lookup"><span data-stu-id="28137-159">All you need in this case is a dataset, an untrained model, and a [Cross-Validate Model][cross-validate-model] module (see figure below).</span></span> <span data-ttu-id="28137-160">Observe que você precisa definir a coluna de rótulo como *preço* nas propriedades do módulo [Modelo de Validação Cruzada][cross-validate-model].</span><span class="sxs-lookup"><span data-stu-id="28137-160">Note that you need to set the label column to *price* in the [Cross-Validate Model][cross-validate-model] module’s properties.</span></span>

![Validação cruzada de um modelo de regressão](media/machine-learning-evaluate-model-performance/3.png)

<span data-ttu-id="28137-162">Figura 3.</span><span class="sxs-lookup"><span data-stu-id="28137-162">Figure 3.</span></span> <span data-ttu-id="28137-163">A validação cruzada em um modelo de regressão.</span><span class="sxs-lookup"><span data-stu-id="28137-163">Cross-Validating a Regression Model.</span></span>

<span data-ttu-id="28137-164">Depois de executar o experimento, você pode inspecionar os resultados da avaliação clicando na porta de saída à direita do módulo [Modelo de Validação Cruzada][cross-validate-model].</span><span class="sxs-lookup"><span data-stu-id="28137-164">After running the experiment, you can inspect the evaluation results by clicking on the right output port of the [Cross-Validate Model][cross-validate-model] module.</span></span> <span data-ttu-id="28137-165">Isso fornecerá uma exibição detalhada das métricas para cada iteração (partição) e os resultados médios de cada uma das métricas (Figura 4).</span><span class="sxs-lookup"><span data-stu-id="28137-165">This will provide a detailed view of the metrics for each iteration (fold), and the averaged results of each of the metrics (Figure 4).</span></span>

![Resultados de validação cruzada de um modelo de regressão](media/machine-learning-evaluate-model-performance/4.png)

<span data-ttu-id="28137-167">Figura 4.</span><span class="sxs-lookup"><span data-stu-id="28137-167">Figure 4.</span></span> <span data-ttu-id="28137-168">Resultados de Validação cruzada de um modelo de regressão.</span><span class="sxs-lookup"><span data-stu-id="28137-168">Cross-Validation Results of a Regression Model.</span></span>

## <a name="evaluating-a-binary-classification-model"></a><span data-ttu-id="28137-169">Avaliar um modelo de classificação binária</span><span class="sxs-lookup"><span data-stu-id="28137-169">Evaluating a Binary Classification Model</span></span>
<span data-ttu-id="28137-170">Em um cenário de classificação binária, a variável de destino tem somente dois resultados possíveis, por exemplo: {0, 1} ou {falso, verdadeiro}, {negativo, positivo}.</span><span class="sxs-lookup"><span data-stu-id="28137-170">In a binary classification scenario, the target variable has only two possible outcomes, for example: {0, 1} or {false, true}, {negative, positive}.</span></span> <span data-ttu-id="28137-171">Suponha que você terá um conjunto de dados de funcionários adultos com algumas variáveis demográficas e de emprego e que você será solicitado a prever o nível de renda, uma variável binária com os valores {“<=50K”, “>50K”}.</span><span class="sxs-lookup"><span data-stu-id="28137-171">Assume you are given a dataset of adult employees with some demographic and employment variables, and that you are asked to predict the income level, a binary variable with the values {“<=50K”, “>50K”}.</span></span> <span data-ttu-id="28137-172">Em outras palavras, a classe negativa representa os funcionários que recebem um valor menor ou igual a 50 mil por ano, e a classe positiva representa todos os outros funcionários.</span><span class="sxs-lookup"><span data-stu-id="28137-172">In other words, the negative class represents the employees who make less than or equal to 50K per year, and the positive class represents all other employees.</span></span> <span data-ttu-id="28137-173">Como no cenário de regressão, podemos treinar um modelo, pontuar alguns dados e avaliar os resultados.</span><span class="sxs-lookup"><span data-stu-id="28137-173">As in the regression scenario, we would train a model, score some data, and evaluate the results.</span></span> <span data-ttu-id="28137-174">A principal diferença é a opção de métricas que o Azure Machine Learning computa e as saídas.</span><span class="sxs-lookup"><span data-stu-id="28137-174">The main difference here is the choice of metrics Azure Machine Learning computes and outputs.</span></span> <span data-ttu-id="28137-175">Para ilustrar o cenário de previsão de nível de renda, utilizaremos o conjunto de dados [Adulto](http://archive.ics.uci.edu/ml/datasets/Adult) para criar um experimento de Azure Machine Learning e avaliar o desempenho de um modelo de regressão logística de duas classes, uma classificação binária tipicamente usada.</span><span class="sxs-lookup"><span data-stu-id="28137-175">To illustrate the income level prediction scenario, we will use the [Adult](http://archive.ics.uci.edu/ml/datasets/Adult) dataset to create an Azure Machine Learning experiment and evaluate the performance of a two-class logistic regression model, a commonly used binary classifier.</span></span>

### <a name="creating-the-experiment"></a><span data-ttu-id="28137-176">Criando o experimento</span><span class="sxs-lookup"><span data-stu-id="28137-176">Creating the Experiment</span></span>
<span data-ttu-id="28137-177">Adicione os seguintes módulos ao seu espaço de trabalho no Machine Learning Studio do Microsoft Azure:</span><span class="sxs-lookup"><span data-stu-id="28137-177">Add the following modules to your workspace in Azure Machine Learning Studio:</span></span>

* <span data-ttu-id="28137-178">Conjunto de dados de classificação binária de receita no recenseamento adulto</span><span class="sxs-lookup"><span data-stu-id="28137-178">Adult Census Income Binary Classification dataset</span></span>
* <span data-ttu-id="28137-179">[Regressão logística de duas classes][two-class-logistic-regression]</span><span class="sxs-lookup"><span data-stu-id="28137-179">[Two-Class Logistic Regression][two-class-logistic-regression]</span></span>
* <span data-ttu-id="28137-180">[Modelo de Treinamento][train-model]</span><span class="sxs-lookup"><span data-stu-id="28137-180">[Train Model][train-model]</span></span>
* <span data-ttu-id="28137-181">[Modelo de Pontuação][score-model]</span><span class="sxs-lookup"><span data-stu-id="28137-181">[Score Model][score-model]</span></span>
* <span data-ttu-id="28137-182">[Avaliar Modelo][evaluate-model]</span><span class="sxs-lookup"><span data-stu-id="28137-182">[Evaluate Model][evaluate-model]</span></span>

<span data-ttu-id="28137-183">Conecte as portas, conforme mostrado abaixo na Figura 5 e defina a coluna Rótulo do módulo [Treinar Modelo][train-model] como *renda*.</span><span class="sxs-lookup"><span data-stu-id="28137-183">Connect the ports as shown below in Figure 5 and set the Label column of the [Train Model][train-model] module to *income*.</span></span>

![Avaliar um modelo de classificação binária](media/machine-learning-evaluate-model-performance/5.png)

<span data-ttu-id="28137-185">Figura 5.</span><span class="sxs-lookup"><span data-stu-id="28137-185">Figure 5.</span></span> <span data-ttu-id="28137-186">Avaliar um modelo de classificação binária.</span><span class="sxs-lookup"><span data-stu-id="28137-186">Evaluating a Binary Classification Model.</span></span>

### <a name="inspecting-the-evaluation-results"></a><span data-ttu-id="28137-187">Inspecionando os Resultados da avaliação</span><span class="sxs-lookup"><span data-stu-id="28137-187">Inspecting the Evaluation Results</span></span>
<span data-ttu-id="28137-188">Depois de executar o experimento, você pode clicar na porta de saída do módulo [Avaliar Modelo][evaluate-model] e selecionar *Visualizar* para ver os resultados da avaliação (Figura 7).</span><span class="sxs-lookup"><span data-stu-id="28137-188">After running the experiment, you can click on the output port of the [Evaluate Model][evaluate-model] module and select *Visualize* to see the evaluation results (Figure 7).</span></span> <span data-ttu-id="28137-189">A métrica de avaliação disponível para modelos de classificação binária são: *Exatidão*, *Precisão*, *Recuperação*, *Pontuação F1* e *AUC*.</span><span class="sxs-lookup"><span data-stu-id="28137-189">The evaluation metrics available for binary classification models are: *Accuracy*, *Precision*, *Recall*, *F1 Score*, and *AUC*.</span></span> <span data-ttu-id="28137-190">Além disso, o módulo gera uma matriz de confusão, mostrando o número de verdadeiros positivos, de falsos negativos, de falsos positivos e de verdadeiros negativos, bem como as curas *ROC*, *Precisão/Recuperação* e *Elevação*.</span><span class="sxs-lookup"><span data-stu-id="28137-190">In addition, the module outputs a confusion matrix showing the number of true positives, false negatives, false positives, and true negatives, as well as *ROC*, *Precision/Recall*, and *Lift* curves.</span></span>

<span data-ttu-id="28137-191">A precisão é simplesmente a proporção das instâncias classificadas corretamente.</span><span class="sxs-lookup"><span data-stu-id="28137-191">Accuracy is simply the proportion of correctly classified instances.</span></span> <span data-ttu-id="28137-192">Geralmente, ela é a primeira métrica a observar ao avaliar um classificador.</span><span class="sxs-lookup"><span data-stu-id="28137-192">It is usually the first metric you look at when evaluating a classifier.</span></span> <span data-ttu-id="28137-193">No entanto, quando os dados de teste não estão desbalanceados (em que a maioria das instâncias pertence a uma das classes), ou você está mais interessado no desempenho em qualquer uma das classes, a precisão realmente não captura a eficácia de um classificador.</span><span class="sxs-lookup"><span data-stu-id="28137-193">However, when the test data is unbalanced (where most of the instances belong to one of the classes), or you are more interested in the performance on either one of the classes, accuracy doesn’t really capture the effectiveness of a classifier.</span></span> <span data-ttu-id="28137-194">No cenário de classificação de nível de renda, suponha que você esteja testando em alguns dados em que 99% das instâncias representam pessoas que ganham um valor menor ou igual a 50 mil por ano.</span><span class="sxs-lookup"><span data-stu-id="28137-194">In the income level classification scenario, assume you are testing on some data where 99% of the instances represent people who earn less than or equal to 50K per year.</span></span> <span data-ttu-id="28137-195">É possível obter uma precisão de 0,99 prevendo a classe “<=50K” para todas as instâncias.</span><span class="sxs-lookup"><span data-stu-id="28137-195">It is possible to achieve a 0.99 accuracy by predicting the class “<=50K” for all instances.</span></span> <span data-ttu-id="28137-196">O classificador parece estar fazendo um bom trabalho em geral nesse caso, mas na realidade, ele não consegue classificar qualquer uma das pessoas com um recebimento mais elevado (% 1) corretamente.</span><span class="sxs-lookup"><span data-stu-id="28137-196">The classifier in this case appears to be doing a good job overall, but in reality, it fails to classify any of the high-income individuals (the 1%) correctly.</span></span>

<span data-ttu-id="28137-197">Por esse motivo, é útil computar métricas adicionais que capturam aspectos mais específicos da avaliação.</span><span class="sxs-lookup"><span data-stu-id="28137-197">For that reason, it is helpful to compute additional metrics that capture more specific aspects of the evaluation.</span></span> <span data-ttu-id="28137-198">Antes de entrar em detalhes sobre essas métricas, é importante compreender a matriz de confusão de uma avaliação de classificação binária.</span><span class="sxs-lookup"><span data-stu-id="28137-198">Before going into the details of such metrics, it is important to understand the confusion matrix of a binary classification evaluation.</span></span> <span data-ttu-id="28137-199">Os rótulos de classe no conjunto de treinamento podem assumir apenas 2 valores possíveis, o que normalmente chamamos como positivo ou negativo.</span><span class="sxs-lookup"><span data-stu-id="28137-199">The class labels in the training set can take on only 2 possible values, which we usually refer to as positive or negative.</span></span> <span data-ttu-id="28137-200">As instâncias positivas e negativas que um classificador prevê corretamente são chamadas verdadeiros positivos (TP) e verdadeiros negativos (TN), respectivamente.</span><span class="sxs-lookup"><span data-stu-id="28137-200">The positive and negative instances that a classifier predicts correctly are called true positives (TP) and true negatives (TN), respectively.</span></span> <span data-ttu-id="28137-201">Da mesma forma, as instâncias classificadas incorretamente são chamadas de falsos positivos (FP) e falsos negativos (FN).</span><span class="sxs-lookup"><span data-stu-id="28137-201">Similarly, the incorrectly classified instances are called false positives (FP) and false negatives (FN).</span></span> <span data-ttu-id="28137-202">A matriz de confusão é simplesmente uma tabela que mostra o número de instâncias que se enquadram em cada uma dessas 4 categorias.</span><span class="sxs-lookup"><span data-stu-id="28137-202">The confusion matrix is simply a table showing the number of instances that fall under each of these 4 categories.</span></span> <span data-ttu-id="28137-203">O Azure Machine Learning decide automaticamente qual das duas classes no conjunto de dados é a classe positiva.</span><span class="sxs-lookup"><span data-stu-id="28137-203">Azure Machine Learning automatically decides which of the two classes in the dataset is the positive class.</span></span> <span data-ttu-id="28137-204">Se os rótulos de classe forem inteiros ou boolianos, as instâncias de rotuladas como 'true' ou '1' serão atribuídas à classe positiva.</span><span class="sxs-lookup"><span data-stu-id="28137-204">If the class labels are Boolean or integers, then the ‘true’ or ‘1’ labeled instances are assigned the positive class.</span></span> <span data-ttu-id="28137-205">Se os rótulos forem cadeias de caracteres, como no caso do conjunto de dados de renda, os rótulos serão classificados em ordem alfabética e o primeiro nível será escolhido para ser a classe negativa, enquanto o segundo nível será a classe positiva.</span><span class="sxs-lookup"><span data-stu-id="28137-205">If the labels are strings, as in the case of the income dataset, the labels are sorted alphabetically and the first level is chosen to be the negative class while the second level is the positive class.</span></span>

![Matriz de confusão de classificação binária](media/machine-learning-evaluate-model-performance/6a.png)

<span data-ttu-id="28137-207">Figura 6.</span><span class="sxs-lookup"><span data-stu-id="28137-207">Figure 6.</span></span> <span data-ttu-id="28137-208">Matriz de confusão de classificação binária.</span><span class="sxs-lookup"><span data-stu-id="28137-208">Binary Classification Confusion Matrix.</span></span>

<span data-ttu-id="28137-209">Voltando ao problema de classificação de renda, queremos fazer várias perguntas de avaliação que nos ajudam a compreender o desempenho do classificador usado.</span><span class="sxs-lookup"><span data-stu-id="28137-209">Going back to the income classification problem, we would want to ask several evaluation questions that help us understand the performance of the classifier used.</span></span> <span data-ttu-id="28137-210">Uma pergunta muito comum é: “Dentre os indivíduos que o modelo prevê estarem ganhando > 50 mil (TP + FP), quantos foram classificados corretamente (TP)?"</span><span class="sxs-lookup"><span data-stu-id="28137-210">A very natural question is: ‘Out of the individuals whom the model predicted to be earning >50K (TP+FP), how many were classified correctly (TP)?’</span></span> <span data-ttu-id="28137-211">Essa pergunta pode ser respondida, examinando a **Precisão** do modelo, que é a proporção de positivos que foram classificados corretamente: TP/(TP + FP).</span><span class="sxs-lookup"><span data-stu-id="28137-211">This question can be answered by looking at the **Precision** of the model, which is the proportion of positives that are classified correctly: TP/(TP+FP).</span></span> <span data-ttu-id="28137-212">Outra pergunta comum é “Dentre todos os funcionários com renda alta > 50 mil (TP + FN), quantos o classificador classifica corretamente (TP)".</span><span class="sxs-lookup"><span data-stu-id="28137-212">Another common question is “Out of all the high earning employees with income >50k (TP+FN), how many did the classifier classify correctly (TP)”.</span></span> <span data-ttu-id="28137-213">Na verdade, isso é a **Recuperação** ou a taxa de positivos verdadeiros: TP/(TP + FN) do classificador.</span><span class="sxs-lookup"><span data-stu-id="28137-213">This is actually the **Recall**, or the true positive rate: TP/(TP+FN) of the classifier.</span></span> <span data-ttu-id="28137-214">Você observará que há uma opção óbvia entre a precisão e a recuperação.</span><span class="sxs-lookup"><span data-stu-id="28137-214">You might notice that there is an obvious trade-off between precision and recall.</span></span> <span data-ttu-id="28137-215">Por exemplo, dado um conjunto de dados relativamente equilibrado, uma classificação que prevê principalmente instâncias positivas, teria um lembrete alto, mas uma precisão bastante baixa com muitas instâncias negativas deve ser classificada incorretamente, resultando em um grande número de falsos positivos.</span><span class="sxs-lookup"><span data-stu-id="28137-215">For example, given a relatively balanced dataset, a classifier that predicts mostly positive instances, would have a high recall, but a rather low precision as many of the negative instances would be misclassified resulting in a large number of false positives.</span></span> <span data-ttu-id="28137-216">Para ver um gráfico de como essas duas métricas variam, você pode clicar na curva ‘PRECISION/RECALL’ na página de saída do resultado de avaliação (parte superior esquerda da Figura 7).</span><span class="sxs-lookup"><span data-stu-id="28137-216">To see a plot of how these two metrics vary, you can click on the ‘PRECISION/RECALL’ curve in the evaluation result output page (top left part of Figure 7).</span></span>

![Resultados da avaliação de classificação binária](media/machine-learning-evaluate-model-performance/7.png)

<span data-ttu-id="28137-218">Figura 7.</span><span class="sxs-lookup"><span data-stu-id="28137-218">Figure 7.</span></span> <span data-ttu-id="28137-219">Resultados da avaliação de classificação binária.</span><span class="sxs-lookup"><span data-stu-id="28137-219">Binary Classification Evaluation Results.</span></span>

<span data-ttu-id="28137-220">Outra métrica relacionada usada com frequência é a **Pontuação F1**, que usa a precisão e a recuperação em consideração.</span><span class="sxs-lookup"><span data-stu-id="28137-220">Another related metric that is often used is the **F1 Score**, which takes both precision and recall into consideration.</span></span> <span data-ttu-id="28137-221">Ela é a média harmônica dessas 2 métricas e é calculada como tal: F1 = 2 (precisão x recuperação) / (precisão + recuperação).</span><span class="sxs-lookup"><span data-stu-id="28137-221">It is the harmonic mean of these 2 metrics and is computed as such: F1 = 2 (precision x recall) / (precision + recall).</span></span> <span data-ttu-id="28137-222">A pontuação F1 é uma boa maneira de resumir a avaliação de um único número, mas é sempre uma boa prática examinar a precisão e a recuperação para entender melhor como um classificador se comporta.</span><span class="sxs-lookup"><span data-stu-id="28137-222">The F1 score is a good way to summarize the evaluation in a single number, but it’s always a good practice to look at both precision and recall together to better understand how a classifier behaves.</span></span>

<span data-ttu-id="28137-223">Além disso, é possível inspecionar a taxa de positivos verdadeiros versus a taxa de falsos positivos na curva **ROC (Característica de Operação do Receptor)** e o valor correspondente de **AUC (Área sob a Curva)**.</span><span class="sxs-lookup"><span data-stu-id="28137-223">In addition, one can inspect the true positive rate vs. the false positive rate in the **Receiver Operating Characteristic (ROC)** curve and the corresponding **Area Under the Curve (AUC)** value.</span></span> <span data-ttu-id="28137-224">Quanto mais próxima essa curva estiver do canto superior esquerdo, melhor estará o desempenho do classificador (que é maximizar a taxa de positivos verdadeiros enquanto minimiza os falsos positivos).</span><span class="sxs-lookup"><span data-stu-id="28137-224">The closer this curve is to the upper left corner, the better the classifier’s performance is (that is maximizing the true positive rate while minimizing the false positive rate).</span></span> <span data-ttu-id="28137-225">As curvas que estão próximas à diagonal do gráfico, o resultado dos classificadores que tendem a fazer previsões próximas à previsão aleatória.</span><span class="sxs-lookup"><span data-stu-id="28137-225">Curves that are close to the diagonal of the plot, result from classifiers that tend to make predictions that are close to random guessing.</span></span>

### <a name="using-cross-validation"></a><span data-ttu-id="28137-226">Usando Validação Cruzada</span><span class="sxs-lookup"><span data-stu-id="28137-226">Using Cross Validation</span></span>
<span data-ttu-id="28137-227">Como no exemplo de regressão, podemos executar validação cruzada para treinar repetidamente, classificar e avaliar os diferentes subconjuntos de dados automaticamente.</span><span class="sxs-lookup"><span data-stu-id="28137-227">As in the regression example, we can perform cross validation to repeatedly train, score and evaluate different subsets of the data automatically.</span></span> <span data-ttu-id="28137-228">Da mesma forma, podemos usar o módulo [Modelo de Validação Cruzada][cross-validate-model], um modelo de regressão logística não treinado e um conjunto de dados.</span><span class="sxs-lookup"><span data-stu-id="28137-228">Similarly, we can use the [Cross-Validate Model][cross-validate-model] module, an untrained logistic regression model, and a dataset.</span></span> <span data-ttu-id="28137-229">A coluna de rótulo deve ser definida como *renda* nas propriedades do módulo [Modelo de Validação Cruzada][cross-validate-model].</span><span class="sxs-lookup"><span data-stu-id="28137-229">The label column must be set to *income* in the [Cross-Validate Model][cross-validate-model] module’s properties.</span></span> <span data-ttu-id="28137-230">Após executar o experimento e clicar na porta de saída à direita do módulo [Modelo de Validação Cruzada][cross-validate-model], podemos ver os valores de métrica de classificação binária para cada partição, além da média e do desvio padrão de cada um.</span><span class="sxs-lookup"><span data-stu-id="28137-230">After running the experiment and clicking on the right output port of the [Cross-Validate Model][cross-validate-model] module, we can see the binary classification metric values for each fold, in addition to the mean and standard deviation of each.</span></span> 

![Validação cruzada de um modelo de classificação binária](media/machine-learning-evaluate-model-performance/8.png)

<span data-ttu-id="28137-232">Figura 8.</span><span class="sxs-lookup"><span data-stu-id="28137-232">Figure 8.</span></span> <span data-ttu-id="28137-233">Validação cruzada em um modelo de classificação binária.</span><span class="sxs-lookup"><span data-stu-id="28137-233">Cross-Validating a Binary Classification Model.</span></span>

![Resultados de validação cruzada de um classificador binário](media/machine-learning-evaluate-model-performance/9.png)

<span data-ttu-id="28137-235">Figura 9.</span><span class="sxs-lookup"><span data-stu-id="28137-235">Figure 9.</span></span> <span data-ttu-id="28137-236">Resultados de validação cruzada de um classificador binário.</span><span class="sxs-lookup"><span data-stu-id="28137-236">Cross-Validation Results of a Binary Classifier.</span></span>

## <a name="evaluating-a-multiclass-classification-model"></a><span data-ttu-id="28137-237">Avaliar um modelo de classificação com multiclass</span><span class="sxs-lookup"><span data-stu-id="28137-237">Evaluating a Multiclass Classification Model</span></span>
<span data-ttu-id="28137-238">Nesse experimento, usaremos o conjunto de dados popular [Íris](http://archive.ics.uci.edu/ml/datasets/Iris "Íris"), que contém instâncias de 3 diferentes tipos (classes) da planta íris.</span><span class="sxs-lookup"><span data-stu-id="28137-238">In this experiment we will use the popular [Iris](http://archive.ics.uci.edu/ml/datasets/Iris "Iris") dataset which contains instances of 3 different types (classes) of the iris plant.</span></span> <span data-ttu-id="28137-239">Há 4 valores de recurso (comprimento/largura da sépala e comprimento/largura da pétala) para cada instância.</span><span class="sxs-lookup"><span data-stu-id="28137-239">There are 4 feature values (sepal length/width and petal length/width) for each instance.</span></span> <span data-ttu-id="28137-240">Nas experiências anteriores, treinamos e testamos os modelos usando os mesmos conjuntos de dados.</span><span class="sxs-lookup"><span data-stu-id="28137-240">In the previous experiments we trained and tested the models using the same datasets.</span></span> <span data-ttu-id="28137-241">Aqui, usaremos o módulo de [Dividir Dados][split] para criar 2 subconjuntos de dados, treinar no primeiro e pontuar e avaliar no segundo.</span><span class="sxs-lookup"><span data-stu-id="28137-241">Here, we will use the [Split Data][split] module to create 2 subsets of the data, train on the first, and score and evaluate on the second.</span></span> <span data-ttu-id="28137-242">O conjunto de dados Íris está disponível publicamente no [Repositório de Machine Learning UCI](http://archive.ics.uci.edu/ml/index.html) e pode ser baixado usando um módulo [Importar Dados][import-data].</span><span class="sxs-lookup"><span data-stu-id="28137-242">The Iris dataset is publicly available on the [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/index.html), and can be downloaded using an [Import Data][import-data] module.</span></span>

### <a name="creating-the-experiment"></a><span data-ttu-id="28137-243">Criando o experimento</span><span class="sxs-lookup"><span data-stu-id="28137-243">Creating the Experiment</span></span>
<span data-ttu-id="28137-244">Adicione os seguintes módulos ao seu espaço de trabalho no Machine Learning Studio do Microsoft Azure:</span><span class="sxs-lookup"><span data-stu-id="28137-244">Add the following modules to your workspace in Azure Machine Learning Studio:</span></span>

* <span data-ttu-id="28137-245">[Importar Dados][import-data]</span><span class="sxs-lookup"><span data-stu-id="28137-245">[Import Data][import-data]</span></span>
* <span data-ttu-id="28137-246">[Floresta de Decisão Multiclasse][multiclass-decision-forest]</span><span class="sxs-lookup"><span data-stu-id="28137-246">[Multiclass Decision Forest][multiclass-decision-forest]</span></span>
* <span data-ttu-id="28137-247">[Dividir Dados][split]</span><span class="sxs-lookup"><span data-stu-id="28137-247">[Split Data][split]</span></span>
* <span data-ttu-id="28137-248">[Modelo de Treinamento][train-model]</span><span class="sxs-lookup"><span data-stu-id="28137-248">[Train Model][train-model]</span></span>
* <span data-ttu-id="28137-249">[Modelo de Pontuação][score-model]</span><span class="sxs-lookup"><span data-stu-id="28137-249">[Score Model][score-model]</span></span>
* <span data-ttu-id="28137-250">[Avaliar Modelo][evaluate-model]</span><span class="sxs-lookup"><span data-stu-id="28137-250">[Evaluate Model][evaluate-model]</span></span>

<span data-ttu-id="28137-251">Conecte as portas, conforme mostrado abaixo na Figura 10.</span><span class="sxs-lookup"><span data-stu-id="28137-251">Connect the ports as shown below in Figure 10.</span></span>

<span data-ttu-id="28137-252">Configure o índice da coluna Rótulo do módulo [Treinar Modelo][train-model] como 5.</span><span class="sxs-lookup"><span data-stu-id="28137-252">Set the Label column index of the [Train Model][train-model] module to 5.</span></span> <span data-ttu-id="28137-253">O conjunto de dados não tem nenhuma linha de cabeçalho, mas sabemos que os rótulos de classe estão na quinta coluna.</span><span class="sxs-lookup"><span data-stu-id="28137-253">The dataset has no header row but we know that the class labels are in the fifth column.</span></span>

<span data-ttu-id="28137-254">Clique no módulo [Importar Dados][import-data] e defina a propriedade *Fonte de dados* como *URL da Web via HTTP* e a *URL* como http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data.</span><span class="sxs-lookup"><span data-stu-id="28137-254">Click on the [Import Data][import-data] module and set the *Data source* property to *Web URL via HTTP*, and the *URL* to http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data.</span></span>

<span data-ttu-id="28137-255">Defina a fração de instâncias a serem usadas para treinamento no módulo [Dividir Dados][split] (0,7, por exemplo).</span><span class="sxs-lookup"><span data-stu-id="28137-255">Set the fraction of instances to be used for training in the [Split Data][split] module (0.7 for example).</span></span>

![Avaliar um classificador Multiclass](media/machine-learning-evaluate-model-performance/10.png)

<span data-ttu-id="28137-257">Figura 10.</span><span class="sxs-lookup"><span data-stu-id="28137-257">Figure 10.</span></span> <span data-ttu-id="28137-258">Avaliar um classificador Multiclass</span><span class="sxs-lookup"><span data-stu-id="28137-258">Evaluating a Multiclass Classifier</span></span>

### <a name="inspecting-the-evaluation-results"></a><span data-ttu-id="28137-259">Inspecionando os Resultados da avaliação</span><span class="sxs-lookup"><span data-stu-id="28137-259">Inspecting the Evaluation Results</span></span>
<span data-ttu-id="28137-260">Execute o experimento e clique na porta de saída de [Avaliar Modelo][evaluate-model].</span><span class="sxs-lookup"><span data-stu-id="28137-260">Run the experiment and click on the output port of [Evaluate Model][evaluate-model].</span></span> <span data-ttu-id="28137-261">Os resultados de avaliação são apresentados na forma de uma matriz de confusão, nesse caso.</span><span class="sxs-lookup"><span data-stu-id="28137-261">The evaluation results are presented in the form of a confusion matrix, in this case.</span></span> <span data-ttu-id="28137-262">A matriz mostra o real versus as instâncias previstas para todas as 3 classes.</span><span class="sxs-lookup"><span data-stu-id="28137-262">The matrix shows the actual vs. predicted instances for all 3 classes.</span></span>

![Resultados da avaliação de classificação multiclass](media/machine-learning-evaluate-model-performance/11.png)

<span data-ttu-id="28137-264">Figura 11.</span><span class="sxs-lookup"><span data-stu-id="28137-264">Figure 11.</span></span> <span data-ttu-id="28137-265">Resultados da avaliação de classificação multiclass.</span><span class="sxs-lookup"><span data-stu-id="28137-265">Multiclass Classification Evaluation Results.</span></span>

### <a name="using-cross-validation"></a><span data-ttu-id="28137-266">Usando Validação Cruzada</span><span class="sxs-lookup"><span data-stu-id="28137-266">Using Cross Validation</span></span>
<span data-ttu-id="28137-267">Como mencionado anteriormente, você pode executar treinamento, pontuação e avaliações repetidas automaticamente usando o módulo [Modelo de Validação Cruzada][cross-validate-model].</span><span class="sxs-lookup"><span data-stu-id="28137-267">As mentioned earlier, you can perform repeated training, scoring and evaluations automatically using the [Cross-Validate Model][cross-validate-model] module.</span></span> <span data-ttu-id="28137-268">Você precisará de um conjunto de dados, um modelo não treinado e um módulo [Modelo de Validação Cruzada][cross-validate-model] (veja a figura abaixo).</span><span class="sxs-lookup"><span data-stu-id="28137-268">You would need a dataset, an untrained model, and a [Cross-Validate Model][cross-validate-model] module (see figure below).</span></span> <span data-ttu-id="28137-269">Novamente, você precisa definir a coluna de rótulo do módulo [Modelo de Validação Cruzada][cross-validate-model] (índice de coluna 5 neste caso).</span><span class="sxs-lookup"><span data-stu-id="28137-269">Again you need to set the label column of the [Cross-Validate Model][cross-validate-model] module (column index 5 in this case).</span></span> <span data-ttu-id="28137-270">Após executar o experimento e clicar na porta de saída à direita do [Modelo de Validação Cruzada][cross-validate-model], você pode inspecionar os valores de métrica para cada partição, além da média e do desvio padrão.</span><span class="sxs-lookup"><span data-stu-id="28137-270">After running the experiment and clicking the right output port of the [Cross-Validate Model][cross-validate-model], you can inspect the metric values for each fold as well as the mean and standard deviation.</span></span> <span data-ttu-id="28137-271">As métricas exibidas aqui são semelhantes àquelas discutidas no caso de classificação binária.</span><span class="sxs-lookup"><span data-stu-id="28137-271">The metrics displayed here are the similar to the ones discussed in the binary classification case.</span></span> <span data-ttu-id="28137-272">No entanto, observe que em classificação multiclass, os verdadeiros positivos/negativos e falsos positivos/negativos de computação são feitos baseados em uma base por classe, pois não há nenhuma classe geral positiva ou negativa.</span><span class="sxs-lookup"><span data-stu-id="28137-272">However, note that in multiclass classification, computing the true positives/negatives and false positives/negatives is done by counting on a per-class basis, as there is no overall positive or negative class.</span></span> <span data-ttu-id="28137-273">Por exemplo, ao computar a precisão ou o cancelamento da classe ‘Iris-setosa’, supõe-se que essa seja a classe positiva e todas as outras sejam negativas.</span><span class="sxs-lookup"><span data-stu-id="28137-273">For example, when computing the precision or recall of the ‘Iris-setosa’ class, it is assumed that this is the positive class and all others as negative.</span></span>

![Validação cruzada de um modelo de classificação multiclass](media/machine-learning-evaluate-model-performance/12.png)

<span data-ttu-id="28137-275">Figura 12.</span><span class="sxs-lookup"><span data-stu-id="28137-275">Figure 12.</span></span> <span data-ttu-id="28137-276">Validação cruzada em um modelo de classificação Multiclass.</span><span class="sxs-lookup"><span data-stu-id="28137-276">Cross-Validating a Multiclass Classification Model.</span></span>

![Resultados da validação cruzada de um modelo de classificação multiclass](media/machine-learning-evaluate-model-performance/13.png)

<span data-ttu-id="28137-278">Figura 13.</span><span class="sxs-lookup"><span data-stu-id="28137-278">Figure 13.</span></span> <span data-ttu-id="28137-279">Resultados da validação cruzada de um modelo de classificação multiclass.</span><span class="sxs-lookup"><span data-stu-id="28137-279">Cross-Validation Results of a Multiclass Classification Model.</span></span>

<!-- Module References -->
[cross-validate-model]: https://msdn.microsoft.com/library/azure/75fb875d-6b86-4d46-8bcc-74261ade5826/
[evaluate-model]: https://msdn.microsoft.com/library/azure/927d65ac-3b50-4694-9903-20f6c1672089/
[linear-regression]: https://msdn.microsoft.com/library/azure/31960a6f-789b-4cf7-88d6-2e1152c0bd1a/
[multiclass-decision-forest]: https://msdn.microsoft.com/library/azure/5e70108d-2e44-45d9-86e8-94f37c68fe86/
[import-data]: https://msdn.microsoft.com/library/azure/4e1b0fe6-aded-4b3f-a36f-39b8862b9004/
[score-model]: https://msdn.microsoft.com/library/azure/401b4f92-e724-4d5a-be81-d5b0ff9bdb33/
[split]: https://msdn.microsoft.com/library/azure/70530644-c97a-4ab6-85f7-88bf30a8be5f/
[train-model]: https://msdn.microsoft.com/library/azure/5cc7053e-aa30-450d-96c0-dae4be720977/
[two-class-logistic-regression]: https://msdn.microsoft.com/library/azure/b0fd7660-eeed-43c5-9487-20d9cc79ed5d/

