---
title: "Visão geral da Ciência de dados usando Spark no Azure HDInsight | Microsoft Docs"
description: "O kit de ferramentas Spark MLlib traz recursos consideráveis de modelagem de aprendizado de máquina para o ambiente distribuído do HDInsight."
services: machine-learning
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: a4e1de99-a554-4240-9647-2c6d669593c8
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/15/2017
ms.author: deguhath;bradsev;gokuma
ms.openlocfilehash: 379b32f4e533f48f1593a97e73737a0c5bfb9135
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: pt-BR
ms.lasthandoff: 07/11/2017
---
# <a name="overview-of-data-science-using-spark-on-azure-hdinsight"></a><span data-ttu-id="c21b2-103">Visão geral da ciência de dados usando Spark no Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="c21b2-103">Overview of data science using Spark on Azure HDInsight</span></span>
[!INCLUDE [machine-learning-spark-modeling](../../includes/machine-learning-spark-modeling.md)]

<span data-ttu-id="c21b2-104">Este conjunto de tópicos mostra como usar o HDInsight Spark para concluir tarefas comuns de ciência de dados, tais como ingestão de dados, engenharia de recursos, modelagem e avaliação de modelo.</span><span class="sxs-lookup"><span data-stu-id="c21b2-104">This suite of topics shows how to use HDInsight Spark to complete common data science tasks such as data ingestion, feature engineering, modeling, and model evaluation.</span></span> <span data-ttu-id="c21b2-105">Os dados usados são uma amostra do conjunto de dados de corridas e tarifas de táxi em Nova York de 2013.</span><span class="sxs-lookup"><span data-stu-id="c21b2-105">The data used is a sample of the 2013 NYC taxi trip and fare dataset.</span></span> <span data-ttu-id="c21b2-106">Os modelos criados incluem a regressão logística e linear, florestas aleatórias e árvores aumentadas gradientes.</span><span class="sxs-lookup"><span data-stu-id="c21b2-106">The models built include logistic and linear regression, random forests, and gradient boosted trees.</span></span> <span data-ttu-id="c21b2-107">Os tópicos também mostram como armazenar esses modelos no Armazenamento de Blobs do Azure (WASB) e como pontuar e avaliar seu desempenho preditivo.</span><span class="sxs-lookup"><span data-stu-id="c21b2-107">The topics also show how to store these models in Azure blob storage (WASB) and how to score and evaluate their predictive performance.</span></span> <span data-ttu-id="c21b2-108">Os tópicos mais avançados abordam como os modelos podem ser treinados usando a validação cruzada e a limpeza de hiperparâmetro.</span><span class="sxs-lookup"><span data-stu-id="c21b2-108">More advanced topics cover how models can be trained using cross-validation and hyper-parameter sweeping.</span></span> <span data-ttu-id="c21b2-109">Este tópico de visão geral também referencia os tópicos que descrevem como configurar um cluster Spark necessário para concluir as etapas no passo a passos fornecido.</span><span class="sxs-lookup"><span data-stu-id="c21b2-109">This overview topic also references the topics that describe how to set up the Spark cluster that you need to complete the steps in the walkthroughs provided.</span></span> 

## <a name="spark-and-mllib"></a><span data-ttu-id="c21b2-110">Spark e MLlib</span><span class="sxs-lookup"><span data-stu-id="c21b2-110">Spark and MLlib</span></span>
<span data-ttu-id="c21b2-111">[Spark](http://spark.apache.org/) é uma estrutura de processamento paralelo de software livre que dá suporte ao processamento na memória para melhorar o desempenho de aplicativos analíticos de Big Data.</span><span class="sxs-lookup"><span data-stu-id="c21b2-111">[Spark](http://spark.apache.org/) is an open-source parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications.</span></span> <span data-ttu-id="c21b2-112">O mecanismo de processamento do Spark foi desenvolvido para velocidade, facilidade de uso e análise sofisticada.</span><span class="sxs-lookup"><span data-stu-id="c21b2-112">The Spark processing engine is built for speed, ease of use, and sophisticated analytics.</span></span> <span data-ttu-id="c21b2-113">As funcionalidades de computação distribuídas na memória do Spark fazem dele uma boa escolha para algoritmos iterativos usados em cálculos de gráfico e aprendizado de máquina.</span><span class="sxs-lookup"><span data-stu-id="c21b2-113">Spark's in-memory distributed computation capabilities make it a good choice for the iterative algorithms used in machine learning and graph computations.</span></span> <span data-ttu-id="c21b2-114">[MLlib](http://spark.apache.org/mllib/) é a biblioteca de aprendizado de máquina escalonável do Spark que oferece recursos de modelagem de algoritmo para esse ambiente distribuído.</span><span class="sxs-lookup"><span data-stu-id="c21b2-114">[MLlib](http://spark.apache.org/mllib/) is Spark's scalable machine learning library that brings the algorithmic modeling capabilities to this distributed environment.</span></span> 

## <a name="hdinsight-spark"></a><span data-ttu-id="c21b2-115">HDInsight Spark</span><span class="sxs-lookup"><span data-stu-id="c21b2-115">HDInsight Spark</span></span>
<span data-ttu-id="c21b2-116">[HDInsight Spark](../hdinsight/hdinsight-apache-spark-overview.md) é a oferta do Spark de software livre hospedada no Azure.</span><span class="sxs-lookup"><span data-stu-id="c21b2-116">[HDInsight Spark](../hdinsight/hdinsight-apache-spark-overview.md) is the Azure hosted offering of open-source Spark.</span></span> <span data-ttu-id="c21b2-117">Ele também inclui suporte para **notebooks do Jupyter PySpark** no cluster Spark, que podem executar consultas Spark SQL interativas para transformar, filtrar e visualizar dados armazenados em Blobs do Azure (WASB).</span><span class="sxs-lookup"><span data-stu-id="c21b2-117">It also includes support for **Jupyter PySpark notebooks** on the Spark cluster that can run Spark SQL interactive queries for transforming, filtering, and visualizing data stored in Azure Blobs (WASB).</span></span> <span data-ttu-id="c21b2-118">PySpark é a API do Python para o Spark.</span><span class="sxs-lookup"><span data-stu-id="c21b2-118">PySpark is the Python API for Spark.</span></span> <span data-ttu-id="c21b2-119">Os trechos de código que fornecem as soluções e mostram as plotagens relevantes para visualizar os dados aqui são executados em notebooks do Jupyter instalados nos clusters Spark.</span><span class="sxs-lookup"><span data-stu-id="c21b2-119">The code snippets that provide the solutions and show the relevant plots to visualize the data here run in Jupyter notebooks installed on the Spark clusters.</span></span> <span data-ttu-id="c21b2-120">As etapas de modelagem nesses tópicos contêm código que mostra como treinar, avaliar, salvar e consumir cada tipo de modelo.</span><span class="sxs-lookup"><span data-stu-id="c21b2-120">The modeling steps in these topics contain code that shows how to train, evaluate, save, and consume each type of model.</span></span> 

## <a name="setup-spark-clusters-and-jupyter-notebooks"></a><span data-ttu-id="c21b2-121">Instalação: Clusters do Spark e Notebooks Jupyter</span><span class="sxs-lookup"><span data-stu-id="c21b2-121">Setup: Spark clusters and Jupyter notebooks</span></span>
<span data-ttu-id="c21b2-122">As etapas de configuração e o código são fornecidos neste passo a passo para usar um HDInsight Spark 1.6.</span><span class="sxs-lookup"><span data-stu-id="c21b2-122">Setup steps and code are provided in this walkthrough for using an HDInsight Spark 1.6.</span></span> <span data-ttu-id="c21b2-123">Porém, notebooks Jupyter são fornecidos tanto para o HDInsight Spark 1.6 quanto para os clusters Spark 2.0.</span><span class="sxs-lookup"><span data-stu-id="c21b2-123">But Jupyter notebooks are provided for both HDInsight Spark 1.6 and Spark 2.0 clusters.</span></span> <span data-ttu-id="c21b2-124">Uma descrição de notebooks e links são fornecidos em [Readme.md](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Readme.md) para o repositório do GitHub que os contém.</span><span class="sxs-lookup"><span data-stu-id="c21b2-124">A description of the notebooks and links to them are provided in the [Readme.md](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Readme.md) for the GitHub repository containing them.</span></span> <span data-ttu-id="c21b2-125">No entanto, o código mostrado aqui e nos notebooks vinculados é genérico e funcionarão em qualquer cluster Spark.</span><span class="sxs-lookup"><span data-stu-id="c21b2-125">Moreover, the code here and in the linked notebooks is generic and should work on any Spark cluster.</span></span> <span data-ttu-id="c21b2-126">Se você não estiver usando o HDInsight Spark, as etapas de configuração e gerenciamento do cluster poderão ser ligeiramente diferentes do que é mostrado aqui.</span><span class="sxs-lookup"><span data-stu-id="c21b2-126">If you are not using HDInsight Spark, the cluster setup and management steps may be slightly different from what is shown here.</span></span> <span data-ttu-id="c21b2-127">Para sua conveniência, aqui estão os links para os notebooks Jupyter para Spark 1.6 (para execução no kernel do pySpark do servidor Jupyter Notebook) e Spark 2.0 (para execução no kernel pySpark3 do servidor Jupyter Notebook):</span><span class="sxs-lookup"><span data-stu-id="c21b2-127">For convenience, here are the links to the Jupyter notebooks for Spark 1.6 (to be run in the pySpark kernel of the Jupyter Notebook server) and  Spark 2.0 (to be run in the pySpark3 kernel of the Jupyter Notebook server):</span></span>

### <a name="spark-16-notebooks"></a><span data-ttu-id="c21b2-128">Notebooks Spark 1.6</span><span class="sxs-lookup"><span data-stu-id="c21b2-128">Spark 1.6 notebooks</span></span>
<span data-ttu-id="c21b2-129">Esses notebooks devem ser executados no kernel pySpark do servidor de notebook Jupyter.</span><span class="sxs-lookup"><span data-stu-id="c21b2-129">These notebooks are to be run in the pySpark kernel of Jupyter notebook server.</span></span>

- <span data-ttu-id="c21b2-130">[pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb): fornece informações sobre como executar a exploração, a modelagem e a pontuação de dados com vários algoritmos diferentes.</span><span class="sxs-lookup"><span data-stu-id="c21b2-130">[pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb): Provides information on how to perform data exploration, modeling, and scoring with several different algorithms.</span></span>
- <span data-ttu-id="c21b2-131">[pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): inclui tópicos de notebook nº 1 e o desenvolvimento de modelos usando ajude e validação cruzada de hiperparâmetro.</span><span class="sxs-lookup"><span data-stu-id="c21b2-131">[pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): Includes topics in notebook #1, and model development using hyperparameter tuning and cross-validation.</span></span>
- <span data-ttu-id="c21b2-132">[pySpark-machine-learning-data-science-spark-model-consumption.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb): mostra como colocar em operação um modelo salvo usando o Python em clusters HDInsight.</span><span class="sxs-lookup"><span data-stu-id="c21b2-132">[pySpark-machine-learning-data-science-spark-model-consumption.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb): Shows how to operationalize a saved model using Python on HDInsight clusters.</span></span>

### <a name="spark-20-notebooks"></a><span data-ttu-id="c21b2-133">Notebooks Spark 2.0</span><span class="sxs-lookup"><span data-stu-id="c21b2-133">Spark 2.0 notebooks</span></span>
<span data-ttu-id="c21b2-134">Esses notebooks devem ser executados no kernel pySpark3 do servidor de notebook Jupyter.</span><span class="sxs-lookup"><span data-stu-id="c21b2-134">These notebooks are to be run in the pySpark3 kernel of Jupyter notebook server.</span></span>

- <span data-ttu-id="c21b2-135">[Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): este arquivo fornece informações sobre como realizar a exploração, modelagem e classificação de dados nos clusters do Spark 2.0 usando o conjunto de dados de tarifas e viagens de Táxi de Nova York descrito [aqui](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span><span class="sxs-lookup"><span data-stu-id="c21b2-135">[Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): This file provides information on how to perform data exploration, modeling, and scoring in Spark 2.0 clusters using the NYC Taxi trip and fare data-set described [here](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span></span> <span data-ttu-id="c21b2-136">Este notebook pode ser um bom ponto de partida para explorar rapidamente o código que fornecemos para o Spark 2.0.</span><span class="sxs-lookup"><span data-stu-id="c21b2-136">This notebook may be a good starting point for quickly exploring the code we have provided for Spark 2.0.</span></span> <span data-ttu-id="c21b2-137">Para uma análise mais detalhada do notebook dos dados de Táxi de Nova York, veja o próximo notebook nesta lista.</span><span class="sxs-lookup"><span data-stu-id="c21b2-137">For a more detailed notebook analyzes the NYC Taxi data, see the next notebook in this list.</span></span> <span data-ttu-id="c21b2-138">Veja as anotações após esta lista que comparam esses notebooks.</span><span class="sxs-lookup"><span data-stu-id="c21b2-138">See the notes following this list that compare these notebooks.</span></span> 
- <span data-ttu-id="c21b2-139">[Spark2.0-pySpark3_NYC_Taxi_Tip_Regression.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_NYC_Taxi_Tip_Regression.ipynb): esse arquivo mostra como executar disputa de dados (operações SQL Spark e dataframe), exploração, modelagem e pontuação, utilizando as viagens de táxi de NYC e conjunto de dados de tarifas descritas [aqui](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span><span class="sxs-lookup"><span data-stu-id="c21b2-139">[Spark2.0-pySpark3_NYC_Taxi_Tip_Regression.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_NYC_Taxi_Tip_Regression.ipynb): This file shows how to perform data wrangling (Spark SQL and dataframe operations), exploration, modeling and scoring using the NYC Taxi trip and fare data-set described [here](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span></span>
- <span data-ttu-id="c21b2-140">[Spark2.0-pySpark3_Airline_Departure_Delay_Classification.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_Airline_Departure_Delay_Classification.ipynb): esse arquivo mostra como executar disputa de dados (operações SQL Spark e dataframe), exploração, modelagem e pontuação, utilizando um conjunto de dados de partidas no horário de uma companhia aérea conhecida de 2011 e 2012.</span><span class="sxs-lookup"><span data-stu-id="c21b2-140">[Spark2.0-pySpark3_Airline_Departure_Delay_Classification.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_Airline_Departure_Delay_Classification.ipynb): This file shows how to perform data wrangling (Spark SQL and dataframe operations), exploration, modeling and scoring using the well-known Airline On-time departure dataset from 2011 and 2012.</span></span> <span data-ttu-id="c21b2-141">Integramos o conjunto de dados da companhia aérea com os dados de clima do aeroporto (por exemplo, velocidade do vento, temperatura, altitude etc.) antes da modelagem, para que esses recursos de tempo pudessem ser incluídos no modelo.</span><span class="sxs-lookup"><span data-stu-id="c21b2-141">We integrated the airline dataset with the airport weather data (e.g. windspeed, temperature, altitude etc.) prior to modeling, so these weather features can be included in the model.</span></span>

<!-- -->

> [!NOTE]
> <span data-ttu-id="c21b2-142">O conjunto de dados da companhia aérea foi adicionado ao notebook Spark 2.0 para melhor ilustrar os algoritmos de classificação.</span><span class="sxs-lookup"><span data-stu-id="c21b2-142">The airline dataset was added to the Spark 2.0 notebooks to better illustrate the use of classification algorithms.</span></span> <span data-ttu-id="c21b2-143">Consulte os links a seguir para obter informações sobre um conjunto de dados de partidas no horário e de clima:</span><span class="sxs-lookup"><span data-stu-id="c21b2-143">See the following links for information about airline on-time departure dataset and weather dataset:</span></span>

>- <span data-ttu-id="c21b2-144">Dados de partidas no horário em aeroportos: [http://www.transtats.bts.gov/ONTIME/](http://www.transtats.bts.gov/ONTIME/)</span><span class="sxs-lookup"><span data-stu-id="c21b2-144">Airline on-time departure data: [http://www.transtats.bts.gov/ONTIME/](http://www.transtats.bts.gov/ONTIME/)</span></span>

>- <span data-ttu-id="c21b2-145">Dados de clima aeroporto: [https://www.ncdc.noaa.gov/](https://www.ncdc.noaa.gov/)</span><span class="sxs-lookup"><span data-stu-id="c21b2-145">Airport weather data: [https://www.ncdc.noaa.gov/](https://www.ncdc.noaa.gov/)</span></span> 
> 
> 

<!-- -->

<!-- -->

> [!NOTE]
<span data-ttu-id="c21b2-146">Os notebooks do Spark 2.0 dos conjuntos de dados de atrasos de voo e táxi de Nova York podem levar 10 minutos ou mais para serem executados (dependendo do tamanho do seu cluster de HDI).</span><span class="sxs-lookup"><span data-stu-id="c21b2-146">The Spark 2.0 notebooks on the NYC taxi and airline flight delay data-sets can take 10 mins or more to run (depending on the size of your HDI cluster).</span></span> <span data-ttu-id="c21b2-147">O primeiro notebook da lista acima mostra muitos aspectos da exploração, visualização e treinamento de modelo AM de dados em um notebook que leva menos tempo para ser executado com um conjunto de dados de Nova York do exemplo abaixo, em que os arquivos de tarifas e táxi foram previamente integrados: [Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb) Este notebook leva menos tempo para concluir (2 a 3 minutos) e pode ser um bom ponto de partida para a exploração rápida do código que fornecemos para o Spark 2.0.</span><span class="sxs-lookup"><span data-stu-id="c21b2-147">The first notebook in the above list shows many aspects of the data exploration, visualization and ML model training in a notebook that takes less time to run with down-sampled NYC data set, in which the taxi and fare files have been pre-joined: [Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb) This notebook takes a much shorter time to finish (2-3 mins) and may be a good starting point for quickly exploring the code we have provided for Spark 2.0.</span></span> 

<!-- -->

<span data-ttu-id="c21b2-148">Para obter orientação sobre a operacionalização de um modelo Spark 2.0 e consumo do modelo para pontuação, consulte o [documento sobre consumo do Spark 1.6](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb) para obter um exemplo que descreva as etapas necessárias.</span><span class="sxs-lookup"><span data-stu-id="c21b2-148">For guidance on the operationalization of a Spark 2.0 model and model consumption for scoring, see the [Spark 1.6 document on consumption](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb) for an example outlining the steps required.</span></span> <span data-ttu-id="c21b2-149">Para usar no Spark 2.0, substitua o arquivo de código Python por [esse arquivo](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/Python/Spark2.0_ConsumeRFCV_NYCReg.py).</span><span class="sxs-lookup"><span data-stu-id="c21b2-149">To use this on Spark 2.0, replace the Python code file with [this file](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/Python/Spark2.0_ConsumeRFCV_NYCReg.py).</span></span>

### <a name="prerequisites"></a><span data-ttu-id="c21b2-150">Pré-requisitos</span><span class="sxs-lookup"><span data-stu-id="c21b2-150">Prerequisites</span></span>
<span data-ttu-id="c21b2-151">Os procedimentos a seguir são relacionados ao Spark 1.6.</span><span class="sxs-lookup"><span data-stu-id="c21b2-151">The following procedures are related to Spark 1.6.</span></span> <span data-ttu-id="c21b2-152">Para as versões do Spark 2.0, use os notebooks descritos e vinculados anteriormente.</span><span class="sxs-lookup"><span data-stu-id="c21b2-152">For  the Spark 2.0 version, use the notebooks described and linked to previously.</span></span> 

<span data-ttu-id="c21b2-153">1.Você precisa ter uma assinatura do Azure.</span><span class="sxs-lookup"><span data-stu-id="c21b2-153">1.You must have an Azure subscription.</span></span> <span data-ttu-id="c21b2-154">Se ainda não tiver uma, veja [Obter avaliação gratuita do Azure](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span><span class="sxs-lookup"><span data-stu-id="c21b2-154">If you do not already have one, see [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span></span>

<span data-ttu-id="c21b2-155">2. Você precisa de um cluster Spark 1.6 para concluir este passo a passo.</span><span class="sxs-lookup"><span data-stu-id="c21b2-155">2.You need a Spark 1.6 cluster to complete this walkthrough.</span></span> <span data-ttu-id="c21b2-156">Para criar um, veja as instruções fornecidas em [Introdução: criar um Apache Spark no Azure HDInsight](../hdinsight/hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="c21b2-156">To create one, see the instructions provided in [Get started: create Apache Spark on Azure HDInsight](../hdinsight/hdinsight-apache-spark-jupyter-spark-sql.md).</span></span> <span data-ttu-id="c21b2-157">O tipo de cluster e a versão são especificados no menu **Selecionar Tipo de Cluster** .</span><span class="sxs-lookup"><span data-stu-id="c21b2-157">The cluster type and version is specified from the **Select Cluster Type** menu.</span></span> 

![Configurar cluster](./media/machine-learning-data-science-spark-overview/spark-cluster-on-portal.png)

<!-- -->

> [!NOTE]
> <span data-ttu-id="c21b2-159">Para ver um tópico que mostra como usar o Scala, em vez do Python, para concluir as tarefas em um processo completo de ciência de dados, confira [Ciência de dados usando Scala com Spark no Azure](machine-learning-data-science-process-scala-walkthrough.md).</span><span class="sxs-lookup"><span data-stu-id="c21b2-159">For a topic that shows how to use Scala rather than Python to complete tasks for an end-to-end data science process, see the [Data Science using Scala with Spark on Azure](machine-learning-data-science-process-scala-walkthrough.md).</span></span>
> 
> 

<!-- -->

> [!INCLUDE [delete-cluster-warning](../../includes/hdinsight-delete-cluster-warning.md)]
> 
> 

## <a name="the-nyc-2013-taxi-data"></a><span data-ttu-id="c21b2-160">Os dados de Táxi em NYC em 2013</span><span class="sxs-lookup"><span data-stu-id="c21b2-160">The NYC 2013 Taxi data</span></span>
<span data-ttu-id="c21b2-161">Os dados de Viagens de Táxi em NYC são cerca de 20 GB de arquivos compactados em valores separados por vírgulas (CSV) (cerca de 48 GB descompactados), que incluem mais de 173 milhões de viagens individuais e a tarifa paga por cada viagem.</span><span class="sxs-lookup"><span data-stu-id="c21b2-161">The NYC Taxi Trip data is about 20 GB of compressed comma-separated values (CSV) files (~48 GB uncompressed), comprising more than 173 million individual trips and the fares paid for each trip.</span></span> <span data-ttu-id="c21b2-162">Cada registro de corrida inclui o local e horário de saída e chegada, número da carteira de motorista de taxista anônima e o número do medalhão (identificador exclusivo do táxi).</span><span class="sxs-lookup"><span data-stu-id="c21b2-162">Each trip record includes the pick up and drop-off location and time, anonymized hack (driver's) license number and medallion (taxi’s unique id) number.</span></span> <span data-ttu-id="c21b2-163">Os dados abrangem todas as corridas no ano de 2013 e são fornecidos nos dois conjuntos de dados a seguir para cada mês:</span><span class="sxs-lookup"><span data-stu-id="c21b2-163">The data covers all trips in the year 2013 and is provided in the following two datasets for each month:</span></span>

1. <span data-ttu-id="c21b2-164">Os arquivos CSV “trip_data” contêm detalhes da corrida, como o número de passageiros, pontos de saída e chegada, duração e extensão da corrida.</span><span class="sxs-lookup"><span data-stu-id="c21b2-164">The 'trip_data' CSV files contain trip details, such as number of passengers, pick up and dropoff points, trip duration, and trip length.</span></span> <span data-ttu-id="c21b2-165">Aqui estão alguns exemplos de registros:</span><span class="sxs-lookup"><span data-stu-id="c21b2-165">Here are a few sample records:</span></span>
   
        medallion,hack_license,vendor_id,rate_code,store_and_fwd_flag,pickup_datetime,dropoff_datetime,passenger_count,trip_time_in_secs,trip_distance,pickup_longitude,pickup_latitude,dropoff_longitude,dropoff_latitude
        89D227B655E5C82AECF13C3F540D4CF4,BA96DE419E711691B9445D6A6307C170,CMT,1,N,2013-01-01 15:11:48,2013-01-01 15:18:10,4,382,1.00,-73.978165,40.757977,-73.989838,40.751171
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,1,N,2013-01-06 00:18:35,2013-01-06 00:22:54,1,259,1.50,-74.006683,40.731781,-73.994499,40.75066
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,1,N,2013-01-05 18:49:41,2013-01-05 18:54:23,1,282,1.10,-74.004707,40.73777,-74.009834,40.726002
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,1,N,2013-01-07 23:54:15,2013-01-07 23:58:20,2,244,.70,-73.974602,40.759945,-73.984734,40.759388
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,1,N,2013-01-07 23:25:03,2013-01-07 23:34:24,1,560,2.10,-73.97625,40.748528,-74.002586,40.747868
2. <span data-ttu-id="c21b2-166">Os arquivos CSV “trip_fare” contêm detalhes sobre as passagens pagas por cada corrida, como tipo de pagamento, valor da tarifa, custos adicionais e impostos, gorjetas e pedágios, e o valor total pago.</span><span class="sxs-lookup"><span data-stu-id="c21b2-166">The 'trip_fare' CSV files contain details of the fare paid for each trip, such as payment type, fare amount, surcharge and taxes, tips and tolls, and the total amount paid.</span></span> <span data-ttu-id="c21b2-167">Aqui estão alguns exemplos de registros:</span><span class="sxs-lookup"><span data-stu-id="c21b2-167">Here are a few sample records:</span></span>
   
        medallion, hack_license, vendor_id, pickup_datetime, payment_type, fare_amount, surcharge, mta_tax, tip_amount, tolls_amount, total_amount
        89D227B655E5C82AECF13C3F540D4CF4,BA96DE419E711691B9445D6A6307C170,CMT,2013-01-01 15:11:48,CSH,6.5,0,0.5,0,0,7
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,2013-01-06 00:18:35,CSH,6,0.5,0.5,0,0,7
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,2013-01-05 18:49:41,CSH,5.5,1,0.5,0,0,7
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,2013-01-07 23:54:15,CSH,5,0.5,0.5,0,0,6
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,2013-01-07 23:25:03,CSH,9.5,0.5,0.5,0,0,10.5

<span data-ttu-id="c21b2-168">Pegamos uma amostra de 0,1% desses arquivos CVS trip\_data and trip\_fare e os unimos em um único conjunto de dados que será usado como o conjunto de dados de entrada para este passo a passo.</span><span class="sxs-lookup"><span data-stu-id="c21b2-168">We have taken a 0.1% sample of these files and joined the trip\_data and trip\_fare CVS files into a single dataset to use as the input dataset for this walkthrough.</span></span> <span data-ttu-id="c21b2-169">A chave exclusiva para unir trip\_data e trip\_fare é composta pelos campos: medallion, hack\_license e pickup\_datetime.</span><span class="sxs-lookup"><span data-stu-id="c21b2-169">The unique key to join trip\_data and trip\_fare is composed of the fields: medallion, hack\_licence and pickup\_datetime.</span></span> <span data-ttu-id="c21b2-170">Cada registro do conjunto de dados contém os seguintes atributos que representam uma corrida de táxi em NYC:</span><span class="sxs-lookup"><span data-stu-id="c21b2-170">Each record of the dataset contains the following attributes representing a NYC Taxi trip:</span></span>

| <span data-ttu-id="c21b2-171">Campo</span><span class="sxs-lookup"><span data-stu-id="c21b2-171">Field</span></span> | <span data-ttu-id="c21b2-172">Breve descrição</span><span class="sxs-lookup"><span data-stu-id="c21b2-172">Brief Description</span></span> |
| --- | --- |
| <span data-ttu-id="c21b2-173">medallion</span><span class="sxs-lookup"><span data-stu-id="c21b2-173">medallion</span></span> |<span data-ttu-id="c21b2-174">Licença do táxi em forma anônima (ID exclusiva do táxi)</span><span class="sxs-lookup"><span data-stu-id="c21b2-174">Anonymized taxi medallion (unique taxi id)</span></span> |
| <span data-ttu-id="c21b2-175">hack_license</span><span class="sxs-lookup"><span data-stu-id="c21b2-175">hack_license</span></span> |<span data-ttu-id="c21b2-176">Número de licença do carro em forma anônima</span><span class="sxs-lookup"><span data-stu-id="c21b2-176">Anonymized Hackney Carriage License number</span></span> |
| <span data-ttu-id="c21b2-177">vendor_id</span><span class="sxs-lookup"><span data-stu-id="c21b2-177">vendor_id</span></span> |<span data-ttu-id="c21b2-178">ID do fornecedor do serviço de táxi</span><span class="sxs-lookup"><span data-stu-id="c21b2-178">Taxi vendor id</span></span> |
| <span data-ttu-id="c21b2-179">rate_code</span><span class="sxs-lookup"><span data-stu-id="c21b2-179">rate_code</span></span> |<span data-ttu-id="c21b2-180">Tarifa praticada pelos táxis em NYC</span><span class="sxs-lookup"><span data-stu-id="c21b2-180">NYC taxi rate of fare</span></span> |
| <span data-ttu-id="c21b2-181">store_and_fwd_flag</span><span class="sxs-lookup"><span data-stu-id="c21b2-181">store_and_fwd_flag</span></span> |<span data-ttu-id="c21b2-182">Sinalizador de que os dados foram armazenados no veículo e encaminhados posteriormente</span><span class="sxs-lookup"><span data-stu-id="c21b2-182">Store and forward flag</span></span> |
| <span data-ttu-id="c21b2-183">pickup_datetime</span><span class="sxs-lookup"><span data-stu-id="c21b2-183">pickup_datetime</span></span> |<span data-ttu-id="c21b2-184">Data e hora do início da corrida</span><span class="sxs-lookup"><span data-stu-id="c21b2-184">Pick up date & time</span></span> |
| <span data-ttu-id="c21b2-185">dropoff_datetime</span><span class="sxs-lookup"><span data-stu-id="c21b2-185">dropoff_datetime</span></span> |<span data-ttu-id="c21b2-186">Data e hora do final da corrida</span><span class="sxs-lookup"><span data-stu-id="c21b2-186">Dropoff date & time</span></span> |
| <span data-ttu-id="c21b2-187">pickup_hour</span><span class="sxs-lookup"><span data-stu-id="c21b2-187">pickup_hour</span></span> |<span data-ttu-id="c21b2-188">Hora da corrida</span><span class="sxs-lookup"><span data-stu-id="c21b2-188">Pick up hour</span></span> |
| <span data-ttu-id="c21b2-189">pickup_week</span><span class="sxs-lookup"><span data-stu-id="c21b2-189">pickup_week</span></span> |<span data-ttu-id="c21b2-190">Semana do ano da corrida</span><span class="sxs-lookup"><span data-stu-id="c21b2-190">Pick up week of the year</span></span> |
| <span data-ttu-id="c21b2-191">weekday</span><span class="sxs-lookup"><span data-stu-id="c21b2-191">weekday</span></span> |<span data-ttu-id="c21b2-192">Dia da semana (intervalo de 1 a 7)</span><span class="sxs-lookup"><span data-stu-id="c21b2-192">Weekday (range 1-7)</span></span> |
| <span data-ttu-id="c21b2-193">passenger_count</span><span class="sxs-lookup"><span data-stu-id="c21b2-193">passenger_count</span></span> |<span data-ttu-id="c21b2-194">Número de passageiros em uma corrida de táxi</span><span class="sxs-lookup"><span data-stu-id="c21b2-194">Number of passengers in a taxi trip</span></span> |
| <span data-ttu-id="c21b2-195">trip_time_in_secs</span><span class="sxs-lookup"><span data-stu-id="c21b2-195">trip_time_in_secs</span></span> |<span data-ttu-id="c21b2-196">Tempo da corrida em segundos</span><span class="sxs-lookup"><span data-stu-id="c21b2-196">Trip time in seconds</span></span> |
| <span data-ttu-id="c21b2-197">trip_distance</span><span class="sxs-lookup"><span data-stu-id="c21b2-197">trip_distance</span></span> |<span data-ttu-id="c21b2-198">Distância percorrida na corrida em milhas</span><span class="sxs-lookup"><span data-stu-id="c21b2-198">Trip distance traveled in miles</span></span> |
| <span data-ttu-id="c21b2-199">pickup_longitude</span><span class="sxs-lookup"><span data-stu-id="c21b2-199">pickup_longitude</span></span> |<span data-ttu-id="c21b2-200">Longitude da corrida</span><span class="sxs-lookup"><span data-stu-id="c21b2-200">Pick up longitude</span></span> |
| <span data-ttu-id="c21b2-201">pickup_latitude</span><span class="sxs-lookup"><span data-stu-id="c21b2-201">pickup_latitude</span></span> |<span data-ttu-id="c21b2-202">Latitude da corrida</span><span class="sxs-lookup"><span data-stu-id="c21b2-202">Pick up latitude</span></span> |
| <span data-ttu-id="c21b2-203">dropoff_longitude</span><span class="sxs-lookup"><span data-stu-id="c21b2-203">dropoff_longitude</span></span> |<span data-ttu-id="c21b2-204">Longitude do final da corrida</span><span class="sxs-lookup"><span data-stu-id="c21b2-204">Dropoff longitude</span></span> |
| <span data-ttu-id="c21b2-205">dropoff_latitude</span><span class="sxs-lookup"><span data-stu-id="c21b2-205">dropoff_latitude</span></span> |<span data-ttu-id="c21b2-206">Latitude do final da corrida</span><span class="sxs-lookup"><span data-stu-id="c21b2-206">Dropoff latitude</span></span> |
| <span data-ttu-id="c21b2-207">direct_distance</span><span class="sxs-lookup"><span data-stu-id="c21b2-207">direct_distance</span></span> |<span data-ttu-id="c21b2-208">Distância direta entre os locais inicial e final da corrida</span><span class="sxs-lookup"><span data-stu-id="c21b2-208">Direct distance between pick up and dropoff locations</span></span> |
| <span data-ttu-id="c21b2-209">payment_type</span><span class="sxs-lookup"><span data-stu-id="c21b2-209">payment_type</span></span> |<span data-ttu-id="c21b2-210">Tipo de pagamento (dinheiro, cartão de crédito etc.)</span><span class="sxs-lookup"><span data-stu-id="c21b2-210">Payment type (cas, credit-card etc.)</span></span> |
| <span data-ttu-id="c21b2-211">fare_amount</span><span class="sxs-lookup"><span data-stu-id="c21b2-211">fare_amount</span></span> |<span data-ttu-id="c21b2-212">Valor da tarifa</span><span class="sxs-lookup"><span data-stu-id="c21b2-212">Fare amount in</span></span> |
| <span data-ttu-id="c21b2-213">surcharge</span><span class="sxs-lookup"><span data-stu-id="c21b2-213">surcharge</span></span> |<span data-ttu-id="c21b2-214">Taxa adicional</span><span class="sxs-lookup"><span data-stu-id="c21b2-214">Surcharge</span></span> |
| <span data-ttu-id="c21b2-215">mta_tax</span><span class="sxs-lookup"><span data-stu-id="c21b2-215">mta_tax</span></span> |<span data-ttu-id="c21b2-216">Imposto da MTA</span><span class="sxs-lookup"><span data-stu-id="c21b2-216">Mta tax</span></span> |
| <span data-ttu-id="c21b2-217">tip_amount</span><span class="sxs-lookup"><span data-stu-id="c21b2-217">tip_amount</span></span> |<span data-ttu-id="c21b2-218">Valor da gorjeta</span><span class="sxs-lookup"><span data-stu-id="c21b2-218">Tip amount</span></span> |
| <span data-ttu-id="c21b2-219">tolls_amount</span><span class="sxs-lookup"><span data-stu-id="c21b2-219">tolls_amount</span></span> |<span data-ttu-id="c21b2-220">Valor dos pedágios</span><span class="sxs-lookup"><span data-stu-id="c21b2-220">Tolls amount</span></span> |
| <span data-ttu-id="c21b2-221">total_amount</span><span class="sxs-lookup"><span data-stu-id="c21b2-221">total_amount</span></span> |<span data-ttu-id="c21b2-222">Valor total</span><span class="sxs-lookup"><span data-stu-id="c21b2-222">Total amount</span></span> |
| <span data-ttu-id="c21b2-223">tipped</span><span class="sxs-lookup"><span data-stu-id="c21b2-223">tipped</span></span> |<span data-ttu-id="c21b2-224">Gorjeta (0/1 para não ou sim)</span><span class="sxs-lookup"><span data-stu-id="c21b2-224">Tipped (0/1 for no or yes)</span></span> |
| <span data-ttu-id="c21b2-225">tip_class</span><span class="sxs-lookup"><span data-stu-id="c21b2-225">tip_class</span></span> |<span data-ttu-id="c21b2-226">Classe da gorjeta (0: US$ 0, 1: US$ 0 a 5, 2: US$ 6 a 10, 3: US$ 11 a 20, 4: mais de US$ 20)</span><span class="sxs-lookup"><span data-stu-id="c21b2-226">Tip class (0: $0, 1: $0-5, 2: $6-10, 3: $11-20, 4: > $20)</span></span> |

## <a name="execute-code-from-a-jupyter-notebook-on-the-spark-cluster"></a><span data-ttu-id="c21b2-227">Executar código de um bloco de anotações Jupyter no cluster Spark</span><span class="sxs-lookup"><span data-stu-id="c21b2-227">Execute code from a Jupyter notebook on the Spark cluster</span></span>
<span data-ttu-id="c21b2-228">É possível iniciar o Notebook do Jupyter no portal do Azure.</span><span class="sxs-lookup"><span data-stu-id="c21b2-228">You can launch the Jupyter Notebook from the Azure portal.</span></span> <span data-ttu-id="c21b2-229">Encontre o cluster Spark no painel e clique nele para entrar na página de gerenciamento de seu cluster.</span><span class="sxs-lookup"><span data-stu-id="c21b2-229">Find your Spark cluster on your dashboard and click it to enter management page for your cluster.</span></span> <span data-ttu-id="c21b2-230">Para abrir o notebook associado ao cluster Spark, clique nos **Painéis do Cluster** -> **Notebook Jupyter**.</span><span class="sxs-lookup"><span data-stu-id="c21b2-230">To open the notebook associated with the Spark cluster, click **Cluster Dashboards** -> **Jupyter Notebook** .</span></span>

![Painéis de cluster](./media/machine-learning-data-science-spark-overview/spark-jupyter-on-portal.png)

<span data-ttu-id="c21b2-232">Você também pode navegar até ***https://CLUSTERNAME.azurehdinsight.net/jupyter*** para acessar os Notebooks Jupyter.</span><span class="sxs-lookup"><span data-stu-id="c21b2-232">You can also browse to ***https://CLUSTERNAME.azurehdinsight.net/jupyter*** to access the Jupyter Notebooks.</span></span> <span data-ttu-id="c21b2-233">Substitua a parte CLUSTERNAME desta URL pelo nome do seu próprio cluster.</span><span class="sxs-lookup"><span data-stu-id="c21b2-233">Replace the CLUSTERNAME part of this URL with the name of your own cluster.</span></span> <span data-ttu-id="c21b2-234">Você precisa da senha de sua conta de administrador para acessar os notebooks.</span><span class="sxs-lookup"><span data-stu-id="c21b2-234">You need the password for your admin account to access the notebooks.</span></span>

![Procurar Notebooks Jupyter](./media/machine-learning-data-science-spark-overview/spark-jupyter-notebook.png)

<span data-ttu-id="c21b2-236">Selecione PySpark para ver um diretório que contém alguns exemplos de notebooks predefinidos que usam a API do PySpark. Os notebooks que contêm os exemplos de código para esse conjunto de tópicos do Spark estão disponíveis no [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark)</span><span class="sxs-lookup"><span data-stu-id="c21b2-236">Select PySpark to see a directory that contains a few examples of pre-packaged notebooks that use the PySpark API.The notebooks that contain the code samples for this suite of Spark topic are available at [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark)</span></span>

<span data-ttu-id="c21b2-237">Você pode carregar os blocos de anotações diretamente do [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark) para o servidor do bloco de anotações Jupyter no seu cluster Spark.</span><span class="sxs-lookup"><span data-stu-id="c21b2-237">You can upload the notebooks directly from [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark) to the Jupyter notebook server on your Spark cluster.</span></span> <span data-ttu-id="c21b2-238">Na home page do seu Jupyter, clique no botão **Carregar** na parte direita da tela.</span><span class="sxs-lookup"><span data-stu-id="c21b2-238">On the home page of your Jupyter, click the **Upload** button on the right part of the screen.</span></span> <span data-ttu-id="c21b2-239">Ele abre o explorador de arquivos.</span><span class="sxs-lookup"><span data-stu-id="c21b2-239">It opens a file explorer.</span></span> <span data-ttu-id="c21b2-240">Aqui, você pode colar a URL do GitHub (conteúdo bruto) do Notebook e clicar em **Abrir**.</span><span class="sxs-lookup"><span data-stu-id="c21b2-240">Here you can paste the GitHub (raw content) URL of the Notebook and click **Open**.</span></span> 

<span data-ttu-id="c21b2-241">Você vê o nome do arquivo em sua lista de arquivos do Jupyter, com um botão **Carregar** novamente.</span><span class="sxs-lookup"><span data-stu-id="c21b2-241">You see the file name on your Jupyter file list with an **Upload** button again.</span></span> <span data-ttu-id="c21b2-242">Clique nesse botão **Carregar** .</span><span class="sxs-lookup"><span data-stu-id="c21b2-242">Click this **Upload** button.</span></span> <span data-ttu-id="c21b2-243">Agora, você importou o notebook.</span><span class="sxs-lookup"><span data-stu-id="c21b2-243">Now you have imported the notebook.</span></span> <span data-ttu-id="c21b2-244">Repita estas etapas deste passo a passo para carregar outros notebooks.</span><span class="sxs-lookup"><span data-stu-id="c21b2-244">Repeat these steps to upload the other notebooks from this walkthrough.</span></span>

> [!TIP]
> <span data-ttu-id="c21b2-245">Clique com o botão direito nos links no seu navegador e selecione **Copiar Link** para obter a URL do conteúdo bruto github.</span><span class="sxs-lookup"><span data-stu-id="c21b2-245">You can right-click the links on your browser and select **Copy Link** to get the github raw content URL.</span></span> <span data-ttu-id="c21b2-246">Você pode colar essa URL na caixa de diálogo do explorador de arquivos de carregamento Jupyter.</span><span class="sxs-lookup"><span data-stu-id="c21b2-246">You can paste this URL into the Jupyter Upload file explorer dialog box.</span></span>
> 
> 

<span data-ttu-id="c21b2-247">Agora você pode:</span><span class="sxs-lookup"><span data-stu-id="c21b2-247">Now you can:</span></span>

* <span data-ttu-id="c21b2-248">Consulte o código clicando no notebook.</span><span class="sxs-lookup"><span data-stu-id="c21b2-248">See the code by clicking the notebook.</span></span>
* <span data-ttu-id="c21b2-249">Executar cada célula pressionando **SHIFT-ENTER**.</span><span class="sxs-lookup"><span data-stu-id="c21b2-249">Execute each cell by pressing **SHIFT-ENTER**.</span></span>
* <span data-ttu-id="c21b2-250">Executar o notebook inteiro clicando em **Célula** -> **Executar**.</span><span class="sxs-lookup"><span data-stu-id="c21b2-250">Run the entire notebook by clicking on **Cell** -> **Run**.</span></span>
* <span data-ttu-id="c21b2-251">Usar a visualização automática de consultas.</span><span class="sxs-lookup"><span data-stu-id="c21b2-251">Use the automatic visualization of queries.</span></span>

> [!TIP]
> <span data-ttu-id="c21b2-252">O kernel PySpark visualiza automaticamente a saída das consultas SQL (HiveQL).</span><span class="sxs-lookup"><span data-stu-id="c21b2-252">The PySpark kernel automatically visualizes the output of SQL (HiveQL) queries.</span></span> <span data-ttu-id="c21b2-253">Você terá a opção de selecionar entre vários tipos diferentes de visualização (Tabela, Pizza, Linha, Área ou Barra) usando os botões de menu **Tipo** no notebook:</span><span class="sxs-lookup"><span data-stu-id="c21b2-253">You are given the option to select among several different types of visualizations (Table, Pie, Line, Area, or Bar) by using the **Type** menu buttons in the notebook:</span></span>
> 
> 

![Curva ROC de regressão logística de abordagem genérica](./media/machine-learning-data-science-spark-overview/pyspark-jupyter-autovisualization.png)

## <a name="whats-next"></a><span data-ttu-id="c21b2-255">O que vem a seguir?</span><span class="sxs-lookup"><span data-stu-id="c21b2-255">What's next?</span></span>
<span data-ttu-id="c21b2-256">Agora que configurou um cluster HDInsight Spark e carregou os notebooks Jupyter, você está pronto para usar os tópicos que correspondem aos três notebooks PySpark.</span><span class="sxs-lookup"><span data-stu-id="c21b2-256">Now that you are set up with an HDInsight Spark cluster and have uploaded the Jupyter notebooks, you are ready to work through the topics that correspond to the three PySpark notebooks.</span></span> <span data-ttu-id="c21b2-257">Eles mostram como explorar os dados e como criar e consumir modelos.</span><span class="sxs-lookup"><span data-stu-id="c21b2-257">They show how to explore your data and then how to create and consume models.</span></span> <span data-ttu-id="c21b2-258">Onotebook de exploração e modelagem de dados avançadas mostra como incluir validação cruzada, limpeza de hiperparâmetro e avaliação de modelo.</span><span class="sxs-lookup"><span data-stu-id="c21b2-258">The advanced data exploration and modeling notebook shows how to include cross-validation, hyper-parameter sweeping, and model evaluation.</span></span> 

<span data-ttu-id="c21b2-259">**Exploração de Dados e modelagem com o Spark:** explore o conjunto de dados, crie, pontue e avalie os modelos de aprendizado de máquina usando o tópico [Create binary classification and regression models for data with the Spark MLlib toolkit](machine-learning-data-science-spark-data-exploration-modeling.md) (Criar modelos de regressão e classificação binária para dados com o kit de ferramentas MLlib do Spark).</span><span class="sxs-lookup"><span data-stu-id="c21b2-259">**Data Exploration and modeling with Spark:** Explore the dataset and create, score, and evaluate the machine learning models by working through the [Create binary classification and regression models for data with the Spark MLlib toolkit](machine-learning-data-science-spark-data-exploration-modeling.md) topic.</span></span>

<span data-ttu-id="c21b2-260">**Consumo de modelo:** para saber como pontuar os modelos de classificação e regressão criados neste tópico, confira [Pontuar modelos de aprendizado de máquina criados no Spark](machine-learning-data-science-spark-model-consumption.md).</span><span class="sxs-lookup"><span data-stu-id="c21b2-260">**Model consumption:** To learn how to score the classification and regression models created in this topic, see [Score and evaluate Spark-built machine learning models](machine-learning-data-science-spark-model-consumption.md).</span></span>

<span data-ttu-id="c21b2-261">**Validação cruzada e limpeza de hiperparâmetro**: confira [Modelagem e exploração de dados avançados com o Spark](machine-learning-data-science-spark-advanced-data-exploration-modeling.md) para saber como os modelos podem ser treinados usando a validação cruzada e a limpeza de hiperparâmetro</span><span class="sxs-lookup"><span data-stu-id="c21b2-261">**Cross-validation and hyperparameter sweeping**: See [Advanced data exploration and modeling with Spark](machine-learning-data-science-spark-advanced-data-exploration-modeling.md) on how models can be trained using cross-validation and hyper-parameter sweeping</span></span>

