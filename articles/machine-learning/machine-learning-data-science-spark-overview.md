---
title: "aaaOverview da ciência de dados usando o Spark no Azure HDInsight | Microsoft Docs"
description: "Kit de ferramentas do Hello MLlib Spark traz recursos toohello distribuída HDInsight ambiente de modelagem de aprendizado de máquina considerável."
services: machine-learning
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: a4e1de99-a554-4240-9647-2c6d669593c8
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/15/2017
ms.author: deguhath;bradsev;gokuma
ms.openlocfilehash: 515705684a46917c2741bf063d439b1cda016abb
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: pt-BR
ms.lasthandoff: 10/06/2017
---
# <a name="overview-of-data-science-using-spark-on-azure-hdinsight"></a><span data-ttu-id="9d464-103">Visão geral da ciência de dados usando Spark no Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="9d464-103">Overview of data science using Spark on Azure HDInsight</span></span>
[!INCLUDE [machine-learning-spark-modeling](../../includes/machine-learning-spark-modeling.md)]

<span data-ttu-id="9d464-104">Este conjunto de tópicos mostra como as tarefas de ciência de dados comum do HDInsight Spark toocomplete de toouse como ingestão de dados, engenharia de recurso, modelagem e avaliação do modelo.</span><span class="sxs-lookup"><span data-stu-id="9d464-104">This suite of topics shows how toouse HDInsight Spark toocomplete common data science tasks such as data ingestion, feature engineering, modeling, and model evaluation.</span></span> <span data-ttu-id="9d464-105">dados de saudação usados são um exemplo de hello 2013 NYC táxi viagem e passagens conjunto de dados.</span><span class="sxs-lookup"><span data-stu-id="9d464-105">hello data used is a sample of hello 2013 NYC taxi trip and fare dataset.</span></span> <span data-ttu-id="9d464-106">modelos internos de saudação incluem gradientes árvores aumentadas, florestas aleatórias e regressão logística e linear.</span><span class="sxs-lookup"><span data-stu-id="9d464-106">hello models built include logistic and linear regression, random forests, and gradient boosted trees.</span></span> <span data-ttu-id="9d464-107">Olá tópicos também mostram como toostore esses modelos no Azure blob storage (WASB) e como tooscore e avaliar o desempenho previsível.</span><span class="sxs-lookup"><span data-stu-id="9d464-107">hello topics also show how toostore these models in Azure blob storage (WASB) and how tooscore and evaluate their predictive performance.</span></span> <span data-ttu-id="9d464-108">Os tópicos mais avançados abordam como os modelos podem ser treinados usando a validação cruzada e a limpeza de hiperparâmetro.</span><span class="sxs-lookup"><span data-stu-id="9d464-108">More advanced topics cover how models can be trained using cross-validation and hyper-parameter sweeping.</span></span> <span data-ttu-id="9d464-109">Este tópico de visão geral também faz referência a tópicos de saudação que descrevem como tooset backup Olá cluster Spark que você precisa toocomplete etapas Olá Olá orientações fornecidas.</span><span class="sxs-lookup"><span data-stu-id="9d464-109">This overview topic also references hello topics that describe how tooset up hello Spark cluster that you need toocomplete hello steps in hello walkthroughs provided.</span></span> 

## <a name="spark-and-mllib"></a><span data-ttu-id="9d464-110">Spark e MLlib</span><span class="sxs-lookup"><span data-stu-id="9d464-110">Spark and MLlib</span></span>
<span data-ttu-id="9d464-111">[Spark](http://spark.apache.org/) é uma estrutura de processamento paralelo do código-fonte aberto que dá suporte à memória no desempenho do processamento tooboost Olá de aplicativos analíticos grandes de dados.</span><span class="sxs-lookup"><span data-stu-id="9d464-111">[Spark](http://spark.apache.org/) is an open-source parallel processing framework that supports in-memory processing tooboost hello performance of big-data analytic applications.</span></span> <span data-ttu-id="9d464-112">mecanismo de processamento do Spark Olá é construído para velocidade, facilidade de uso e análise sofisticada.</span><span class="sxs-lookup"><span data-stu-id="9d464-112">hello Spark processing engine is built for speed, ease of use, and sophisticated analytics.</span></span> <span data-ttu-id="9d464-113">Os recursos de computação distribuída na memória do Spark tornam uma boa escolha para algoritmos de iterativo Olá usados em cálculos de gráfico e de aprendizado de máquina.</span><span class="sxs-lookup"><span data-stu-id="9d464-113">Spark's in-memory distributed computation capabilities make it a good choice for hello iterative algorithms used in machine learning and graph computations.</span></span> <span data-ttu-id="9d464-114">[MLlib](http://spark.apache.org/mllib/) é biblioteca de aprendizado de máquina escalonável do Spark que traz Olá algorítmico ambiente distribuído do toothis de recursos de modelagem.</span><span class="sxs-lookup"><span data-stu-id="9d464-114">[MLlib](http://spark.apache.org/mllib/) is Spark's scalable machine learning library that brings hello algorithmic modeling capabilities toothis distributed environment.</span></span> 

## <a name="hdinsight-spark"></a><span data-ttu-id="9d464-115">HDInsight Spark</span><span class="sxs-lookup"><span data-stu-id="9d464-115">HDInsight Spark</span></span>
<span data-ttu-id="9d464-116">[HDInsight Spark](../hdinsight/hdinsight-apache-spark-overview.md) hello Azure hospedado oferta do código-fonte aberto Spark.</span><span class="sxs-lookup"><span data-stu-id="9d464-116">[HDInsight Spark](../hdinsight/hdinsight-apache-spark-overview.md) is hello Azure hosted offering of open-source Spark.</span></span> <span data-ttu-id="9d464-117">Ela também inclui suporte para **blocos de anotações do Jupyter PySpark** no cluster do Spark Olá que pode executar consultas interativas do Spark SQL para transformar, filtrar e visualização de dados armazenados em Blobs do Azure (WASB).</span><span class="sxs-lookup"><span data-stu-id="9d464-117">It also includes support for **Jupyter PySpark notebooks** on hello Spark cluster that can run Spark SQL interactive queries for transforming, filtering, and visualizing data stored in Azure Blobs (WASB).</span></span> <span data-ttu-id="9d464-118">PySpark é hello API Python para Spark.</span><span class="sxs-lookup"><span data-stu-id="9d464-118">PySpark is hello Python API for Spark.</span></span> <span data-ttu-id="9d464-119">trechos de código de saudação que fornecem soluções hello e mostram Olá gráficos relevantes toovisualize Olá dados aqui executados em blocos de anotações do Jupyter instalados nos clusters do Spark hello.</span><span class="sxs-lookup"><span data-stu-id="9d464-119">hello code snippets that provide hello solutions and show hello relevant plots toovisualize hello data here run in Jupyter notebooks installed on hello Spark clusters.</span></span> <span data-ttu-id="9d464-120">etapas de modelagem Olá nestes tópicos contêm código que mostra como tootrain, avaliar, salvar e consumir cada tipo de modelo.</span><span class="sxs-lookup"><span data-stu-id="9d464-120">hello modeling steps in these topics contain code that shows how tootrain, evaluate, save, and consume each type of model.</span></span> 

## <a name="setup-spark-clusters-and-jupyter-notebooks"></a><span data-ttu-id="9d464-121">Instalação: Clusters do Spark e Notebooks Jupyter</span><span class="sxs-lookup"><span data-stu-id="9d464-121">Setup: Spark clusters and Jupyter notebooks</span></span>
<span data-ttu-id="9d464-122">As etapas de configuração e o código são fornecidos neste passo a passo para usar um HDInsight Spark 1.6.</span><span class="sxs-lookup"><span data-stu-id="9d464-122">Setup steps and code are provided in this walkthrough for using an HDInsight Spark 1.6.</span></span> <span data-ttu-id="9d464-123">Porém, notebooks Jupyter são fornecidos tanto para o HDInsight Spark 1.6 quanto para os clusters Spark 2.0.</span><span class="sxs-lookup"><span data-stu-id="9d464-123">But Jupyter notebooks are provided for both HDInsight Spark 1.6 and Spark 2.0 clusters.</span></span> <span data-ttu-id="9d464-124">Uma descrição da saudação toothem de anotações e links são fornecidos no hello [Readme.md](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Readme.md) para o repositório do GitHub Olá que os contém.</span><span class="sxs-lookup"><span data-stu-id="9d464-124">A description of hello notebooks and links toothem are provided in hello [Readme.md](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Readme.md) for hello GitHub repository containing them.</span></span> <span data-ttu-id="9d464-125">Além disso, Olá código aqui e em blocos de anotações Olá vinculado é genérico e deve funcionar em qualquer cluster do Spark.</span><span class="sxs-lookup"><span data-stu-id="9d464-125">Moreover, hello code here and in hello linked notebooks is generic and should work on any Spark cluster.</span></span> <span data-ttu-id="9d464-126">Se você não estiver usando o HDInsight Spark, as etapas de configuração e gerenciamento de cluster Olá podem ser ligeiramente diferentes da que é mostrado aqui.</span><span class="sxs-lookup"><span data-stu-id="9d464-126">If you are not using HDInsight Spark, hello cluster setup and management steps may be slightly different from what is shown here.</span></span> <span data-ttu-id="9d464-127">Para sua conveniência, aqui estão os links de saudação blocos de anotações do Jupyter toohello para Spark 1.6 (toobe executar no kernel do pySpark de saudação do servidor de Jupyter Notebook de saudação) e o Spark 2.0 (toobe executar no kernel do pySpark3 de saudação do servidor de Jupyter Notebook de saudação):</span><span class="sxs-lookup"><span data-stu-id="9d464-127">For convenience, here are hello links toohello Jupyter notebooks for Spark 1.6 (toobe run in hello pySpark kernel of hello Jupyter Notebook server) and  Spark 2.0 (toobe run in hello pySpark3 kernel of hello Jupyter Notebook server):</span></span>

### <a name="spark-16-notebooks"></a><span data-ttu-id="9d464-128">Blocos de notas Spark 1.6</span><span class="sxs-lookup"><span data-stu-id="9d464-128">Spark 1.6 notebooks</span></span>
<span data-ttu-id="9d464-129">Esses blocos são toobe executado no kernel de pySpark de saudação do servidor de notebook Jupyter.</span><span class="sxs-lookup"><span data-stu-id="9d464-129">These notebooks are toobe run in hello pySpark kernel of Jupyter notebook server.</span></span>

- <span data-ttu-id="9d464-130">[pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb): fornece informações sobre como tooperform de exploração de dados, modelagem e pontuação com vários algoritmos diferentes.</span><span class="sxs-lookup"><span data-stu-id="9d464-130">[pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb): Provides information on how tooperform data exploration, modeling, and scoring with several different algorithms.</span></span>
- <span data-ttu-id="9d464-131">[pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): inclui tópicos de notebook nº 1 e o desenvolvimento de modelos usando ajude e validação cruzada de hiperparâmetro.</span><span class="sxs-lookup"><span data-stu-id="9d464-131">[pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): Includes topics in notebook #1, and model development using hyperparameter tuning and cross-validation.</span></span>
- <span data-ttu-id="9d464-132">[pySpark-machine-learning-data-science-spark-model-consumption.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb): mostra como toooperationalize um modelo de salvo usando Python no HDInsight clusters.</span><span class="sxs-lookup"><span data-stu-id="9d464-132">[pySpark-machine-learning-data-science-spark-model-consumption.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb): Shows how toooperationalize a saved model using Python on HDInsight clusters.</span></span>

### <a name="spark-20-notebooks"></a><span data-ttu-id="9d464-133">Blocos de notas Spark 2.0</span><span class="sxs-lookup"><span data-stu-id="9d464-133">Spark 2.0 notebooks</span></span>
<span data-ttu-id="9d464-134">Esses blocos são toobe executado no kernel de pySpark3 de saudação do servidor de notebook Jupyter.</span><span class="sxs-lookup"><span data-stu-id="9d464-134">These notebooks are toobe run in hello pySpark3 kernel of Jupyter notebook server.</span></span>

- <span data-ttu-id="9d464-135">[Spark2.0-pySpark3-Machine-Learning-data-Science-Spark-Advanced-data-exploration-Modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): este arquivo fornece informações sobre como tooperform a exploração de dados, modelagem e pontuação no Spark 2.0 clusters usando Olá trip NYC táxi e passagens-conjunto de dados descrito [aqui](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span><span class="sxs-lookup"><span data-stu-id="9d464-135">[Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): This file provides information on how tooperform data exploration, modeling, and scoring in Spark 2.0 clusters using hello NYC Taxi trip and fare data-set described [here](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span></span> <span data-ttu-id="9d464-136">Este bloco de anotações pode ser um bom ponto de partida para explorar rapidamente código Olá que fornecemos para Spark 2.0.</span><span class="sxs-lookup"><span data-stu-id="9d464-136">This notebook may be a good starting point for quickly exploring hello code we have provided for Spark 2.0.</span></span> <span data-ttu-id="9d464-137">Para um bloco de anotações mais detalhado analisa Olá dados NYC táxi, consulte o próximo bloco de anotações de saudação nesta lista.</span><span class="sxs-lookup"><span data-stu-id="9d464-137">For a more detailed notebook analyzes hello NYC Taxi data, see hello next notebook in this list.</span></span> <span data-ttu-id="9d464-138">Consulte as notas de saudação seguinte lista que comparam esses blocos de anotações.</span><span class="sxs-lookup"><span data-stu-id="9d464-138">See hello notes following this list that compare these notebooks.</span></span> 
- <span data-ttu-id="9d464-139">[Spark2.0 pySpark3_NYC_Taxi_Tip_Regression.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_NYC_Taxi_Tip_Regression.ipynb): esse arquivo mostra como tooperform dados disputa (operações Spark SQL e dataframe), a exploração, modelagem e pontuação usando Olá trip NYC táxi e passagens conjunto de dados descrito [ aqui](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span><span class="sxs-lookup"><span data-stu-id="9d464-139">[Spark2.0-pySpark3_NYC_Taxi_Tip_Regression.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_NYC_Taxi_Tip_Regression.ipynb): This file shows how tooperform data wrangling (Spark SQL and dataframe operations), exploration, modeling and scoring using hello NYC Taxi trip and fare data-set described [here](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span></span>
- <span data-ttu-id="9d464-140">[Spark2.0 pySpark3_Airline_Departure_Delay_Classification.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_Airline_Departure_Delay_Classification.ipynb): esse arquivo mostra como tooperform dados disputa (operações Spark SQL e dataframe), a exploração, modelagem e pontuação usando Olá conhecida saída em tempo de aérea conjunto de dados de 2011 e 2012.</span><span class="sxs-lookup"><span data-stu-id="9d464-140">[Spark2.0-pySpark3_Airline_Departure_Delay_Classification.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_Airline_Departure_Delay_Classification.ipynb): This file shows how tooperform data wrangling (Spark SQL and dataframe operations), exploration, modeling and scoring using hello well-known Airline On-time departure dataset from 2011 and 2012.</span></span> <span data-ttu-id="9d464-141">Podemos integrada Olá aérea dataset com hello a toomodeling de anteriores de dados (por exemplo, windspeed, temperatura, altitude etc.) do aeroporto clima, para que esses recursos de tempo podem ser incluídos no modelo de saudação.</span><span class="sxs-lookup"><span data-stu-id="9d464-141">We integrated hello airline dataset with hello airport weather data (e.g. windspeed, temperature, altitude etc.) prior toomodeling, so these weather features can be included in hello model.</span></span>

<!-- -->

> [!NOTE]
> <span data-ttu-id="9d464-142">Olá aérea dataset foi adicionado toohello 2.0 Spark notebooks toobetter ilustram o uso de saudação de algoritmos de classificação.</span><span class="sxs-lookup"><span data-stu-id="9d464-142">hello airline dataset was added toohello Spark 2.0 notebooks toobetter illustrate hello use of classification algorithms.</span></span> <span data-ttu-id="9d464-143">Consulte Olá links para obter informações sobre o conjunto de dados de saída em tempo de passagens áreas e conjunto de dados de tempo a seguir:</span><span class="sxs-lookup"><span data-stu-id="9d464-143">See hello following links for information about airline on-time departure dataset and weather dataset:</span></span>

>- <span data-ttu-id="9d464-144">Dados de partidas no horário em aeroportos: [http://www.transtats.bts.gov/ONTIME/](http://www.transtats.bts.gov/ONTIME/)</span><span class="sxs-lookup"><span data-stu-id="9d464-144">Airline on-time departure data: [http://www.transtats.bts.gov/ONTIME/](http://www.transtats.bts.gov/ONTIME/)</span></span>

>- <span data-ttu-id="9d464-145">Dados de clima aeroporto: [https://www.ncdc.noaa.gov/](https://www.ncdc.noaa.gov/)</span><span class="sxs-lookup"><span data-stu-id="9d464-145">Airport weather data: [https://www.ncdc.noaa.gov/](https://www.ncdc.noaa.gov/)</span></span> 
> 
> 

<!-- -->

<!-- -->

> [!NOTE]
<span data-ttu-id="9d464-146">Olá Spark 2.0 blocos de anotações Olá táxi NYC e conjuntos de dados de atraso de voo de aérea podem levar 10 minutos ou mais toorun (dependendo do tamanho de saudação do cluster HDI).</span><span class="sxs-lookup"><span data-stu-id="9d464-146">hello Spark 2.0 notebooks on hello NYC taxi and airline flight delay data-sets can take 10 mins or more toorun (depending on hello size of your HDI cluster).</span></span> <span data-ttu-id="9d464-147">primeiro notebook no hello acima da lista Hello mostra muitos aspectos de exploração de dados hello, visualização e ML do modelo de treinamento em um bloco de anotações que utiliza menos toorun de tempo com convertidos NYC conjunto de dados, no qual Olá táxi e passagens arquivos tem sido previamente Unidos: [ Spark2.0-pySpark3-Machine-Learning-data-Science-Spark-Advanced-data-exploration-Modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb) este bloco de anotações leva uma quantidade menor tempo toofinish (2-3 minutos) e pode ser um bom ponto de partida para explorar rapidamente código Olá temos fornecido para Spark 2.0.</span><span class="sxs-lookup"><span data-stu-id="9d464-147">hello first notebook in hello above list shows many aspects of hello data exploration, visualization and ML model training in a notebook that takes less time toorun with down-sampled NYC data set, in which hello taxi and fare files have been pre-joined: [Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb) This notebook takes a much shorter time toofinish (2-3 mins) and may be a good starting point for quickly exploring hello code we have provided for Spark 2.0.</span></span> 

<!-- -->

<span data-ttu-id="9d464-148">Para obter orientação sobre operacionalização de saudação de um modelo Spark 2.0 e o consumo de modelo para pontuação, consulte Olá [documento 1.6 Spark no consumo](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb) para obter um exemplo de etapas de saudação necessárias de estrutura de tópicos.</span><span class="sxs-lookup"><span data-stu-id="9d464-148">For guidance on hello operationalization of a Spark 2.0 model and model consumption for scoring, see hello [Spark 1.6 document on consumption](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb) for an example outlining hello steps required.</span></span> <span data-ttu-id="9d464-149">toouse isso no Spark 2.0, substitua o arquivo de código Python Olá com [esse arquivo](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/Python/Spark2.0_ConsumeRFCV_NYCReg.py).</span><span class="sxs-lookup"><span data-stu-id="9d464-149">toouse this on Spark 2.0, replace hello Python code file with [this file](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/Python/Spark2.0_ConsumeRFCV_NYCReg.py).</span></span>

### <a name="prerequisites"></a><span data-ttu-id="9d464-150">Pré-requisitos</span><span class="sxs-lookup"><span data-stu-id="9d464-150">Prerequisites</span></span>
<span data-ttu-id="9d464-151">Olá procedimentos a seguir está relacionada tooSpark 1.6.</span><span class="sxs-lookup"><span data-stu-id="9d464-151">hello following procedures are related tooSpark 1.6.</span></span> <span data-ttu-id="9d464-152">Para a versão de hello Spark 2.0, use Olá notebooks descrito e vinculados toopreviously.</span><span class="sxs-lookup"><span data-stu-id="9d464-152">For  hello Spark 2.0 version, use hello notebooks described and linked toopreviously.</span></span> 

<span data-ttu-id="9d464-153">1.Você precisa ter uma assinatura do Azure.</span><span class="sxs-lookup"><span data-stu-id="9d464-153">1.You must have an Azure subscription.</span></span> <span data-ttu-id="9d464-154">Se ainda não tiver uma, veja [Obter avaliação gratuita do Azure](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span><span class="sxs-lookup"><span data-stu-id="9d464-154">If you do not already have one, see [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span></span>

<span data-ttu-id="9d464-155">2. você precisa de um toocomplete de cluster do Spark 1.6 este passo a passo.</span><span class="sxs-lookup"><span data-stu-id="9d464-155">2.You need a Spark 1.6 cluster toocomplete this walkthrough.</span></span> <span data-ttu-id="9d464-156">toocreate um, consulte as instruções de saudação fornecidas no [Introdução: criar o Apache Spark no Azure HDInsight](../hdinsight/hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="9d464-156">toocreate one, see hello instructions provided in [Get started: create Apache Spark on Azure HDInsight](../hdinsight/hdinsight-apache-spark-jupyter-spark-sql.md).</span></span> <span data-ttu-id="9d464-157">Olá cluster tipo e versão especificado a partir do hello **Selecionar tipo de Cluster** menu.</span><span class="sxs-lookup"><span data-stu-id="9d464-157">hello cluster type and version is specified from hello **Select Cluster Type** menu.</span></span> 

![Configurar cluster](./media/machine-learning-data-science-spark-overview/spark-cluster-on-portal.png)

<!-- -->

> [!NOTE]
> <span data-ttu-id="9d464-159">Para um tópico que mostra como as tarefas de toocomplete de toouse Scala em vez de Python para um processo de ciência de dados de ponta a ponta, consulte Olá [ciência de dados usando Scala com Spark no Azure](machine-learning-data-science-process-scala-walkthrough.md).</span><span class="sxs-lookup"><span data-stu-id="9d464-159">For a topic that shows how toouse Scala rather than Python toocomplete tasks for an end-to-end data science process, see hello [Data Science using Scala with Spark on Azure](machine-learning-data-science-process-scala-walkthrough.md).</span></span>
> 
> 

<!-- -->

> [!INCLUDE [delete-cluster-warning](../../includes/hdinsight-delete-cluster-warning.md)]
> 
> 

## <a name="hello-nyc-2013-taxi-data"></a><span data-ttu-id="9d464-160">Olá dados NYC 2013 táxi</span><span class="sxs-lookup"><span data-stu-id="9d464-160">hello NYC 2013 Taxi data</span></span>
<span data-ttu-id="9d464-161">Olá dados NYC táxi viagem é cerca de 20 GB de arquivos compactados valores separados por vírgulas (CSV) (~ 48 GB descompactado), que inclui mais de milhões de 173 hello e viagens individuais é pago para cada viagem.</span><span class="sxs-lookup"><span data-stu-id="9d464-161">hello NYC Taxi Trip data is about 20 GB of compressed comma-separated values (CSV) files (~48 GB uncompressed), comprising more than 173 million individual trips and hello fares paid for each trip.</span></span> <span data-ttu-id="9d464-162">Cada registro de viagem inclui Olá retirada e local de entrega e hora, número de licença hack anônimos (driver) e número de medallion (id exclusiva do táxi).</span><span class="sxs-lookup"><span data-stu-id="9d464-162">Each trip record includes hello pick up and drop-off location and time, anonymized hack (driver's) license number and medallion (taxi’s unique id) number.</span></span> <span data-ttu-id="9d464-163">dados saudação abrange todas as viagens no ano Olá 2013 e são fornecidos em dois conjuntos de dados a seguir para cada mês de saudação:</span><span class="sxs-lookup"><span data-stu-id="9d464-163">hello data covers all trips in hello year 2013 and is provided in hello following two datasets for each month:</span></span>

1. <span data-ttu-id="9d464-164">arquivos CSV 'trip_data' Hello contêm detalhes de processamento, como o número de passageiros, acompanhar e pontos de redução, trip duração e o comprimento da viagem.</span><span class="sxs-lookup"><span data-stu-id="9d464-164">hello 'trip_data' CSV files contain trip details, such as number of passengers, pick up and dropoff points, trip duration, and trip length.</span></span> <span data-ttu-id="9d464-165">Aqui estão alguns exemplos de registros:</span><span class="sxs-lookup"><span data-stu-id="9d464-165">Here are a few sample records:</span></span>
   
        medallion,hack_license,vendor_id,rate_code,store_and_fwd_flag,pickup_datetime,dropoff_datetime,passenger_count,trip_time_in_secs,trip_distance,pickup_longitude,pickup_latitude,dropoff_longitude,dropoff_latitude
        89D227B655E5C82AECF13C3F540D4CF4,BA96DE419E711691B9445D6A6307C170,CMT,1,N,2013-01-01 15:11:48,2013-01-01 15:18:10,4,382,1.00,-73.978165,40.757977,-73.989838,40.751171
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,1,N,2013-01-06 00:18:35,2013-01-06 00:22:54,1,259,1.50,-74.006683,40.731781,-73.994499,40.75066
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,1,N,2013-01-05 18:49:41,2013-01-05 18:54:23,1,282,1.10,-74.004707,40.73777,-74.009834,40.726002
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,1,N,2013-01-07 23:54:15,2013-01-07 23:58:20,2,244,.70,-73.974602,40.759945,-73.984734,40.759388
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,1,N,2013-01-07 23:25:03,2013-01-07 23:34:24,1,560,2.10,-73.97625,40.748528,-74.002586,40.747868
2. <span data-ttu-id="9d464-166">arquivos CSV 'trip_fare' Hello contêm detalhes da tarifa Olá pagado para cada viagem, como tipo de pagamento, quantidade de passagens, sobretaxa e impostos, dicas e pedágio e quantidade total de saudação paga.</span><span class="sxs-lookup"><span data-stu-id="9d464-166">hello 'trip_fare' CSV files contain details of hello fare paid for each trip, such as payment type, fare amount, surcharge and taxes, tips and tolls, and hello total amount paid.</span></span> <span data-ttu-id="9d464-167">Aqui estão alguns exemplos de registros:</span><span class="sxs-lookup"><span data-stu-id="9d464-167">Here are a few sample records:</span></span>
   
        medallion, hack_license, vendor_id, pickup_datetime, payment_type, fare_amount, surcharge, mta_tax, tip_amount, tolls_amount, total_amount
        89D227B655E5C82AECF13C3F540D4CF4,BA96DE419E711691B9445D6A6307C170,CMT,2013-01-01 15:11:48,CSH,6.5,0,0.5,0,0,7
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,2013-01-06 00:18:35,CSH,6,0.5,0.5,0,0,7
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,2013-01-05 18:49:41,CSH,5.5,1,0.5,0,0,7
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,2013-01-07 23:54:15,CSH,5,0.5,0.5,0,0,6
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,2013-01-07 23:25:03,CSH,9.5,0.5,0.5,0,0,10.5

<span data-ttu-id="9d464-168">Levamos um exemplo de 0,1% desses arquivos e viagem Olá unidas\_dados e viagem\_passagens arquivos CSV em um único conjunto de dados toouse como conjunto de dados de entrada de saudação para este passo a passo.</span><span class="sxs-lookup"><span data-stu-id="9d464-168">We have taken a 0.1% sample of these files and joined hello trip\_data and trip\_fare CVS files into a single dataset toouse as hello input dataset for this walkthrough.</span></span> <span data-ttu-id="9d464-169">viagem de toojoin de chave exclusivo Olá\_dados e viagem\_passagens é composta de campos de saudação: medallion, ataques\_licença e retirada\_datetime.</span><span class="sxs-lookup"><span data-stu-id="9d464-169">hello unique key toojoin trip\_data and trip\_fare is composed of hello fields: medallion, hack\_licence and pickup\_datetime.</span></span> <span data-ttu-id="9d464-170">Cada registro do conjunto de dados Olá contém Olá atributos que representam uma viagem NYC táxi a seguir:</span><span class="sxs-lookup"><span data-stu-id="9d464-170">Each record of hello dataset contains hello following attributes representing a NYC Taxi trip:</span></span>

| <span data-ttu-id="9d464-171">Campo</span><span class="sxs-lookup"><span data-stu-id="9d464-171">Field</span></span> | <span data-ttu-id="9d464-172">Breve descrição</span><span class="sxs-lookup"><span data-stu-id="9d464-172">Brief Description</span></span> |
| --- | --- |
| <span data-ttu-id="9d464-173">medallion</span><span class="sxs-lookup"><span data-stu-id="9d464-173">medallion</span></span> |<span data-ttu-id="9d464-174">Licença do táxi em forma anônima (ID exclusiva do táxi)</span><span class="sxs-lookup"><span data-stu-id="9d464-174">Anonymized taxi medallion (unique taxi id)</span></span> |
| <span data-ttu-id="9d464-175">hack_license</span><span class="sxs-lookup"><span data-stu-id="9d464-175">hack_license</span></span> |<span data-ttu-id="9d464-176">Número de licença do carro em forma anônima</span><span class="sxs-lookup"><span data-stu-id="9d464-176">Anonymized Hackney Carriage License number</span></span> |
| <span data-ttu-id="9d464-177">vendor_id</span><span class="sxs-lookup"><span data-stu-id="9d464-177">vendor_id</span></span> |<span data-ttu-id="9d464-178">ID do fornecedor do serviço de táxi</span><span class="sxs-lookup"><span data-stu-id="9d464-178">Taxi vendor id</span></span> |
| <span data-ttu-id="9d464-179">rate_code</span><span class="sxs-lookup"><span data-stu-id="9d464-179">rate_code</span></span> |<span data-ttu-id="9d464-180">Tarifa praticada pelos táxis em NYC</span><span class="sxs-lookup"><span data-stu-id="9d464-180">NYC taxi rate of fare</span></span> |
| <span data-ttu-id="9d464-181">store_and_fwd_flag</span><span class="sxs-lookup"><span data-stu-id="9d464-181">store_and_fwd_flag</span></span> |<span data-ttu-id="9d464-182">Sinalizador de que os dados foram armazenados no veículo e encaminhados posteriormente</span><span class="sxs-lookup"><span data-stu-id="9d464-182">Store and forward flag</span></span> |
| <span data-ttu-id="9d464-183">pickup_datetime</span><span class="sxs-lookup"><span data-stu-id="9d464-183">pickup_datetime</span></span> |<span data-ttu-id="9d464-184">Data e hora do início da corrida</span><span class="sxs-lookup"><span data-stu-id="9d464-184">Pick up date & time</span></span> |
| <span data-ttu-id="9d464-185">dropoff_datetime</span><span class="sxs-lookup"><span data-stu-id="9d464-185">dropoff_datetime</span></span> |<span data-ttu-id="9d464-186">Data e hora do final da corrida</span><span class="sxs-lookup"><span data-stu-id="9d464-186">Dropoff date & time</span></span> |
| <span data-ttu-id="9d464-187">pickup_hour</span><span class="sxs-lookup"><span data-stu-id="9d464-187">pickup_hour</span></span> |<span data-ttu-id="9d464-188">Hora da corrida</span><span class="sxs-lookup"><span data-stu-id="9d464-188">Pick up hour</span></span> |
| <span data-ttu-id="9d464-189">pickup_week</span><span class="sxs-lookup"><span data-stu-id="9d464-189">pickup_week</span></span> |<span data-ttu-id="9d464-190">Pegue a semana do ano Olá</span><span class="sxs-lookup"><span data-stu-id="9d464-190">Pick up week of hello year</span></span> |
| <span data-ttu-id="9d464-191">weekday</span><span class="sxs-lookup"><span data-stu-id="9d464-191">weekday</span></span> |<span data-ttu-id="9d464-192">Dia da semana (intervalo de 1 a 7)</span><span class="sxs-lookup"><span data-stu-id="9d464-192">Weekday (range 1-7)</span></span> |
| <span data-ttu-id="9d464-193">passenger_count</span><span class="sxs-lookup"><span data-stu-id="9d464-193">passenger_count</span></span> |<span data-ttu-id="9d464-194">Número de passageiros em uma corrida de táxi</span><span class="sxs-lookup"><span data-stu-id="9d464-194">Number of passengers in a taxi trip</span></span> |
| <span data-ttu-id="9d464-195">trip_time_in_secs</span><span class="sxs-lookup"><span data-stu-id="9d464-195">trip_time_in_secs</span></span> |<span data-ttu-id="9d464-196">Tempo da corrida em segundos</span><span class="sxs-lookup"><span data-stu-id="9d464-196">Trip time in seconds</span></span> |
| <span data-ttu-id="9d464-197">trip_distance</span><span class="sxs-lookup"><span data-stu-id="9d464-197">trip_distance</span></span> |<span data-ttu-id="9d464-198">Distância percorrida na corrida em milhas</span><span class="sxs-lookup"><span data-stu-id="9d464-198">Trip distance traveled in miles</span></span> |
| <span data-ttu-id="9d464-199">pickup_longitude</span><span class="sxs-lookup"><span data-stu-id="9d464-199">pickup_longitude</span></span> |<span data-ttu-id="9d464-200">Longitude da corrida</span><span class="sxs-lookup"><span data-stu-id="9d464-200">Pick up longitude</span></span> |
| <span data-ttu-id="9d464-201">pickup_latitude</span><span class="sxs-lookup"><span data-stu-id="9d464-201">pickup_latitude</span></span> |<span data-ttu-id="9d464-202">Latitude da corrida</span><span class="sxs-lookup"><span data-stu-id="9d464-202">Pick up latitude</span></span> |
| <span data-ttu-id="9d464-203">dropoff_longitude</span><span class="sxs-lookup"><span data-stu-id="9d464-203">dropoff_longitude</span></span> |<span data-ttu-id="9d464-204">Longitude do final da corrida</span><span class="sxs-lookup"><span data-stu-id="9d464-204">Dropoff longitude</span></span> |
| <span data-ttu-id="9d464-205">dropoff_latitude</span><span class="sxs-lookup"><span data-stu-id="9d464-205">dropoff_latitude</span></span> |<span data-ttu-id="9d464-206">Latitude do final da corrida</span><span class="sxs-lookup"><span data-stu-id="9d464-206">Dropoff latitude</span></span> |
| <span data-ttu-id="9d464-207">direct_distance</span><span class="sxs-lookup"><span data-stu-id="9d464-207">direct_distance</span></span> |<span data-ttu-id="9d464-208">Distância direta entre os locais inicial e final da corrida</span><span class="sxs-lookup"><span data-stu-id="9d464-208">Direct distance between pick up and dropoff locations</span></span> |
| <span data-ttu-id="9d464-209">payment_type</span><span class="sxs-lookup"><span data-stu-id="9d464-209">payment_type</span></span> |<span data-ttu-id="9d464-210">Tipo de pagamento (dinheiro, cartão de crédito etc.)</span><span class="sxs-lookup"><span data-stu-id="9d464-210">Payment type (cas, credit-card etc.)</span></span> |
| <span data-ttu-id="9d464-211">fare_amount</span><span class="sxs-lookup"><span data-stu-id="9d464-211">fare_amount</span></span> |<span data-ttu-id="9d464-212">Valor da tarifa</span><span class="sxs-lookup"><span data-stu-id="9d464-212">Fare amount in</span></span> |
| <span data-ttu-id="9d464-213">surcharge</span><span class="sxs-lookup"><span data-stu-id="9d464-213">surcharge</span></span> |<span data-ttu-id="9d464-214">Taxa adicional</span><span class="sxs-lookup"><span data-stu-id="9d464-214">Surcharge</span></span> |
| <span data-ttu-id="9d464-215">mta_tax</span><span class="sxs-lookup"><span data-stu-id="9d464-215">mta_tax</span></span> |<span data-ttu-id="9d464-216">Imposto da MTA</span><span class="sxs-lookup"><span data-stu-id="9d464-216">Mta tax</span></span> |
| <span data-ttu-id="9d464-217">tip_amount</span><span class="sxs-lookup"><span data-stu-id="9d464-217">tip_amount</span></span> |<span data-ttu-id="9d464-218">Valor da gorjeta</span><span class="sxs-lookup"><span data-stu-id="9d464-218">Tip amount</span></span> |
| <span data-ttu-id="9d464-219">tolls_amount</span><span class="sxs-lookup"><span data-stu-id="9d464-219">tolls_amount</span></span> |<span data-ttu-id="9d464-220">Valor dos pedágios</span><span class="sxs-lookup"><span data-stu-id="9d464-220">Tolls amount</span></span> |
| <span data-ttu-id="9d464-221">total_amount</span><span class="sxs-lookup"><span data-stu-id="9d464-221">total_amount</span></span> |<span data-ttu-id="9d464-222">Valor total</span><span class="sxs-lookup"><span data-stu-id="9d464-222">Total amount</span></span> |
| <span data-ttu-id="9d464-223">tipped</span><span class="sxs-lookup"><span data-stu-id="9d464-223">tipped</span></span> |<span data-ttu-id="9d464-224">Gorjeta (0/1 para não ou sim)</span><span class="sxs-lookup"><span data-stu-id="9d464-224">Tipped (0/1 for no or yes)</span></span> |
| <span data-ttu-id="9d464-225">tip_class</span><span class="sxs-lookup"><span data-stu-id="9d464-225">tip_class</span></span> |<span data-ttu-id="9d464-226">Classe da gorjeta (0: US$ 0, 1: US$ 0 a 5, 2: US$ 6 a 10, 3: US$ 11 a 20, 4: mais de US$ 20)</span><span class="sxs-lookup"><span data-stu-id="9d464-226">Tip class (0: $0, 1: $0-5, 2: $6-10, 3: $11-20, 4: > $20)</span></span> |

## <a name="execute-code-from-a-jupyter-notebook-on-hello-spark-cluster"></a><span data-ttu-id="9d464-227">Execute o código de um bloco de anotações do Jupyter no cluster do Spark Olá</span><span class="sxs-lookup"><span data-stu-id="9d464-227">Execute code from a Jupyter notebook on hello Spark cluster</span></span>
<span data-ttu-id="9d464-228">Você pode iniciar Olá anotações do Jupyter do hello portal do Azure.</span><span class="sxs-lookup"><span data-stu-id="9d464-228">You can launch hello Jupyter Notebook from hello Azure portal.</span></span> <span data-ttu-id="9d464-229">Localize seu cluster Spark no painel e clique em página de gerenciamento de tooenter para seu cluster.</span><span class="sxs-lookup"><span data-stu-id="9d464-229">Find your Spark cluster on your dashboard and click it tooenter management page for your cluster.</span></span> <span data-ttu-id="9d464-230">bloco de anotações do hello tooopen associado Olá Spark cluster, clique em **painéis do Cluster** -> **Jupyter Notebook** .</span><span class="sxs-lookup"><span data-stu-id="9d464-230">tooopen hello notebook associated with hello Spark cluster, click **Cluster Dashboards** -> **Jupyter Notebook** .</span></span>

![Painéis de cluster](./media/machine-learning-data-science-spark-overview/spark-jupyter-on-portal.png)

<span data-ttu-id="9d464-232">Você também pode procurar muito***https://CLUSTERNAME.azurehdinsight.net/jupyter*** tooaccess Olá blocos de anotações do Jupyter.</span><span class="sxs-lookup"><span data-stu-id="9d464-232">You can also browse too***https://CLUSTERNAME.azurehdinsight.net/jupyter*** tooaccess hello Jupyter Notebooks.</span></span> <span data-ttu-id="9d464-233">Substitua parte CLUSTERNAME Olá essa URL com nome de saudação do seu próprio cluster.</span><span class="sxs-lookup"><span data-stu-id="9d464-233">Replace hello CLUSTERNAME part of this URL with hello name of your own cluster.</span></span> <span data-ttu-id="9d464-234">Senha de saudação é necessária para os blocos de anotações do administrador conta tooaccess hello.</span><span class="sxs-lookup"><span data-stu-id="9d464-234">You need hello password for your admin account tooaccess hello notebooks.</span></span>

![Procurar Notebooks Jupyter](./media/machine-learning-data-science-spark-overview/spark-jupyter-notebook.png)

<span data-ttu-id="9d464-236">Selecione PySpark toosee um diretório que contém alguns exemplos de blocos de anotações predefinidos que usam Olá PySpark API.hello blocos de anotações que contêm exemplos de código Olá para este conjunto de tópico Spark estão disponíveis em [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark)</span><span class="sxs-lookup"><span data-stu-id="9d464-236">Select PySpark toosee a directory that contains a few examples of pre-packaged notebooks that use hello PySpark API.hello notebooks that contain hello code samples for this suite of Spark topic are available at [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark)</span></span>

<span data-ttu-id="9d464-237">Você pode carregar blocos de anotações Olá diretamente do [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark) servidor de notebook Jupyter toohello em seu cluster Spark.</span><span class="sxs-lookup"><span data-stu-id="9d464-237">You can upload hello notebooks directly from [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark) toohello Jupyter notebook server on your Spark cluster.</span></span> <span data-ttu-id="9d464-238">Na página inicial de saudação do seu Jupyter, clique em Olá **carregar** botão Olá parte direita da tela hello.</span><span class="sxs-lookup"><span data-stu-id="9d464-238">On hello home page of your Jupyter, click hello **Upload** button on hello right part of hello screen.</span></span> <span data-ttu-id="9d464-239">Ele abre o explorador de arquivos.</span><span class="sxs-lookup"><span data-stu-id="9d464-239">It opens a file explorer.</span></span> <span data-ttu-id="9d464-240">Aqui você pode colar a URL GitHub (conteúdo bruto) Olá Olá Notebook e clique em **abrir**.</span><span class="sxs-lookup"><span data-stu-id="9d464-240">Here you can paste hello GitHub (raw content) URL of hello Notebook and click **Open**.</span></span> 

<span data-ttu-id="9d464-241">Consulte o nome do arquivo hello em sua lista de arquivos do Jupyter com um **carregar** novamente.</span><span class="sxs-lookup"><span data-stu-id="9d464-241">You see hello file name on your Jupyter file list with an **Upload** button again.</span></span> <span data-ttu-id="9d464-242">Clique nesse botão **Carregar** .</span><span class="sxs-lookup"><span data-stu-id="9d464-242">Click this **Upload** button.</span></span> <span data-ttu-id="9d464-243">Agora você importou notebook hello.</span><span class="sxs-lookup"><span data-stu-id="9d464-243">Now you have imported hello notebook.</span></span> <span data-ttu-id="9d464-244">Repita a saudação de tooupload essas etapas outros blocos de anotações deste passo a passo.</span><span class="sxs-lookup"><span data-stu-id="9d464-244">Repeat these steps tooupload hello other notebooks from this walkthrough.</span></span>

> [!TIP]
> <span data-ttu-id="9d464-245">Clique links Olá no seu navegador e selecione **Copiar Link** tooget Olá github URL bruta de conteúdo.</span><span class="sxs-lookup"><span data-stu-id="9d464-245">You can right-click hello links on your browser and select **Copy Link** tooget hello github raw content URL.</span></span> <span data-ttu-id="9d464-246">Você pode colar essa URL em Olá Jupyter carregar arquivo explorer caixa de diálogo.</span><span class="sxs-lookup"><span data-stu-id="9d464-246">You can paste this URL into hello Jupyter Upload file explorer dialog box.</span></span>
> 
> 

<span data-ttu-id="9d464-247">Agora você pode:</span><span class="sxs-lookup"><span data-stu-id="9d464-247">Now you can:</span></span>

* <span data-ttu-id="9d464-248">Consulte o código de saudação clicando notebook hello.</span><span class="sxs-lookup"><span data-stu-id="9d464-248">See hello code by clicking hello notebook.</span></span>
* <span data-ttu-id="9d464-249">Executar cada célula pressionando **SHIFT-ENTER**.</span><span class="sxs-lookup"><span data-stu-id="9d464-249">Execute each cell by pressing **SHIFT-ENTER**.</span></span>
* <span data-ttu-id="9d464-250">Execute o bloco de anotações inteiro Olá clicando no **célula** -> **executar**.</span><span class="sxs-lookup"><span data-stu-id="9d464-250">Run hello entire notebook by clicking on **Cell** -> **Run**.</span></span>
* <span data-ttu-id="9d464-251">Use a visualização automática Olá de consultas.</span><span class="sxs-lookup"><span data-stu-id="9d464-251">Use hello automatic visualization of queries.</span></span>

> [!TIP]
> <span data-ttu-id="9d464-252">núcleo de PySpark Olá automaticamente visualiza saída Olá de consultas SQL (HiveQL).</span><span class="sxs-lookup"><span data-stu-id="9d464-252">hello PySpark kernel automatically visualizes hello output of SQL (HiveQL) queries.</span></span> <span data-ttu-id="9d464-253">Recebem Olá opção tooselect entre vários tipos diferentes de visualizações (tabela, pizza, linha, área ou barra) usando Olá **tipo** botões de menu no bloco de anotações de saudação:</span><span class="sxs-lookup"><span data-stu-id="9d464-253">You are given hello option tooselect among several different types of visualizations (Table, Pie, Line, Area, or Bar) by using hello **Type** menu buttons in hello notebook:</span></span>
> 
> 

![Curva ROC de regressão logística de abordagem genérica](./media/machine-learning-data-science-spark-overview/pyspark-jupyter-autovisualization.png)

## <a name="whats-next"></a><span data-ttu-id="9d464-255">O que vem a seguir?</span><span class="sxs-lookup"><span data-stu-id="9d464-255">What's next?</span></span>
<span data-ttu-id="9d464-256">Agora que são configurados com um cluster HDInsight Spark e carregar blocos de anotações do Jupyter hello, você está pronto toowork tópicos Olá que correspondem a três PySpark toohello de anotações.</span><span class="sxs-lookup"><span data-stu-id="9d464-256">Now that you are set up with an HDInsight Spark cluster and have uploaded hello Jupyter notebooks, you are ready toowork through hello topics that correspond toohello three PySpark notebooks.</span></span> <span data-ttu-id="9d464-257">Eles mostram como tooexplore seus dados e, em seguida, como toocreate e consumir modelos.</span><span class="sxs-lookup"><span data-stu-id="9d464-257">They show how tooexplore your data and then how toocreate and consume models.</span></span> <span data-ttu-id="9d464-258">Olá avançados de exploração de dados e modelagem notebook mostra como tooinclude limpeza de validação cruzada, parâmetro hyper e avaliação do modelo.</span><span class="sxs-lookup"><span data-stu-id="9d464-258">hello advanced data exploration and modeling notebook shows how tooinclude cross-validation, hyper-parameter sweeping, and model evaluation.</span></span> 

<span data-ttu-id="9d464-259">**Exploração de dados e modelagem com Spark:** explorar Olá conjunto de dados e criar, pontuação e avaliar modelos de aprendizado de máquina Olá trabalhando Olá [criar modelos de classificação e regressão binários para dados com hello Spark Kit de ferramentas MLlib](machine-learning-data-science-spark-data-exploration-modeling.md) tópico.</span><span class="sxs-lookup"><span data-stu-id="9d464-259">**Data Exploration and modeling with Spark:** Explore hello dataset and create, score, and evaluate hello machine learning models by working through hello [Create binary classification and regression models for data with hello Spark MLlib toolkit](machine-learning-data-science-spark-data-exploration-modeling.md) topic.</span></span>

<span data-ttu-id="9d464-260">**Consumo de modelo:** toolearn como modelos de classificação e regressão Olá tooscore criada neste tópico, consulte [pontuação e avaliar modelos de aprendizado de máquina criados Spark](machine-learning-data-science-spark-model-consumption.md).</span><span class="sxs-lookup"><span data-stu-id="9d464-260">**Model consumption:** toolearn how tooscore hello classification and regression models created in this topic, see [Score and evaluate Spark-built machine learning models](machine-learning-data-science-spark-model-consumption.md).</span></span>

<span data-ttu-id="9d464-261">**Validação cruzada e limpeza de hiperparâmetro**: confira [Modelagem e exploração de dados avançados com o Spark](machine-learning-data-science-spark-advanced-data-exploration-modeling.md) para saber como os modelos podem ser treinados usando a validação cruzada e a limpeza de hiperparâmetro</span><span class="sxs-lookup"><span data-stu-id="9d464-261">**Cross-validation and hyperparameter sweeping**: See [Advanced data exploration and modeling with Spark](machine-learning-data-science-spark-advanced-data-exploration-modeling.md) on how models can be trained using cross-validation and hyper-parameter sweeping</span></span>

